{"cells":[{"cell_type":"markdown","metadata":{"id":"jFInBq9q18Bu"},"source":["Final Year Project"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33648,"status":"ok","timestamp":1742912450894,"user":{"displayName":"Liam John","userId":"06685647300504122282"},"user_tz":240},"id":"i5KEQMJrzD83","outputId":"c21fc1ca-76aa-450d-c7a4-5cd3276c17d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":369931,"status":"ok","timestamp":1742368341103,"user":{"displayName":"Liam John","userId":"06685647300504122282"},"user_tz":240},"id":"fJEAPvY4rVxx","outputId":"9428d057-7595-49c3-fa85-9e3910ff7841"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m949.3/949.3 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCreating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Collecting roboflow\n","  Downloading roboflow-1.1.58-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n","Collecting idna==3.7 (from roboflow)\n","  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n","Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n","  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n","Collecting pillow-heif>=0.18.0 (from roboflow)\n","  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n","Collecting filetype (from roboflow)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.56.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n","Downloading roboflow-1.1.58-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.11.0.86\n","    Uninstalling opencv-python-headless-4.11.0.86:\n","      Successfully uninstalled opencv-python-headless-4.11.0.86\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.0.1 roboflow-1.1.58\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cv2"]},"id":"92959495e45147648d43554b1c60185a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in multiplayer-football-detection-8 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92689/92689 [00:02<00:00, 38245.67it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to multiplayer-football-detection-8 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1064/1064 [00:00<00:00, 1703.13it/s]"]},{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131M/131M [00:00<00:00, 233MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.93 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","YOLOv8x summary (fused): 112 layers, 68,200,608 parameters, 0 gradients, 257.8 GFLOPs\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 21.6MB/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/multiplayer-football-detection-8/valid/labels... 38 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 503.28it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/multiplayer-football-detection-8/valid/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:40<00:00, 73.59s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         38        885       0.25    0.00781   0.000165    4.2e-05\n","                person         31         32    0.00082     0.0312    0.00066   0.000168\n","               bicycle         24         25          1          0          0          0\n","                   car         38        752          0          0          0          0\n","            motorcycle         38         76          0          0          0          0\n","Speed: 9.6ms preprocess, 5762.0ms inference, 0.0ms loss, 3.7ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n"]}],"source":["!pip install -q ultralytics\n","from ultralytics import YOLO\n","!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"3os8PUhuHDYfLxJwP0tm\")\n","project = rf.workspace(\"liam-john-ynzku\").project(\"multiplayer-football-detection\")\n","version = project.version(8)\n","dataset = version.download(\"yolov8\")\n","\n","\n","# Load a pretrained YOLOv8 model\n","#model = YOLO('/content/drive/MyDrive/YOLOv8_PlayerDetection/Copy of best.pt')\n","model = YOLO(\"yolov8x.pt\")\n","\n","# Run validation on a set specified as 'val' argument\n","metrics = model.val(data='/content/multiplayer-football-detection-8/data.yaml')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"UQ9MeSKxy-ch","executionInfo":{"status":"ok","timestamp":1742912575934,"user_tz":240,"elapsed":125050,"user":{"displayName":"Liam John","userId":"06685647300504122282"}},"outputId":"4bfa3a70-a006-47f1-a00e-e94eb44e7e70"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.6/200.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Skipping supervision as it is not installed.\u001b[0m\u001b[33m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: supervision in /usr/local/lib/python3.11/dist-packages (0.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n","Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.7)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (5.29.4)\n","Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.3.1)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision) (0.7.1)\n","Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (3.10.0)\n","Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.11/dist-packages (from supervision) (11.1.0)\n","Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from supervision) (6.0.2)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (2.32.3)\n","Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.14.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.60.0)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2025.1.31)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n"]}],"source":["#!pip install -q gdown inference-gpu\n","!pip install -q onnxruntime-gpu==1.18.0 --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n","!pip uninstall -y supervision && pip install -q supervision>=0.23.0\n","#!pip install -q git+https://github.com/roboflow/sports.git\n","!pip install -q ultralytics\n","!pip install supervision numpy opencv-python transformers umap-learn scikit-learn tqdm sentencepiece protobuf"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"TSc53oF4UJ2Y","executionInfo":{"status":"ok","timestamp":1742912632893,"user_tz":240,"elapsed":56955,"user":{"displayName":"Liam John","userId":"06685647300504122282"}},"outputId":"276d89a3-5ee5-48ed-af32-3350cff267c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}],"source":["from ultralytics import YOLO  # Object detection model\n","import supervision as sv  # Assists with object tracking and detection\n","from tqdm import tqdm\n","import cv2\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import supervision as sv\n","from dataclasses import dataclass, field\n","from typing import Dict, List, Optional, Tuple, Union, Any, Generator, Iterable, List, TypeVar\n","from enum import IntEnum, Enum\n","from collections import deque, defaultdict\n","from scipy.spatial import ConvexHull,Delaunay\n","from scipy.cluster.hierarchy import linkage, fcluster\n","import torch\n","import umap\n","from sklearn.cluster import KMeans\n","from transformers import AutoProcessor, SiglipVisionModel\n","import numpy.typing as npt\n","\n","\n","@dataclass\n","class FootballPitchConfiguration:\n","    width: int = 6800  # [cm]\n","    length: int = 10500  # [cm]\n","    penalty_box_width: int = 4100  # [cm]\n","    penalty_box_length: int = 2015  # [cm]\n","    goal_box_width: int = 1832  # [cm]\n","    goal_box_length: int = 550  # [cm]\n","    centre_circle_radius: int = 915  # [cm]\n","    penalty_spot_distance: int = 1100  # [cm]\n","\n","    @property\n","    def vertices(self) -> List[Tuple[int, int]]:\n","        return [\n","            (0, 0),  # 1\n","            (0, (self.width - self.penalty_box_width) / 2),  # 2\n","            (0, (self.width - self.goal_box_width) / 2),  # 3\n","            (0, (self.width + self.goal_box_width) / 2),  # 4\n","            (0, (self.width + self.penalty_box_width) / 2),  # 5\n","            (0, self.width),  # 6\n","            (self.goal_box_length, (self.width - self.goal_box_width) / 2),  # 7\n","            (self.goal_box_length, (self.width + self.goal_box_width) / 2),  # 8\n","            (self.penalty_spot_distance, self.width / 2),  # 9\n","            (self.penalty_box_length, (self.width - self.penalty_box_width) / 2),  # 10\n","            (self.penalty_box_length, (self.width - self.goal_box_width) / 2),  # 11\n","            (self.penalty_box_length, (self.width + self.goal_box_width) / 2),  # 12\n","            (self.penalty_box_length, (self.width + self.penalty_box_width) / 2),  # 13\n","            (self.length / 2, 0),  # 14\n","            (self.length / 2, self.width / 2 - self.centre_circle_radius),  # 15\n","            (self.length / 2, self.width / 2 + self.centre_circle_radius),  # 16\n","            (self.length / 2, self.width),  # 17\n","            (\n","                self.length - self.penalty_box_length,\n","                (self.width - self.penalty_box_width) / 2\n","            ),  # 18\n","            (\n","                self.length - self.penalty_box_length,\n","                (self.width - self.goal_box_width) / 2\n","            ),  # 19\n","            (\n","                self.length - self.penalty_box_length,\n","                (self.width + self.goal_box_width) / 2\n","            ),  # 20\n","            (\n","                self.length - self.penalty_box_length,\n","                (self.width + self.penalty_box_width) / 2\n","            ),  # 21\n","            (self.length - self.penalty_spot_distance, self.width / 2),  # 22\n","            (\n","                self.length - self.goal_box_length,\n","                (self.width - self.goal_box_width) / 2\n","            ),  # 23\n","            (\n","                self.length - self.goal_box_length,\n","                (self.width + self.goal_box_width) / 2\n","            ),  # 24\n","            (self.length, 0),  # 25\n","            (self.length, (self.width - self.penalty_box_width) / 2),  # 26\n","            (self.length, (self.width - self.goal_box_width) / 2),  # 27\n","            (self.length, (self.width + self.goal_box_width) / 2),  # 28\n","            (self.length, (self.width + self.penalty_box_width) / 2),  # 29\n","            (self.length, self.width),  # 30\n","            (self.length / 2 - self.centre_circle_radius, self.width / 2),  # 31\n","            (self.length / 2 + self.centre_circle_radius, self.width / 2),  # 32\n","        ]\n","\n","    edges: List[Tuple[int, int]] = field(default_factory=lambda: [\n","        (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (7, 8),\n","        (10, 11), (11, 12), (12, 13), (14, 15), (15, 16),\n","        (16, 17), (18, 19), (19, 20), (20, 21), (23, 24),\n","        (25, 26), (26, 27), (27, 28), (28, 29), (29, 30),\n","        (1, 14), (2, 10), (3, 7), (4, 8), (5, 13), (6, 17),\n","        (14, 25), (18, 26), (23, 27), (24, 28), (21, 29), (17, 30)\n","    ])\n","\n","    labels: List[str] = field(default_factory=lambda: [\n","        \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\",\n","        \"11\", \"12\", \"13\", \"15\", \"16\", \"17\", \"18\", \"20\", \"21\", \"22\",\n","        \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\",\n","        \"14\", \"19\"\n","    ])\n","\n","    colors: List[str] = field(default_factory=lambda: [\n","        \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\",\n","        \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\",\n","        \"#FF1493\", \"#00BFFF\", \"#00BFFF\", \"#00BFFF\", \"#00BFFF\", \"#FF6347\",\n","        \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\",\n","        \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\",\n","        \"#00BFFF\", \"#00BFFF\"\n","    ])\n","\n","\n","def draw_pitch(\n","    config: SoccerPitchConfiguration,\n","    background_color: sv.Color = sv.Color(34, 139, 34),\n","    line_color: sv.Color = sv.Color.WHITE,\n","    padding: int = 50,\n","    line_thickness: int = 4,\n","    point_radius: int = 8,\n","    scale: float = 0.1\n",") -> np.ndarray:\n","\n","    scaled_width = int(config.width * scale)\n","    scaled_length = int(config.length * scale)\n","    scaled_circle_radius = int(config.centre_circle_radius * scale)\n","    scaled_penalty_spot_distance = int(config.penalty_spot_distance * scale)\n","\n","    pitch_image = np.ones(\n","        (scaled_width + 2 * padding,\n","         scaled_length + 2 * padding, 3),\n","        dtype=np.uint8\n","    ) * np.array(background_color.as_bgr(), dtype=np.uint8)\n","\n","    for start, end in config.edges:\n","        point1 = (int(config.vertices[start - 1][0] * scale) + padding,\n","                  int(config.vertices[start - 1][1] * scale) + padding)\n","        point2 = (int(config.vertices[end - 1][0] * scale) + padding,\n","                  int(config.vertices[end - 1][1] * scale) + padding)\n","        cv2.line(\n","            img=pitch_image,\n","            pt1=point1,\n","            pt2=point2,\n","            color=line_color.as_bgr(),\n","            thickness=line_thickness\n","        )\n","\n","    centre_circle_center = (\n","        scaled_length // 2 + padding,\n","        scaled_width // 2 + padding\n","    )\n","    cv2.circle(\n","        img=pitch_image,\n","        center=centre_circle_center,\n","        radius=scaled_circle_radius,\n","        color=line_color.as_bgr(),\n","        thickness=line_thickness\n","    )\n","\n","    penalty_spots = [\n","        (\n","            scaled_penalty_spot_distance + padding,\n","            scaled_width // 2 + padding\n","        ),\n","        (\n","            scaled_length - scaled_penalty_spot_distance + padding,\n","            scaled_width // 2 + padding\n","        )\n","    ]\n","    for spot in penalty_spots:\n","        cv2.circle(\n","            img=pitch_image,\n","            center=spot,\n","            radius=point_radius,\n","            color=line_color.as_bgr(),\n","            thickness=-1\n","        )\n","\n","    return pitch_image\n","\n","##############################################################################\n","\n","\n","def draw_points_on_pitch(\n","    config: SoccerPitchConfiguration,\n","    xy: np.ndarray,\n","    face_color: sv.Color = sv.Color.RED,\n","    edge_color: sv.Color = sv.Color.BLACK,\n","    radius: int = 10,\n","    thickness: int = 2,\n","    padding: int = 50,\n","    scale: float = 0.1,\n","    pitch: Optional[np.ndarray] = None\n",") -> np.ndarray:\n","\n","    if pitch is None:\n","        pitch = draw_pitch(\n","            config=config,\n","            padding=padding,\n","            scale=scale\n","        )\n","\n","    for point in xy:\n","        scaled_point = (\n","            int(point[0] * scale) + padding,\n","            int(point[1] * scale) + padding\n","        )\n","        cv2.circle(\n","            img=pitch,\n","            center=scaled_point,\n","            radius=radius,\n","            color=face_color.as_bgr(),\n","            thickness=-1\n","        )\n","        cv2.circle(\n","            img=pitch,\n","            center=scaled_point,\n","            radius=radius,\n","            color=edge_color.as_bgr(),\n","            thickness=thickness\n","        )\n","\n","    return pitch\n","\n","\n","def draw_paths_on_pitch(\n","    config: SoccerPitchConfiguration,\n","    paths: List[np.ndarray],\n","    color: sv.Color = sv.Color.WHITE,\n","    thickness: int = 2,\n","    padding: int = 50,\n","    scale: float = 0.1,\n","    pitch: Optional[np.ndarray] = None\n",") -> np.ndarray:\n","\n","    if pitch is None:\n","        pitch = draw_pitch(\n","            config=config,\n","            padding=padding,\n","            scale=scale\n","        )\n","\n","    for path in paths:\n","        scaled_path = [\n","            (\n","                int(point[0] * scale) + padding,\n","                int(point[1] * scale) + padding\n","            )\n","            for point in path if point.size > 0\n","        ]\n","\n","        if len(scaled_path) < 2:\n","            continue\n","\n","        for i in range(len(scaled_path) - 1):\n","            cv2.line(\n","                img=pitch,\n","                pt1=scaled_path[i],\n","                pt2=scaled_path[i + 1],\n","                color=color.as_bgr(),\n","                thickness=thickness\n","            )\n","\n","        return pitch\n","\n","###########################################################################\n","from sklearn.cluster import KMeans\n","from transformers import AutoFeatureExtractor, ResNetModel\n","import torchvision.transforms as T\n","from PIL import Image\n","\n","V = TypeVar(\"V\")\n","RESNET_MODEL_PATH = 'microsoft/resnet-26'\n","\n","\n","def create_batches(\n","    sequence: Iterable[V], batch_size: int\n",") -> Generator[List[V], None, None]:\n","\n","    batch_size = max(batch_size, 1)\n","    current_batch = []\n","    for element in sequence:\n","        if len(current_batch) == batch_size:\n","            yield current_batch\n","            current_batch = []\n","        current_batch.append(element)\n","    if current_batch:\n","        yield current_batch\n","\n","\n","class TeamClassifier:\n","\n","    def __init__(self, device: str = 'gpu', batch_size: int = 32):\n","\n","        self.device = device\n","        self.batch_size = batch_size\n","\n","        # ResNet\n","        self.features_model = ResNetModel.from_pretrained(\n","            RESNET_MODEL_PATH\n","        ).to(device)\n","\n","        # Replace processor with standard transforms\n","        self.preprocess = T.Compose([\n","            T.Resize(256),\n","            T.CenterCrop(224),\n","            T.ToTensor(),\n","            T.Normalize(\n","                mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225]\n","            )\n","        ])\n","\n","        self.reducer = umap.UMAP(n_components=3)\n","        self.cluster_model = KMeans(n_clusters=2)\n","\n","    def extract_features(self, crops: List[np.ndarray]) -> np.ndarray:\n","\n","        processed_images = []\n","        for crop in crops:\n","            img = Image.fromarray(crop).convert('RGB')\n","            img = self.preprocess(img)  # Shape [3, 224, 224]\n","            processed_images.append(img)\n","\n","        batches = create_batches(processed_images, self.batch_size)\n","        data = []\n","\n","        with torch.no_grad():\n","            for batch in tqdm(batches, desc='Embedding extraction'):\n","                inputs = torch.stack(batch).to(self.device)  # Shape [B, 3, 224, 224]\n","\n","                # Get ResNet features\n","                outputs = self.features_model(inputs)\n","\n","                # Extract and flatten features\n","                features = outputs.last_hidden_state  # Shape [B, 512, 7, 7]\n","\n","                # Global Average Pooling to convert to 2D\n","                embeddings = torch.mean(features, dim=[2, 3])  # Shape [B, 512]\n","\n","                data.append(embeddings.cpu().numpy())\n","\n","        return np.concatenate(data)  # Final shape [N_samples, 512]\n","\n","    def fit(self, crops: List[np.ndarray]) -> None:\n","\n","        data = self.extract_features(crops)\n","        projections = self.reducer.fit_transform(data)\n","        self.cluster_model.fit(projections)\n","\n","    def predict(self, crops: List[np.ndarray]) -> np.ndarray:\n","\n","        if len(crops) == 0:\n","            return np.array([])\n","\n","        data = self.extract_features(crops)\n","        projections = self.reducer.transform(data)\n","        return self.cluster_model.predict(projections)\n","\n","###########################################################################\n","\n","class ViewTransformer:\n","    def __init__(self, source: npt.NDArray[np.float32], target: npt.NDArray[np.float32]) -> None:\n","\n","        if source.shape != target.shape:\n","            raise ValueError(\"Source and target must have the same shape.\")\n","        if source.shape[1] != 2:\n","            raise ValueError(\"Source and target points must be 2D coordinates.\")\n","\n","        source = source.astype(np.float32)\n","        target = target.astype(np.float32)\n","        self.m, _ = cv2.findHomography(source, target)\n","        if self.m is None:\n","            raise ValueError(\"Homography matrix could not be calculated.\")\n","\n","    def transform_points(self, points: npt.NDArray[np.float32]) -> npt.NDArray[np.float32]:\n","\n","        if points.size == 0:\n","            return points\n","\n","        if points.shape[1] != 2:\n","            raise ValueError(\"Points must be 2D coordinates.\")\n","\n","        reshaped_points = points.reshape(-1, 1, 2).astype(np.float32)\n","        transformed_points = cv2.perspectiveTransform(reshaped_points, self.m)\n","        return transformed_points.reshape(-1, 2).astype(np.float32)\n","\n","    def transform_image(self, image: npt.NDArray[np.uint8], resolution_wh: Tuple[int, int]) -> npt.NDArray[np.uint8]:\n","\n","        if len(image.shape) not in {2, 3}:\n","            raise ValueError(\"Image must be either grayscale or color.\")\n","        return cv2.warpPerspective(image, self.m, resolution_wh)"]},{"cell_type":"code","source":["from PIL import Image, ImageDraw, ImageFont\n","import matplotlib.pyplot as plt\n","import os\n","\n","CONFIG = SoccerPitchConfiguration()\n","\n","#Constants\n","PLAYER_DETECTION_MODEL_PATH = '/content/drive/MyDrive/YOLOv8_PlayerDetection/YOLOv8_PlayerDetection/best.pt'\n","FIELD_DETECTION_MODEL_PATH = '/content/drive/MyDrive/YOLOv8_weights/YOLOv8_weights/football_field_keypoints/weights/best.pt'\n","SOURCE_VIDEO_PATH = \"/content/drive/MyDrive/Input_Videos/testing/35.mp4\"\n","\n","PLAYER_DETECTION_MODEL = YOLO(PLAYER_DETECTION_MODEL_PATH)\n","FIELD_DETECTION_MODEL = YOLO(FIELD_DETECTION_MODEL_PATH)\n","\n","#Function to track players across frames\n","def get_object_tracks(frames):\n","    tracks =[]\n","\n","    # Run detection for each frame\n","    for frame in frames:\n","        player_result = PLAYER_DETECTION_MODEL.predict(frame, conf=0.3)[0] #Detect players in the current frame using the trained YOLOv8 model\n","        detections = sv.Detections.from_ultralytics(player_result) #converts detection results to a standarized format (supervision)\n","\n","        # Collect the detections into a tracks list\n","        tracks.append(detections)\n","\n","    return tracks\n","\n","#Function to track keypoints across the frames\n","def get_keypoint_tracks(frames):\n","    keypoint_tracks = []\n","    # Run keypoint detection for each frame\n","    for frame in frames:\n","        field_result = FIELD_DETECTION_MODEL.predict(frame, conf=0.3)[0]\n","        key_points = sv.KeyPoints.from_ultralytics(field_result)\n","        keypoint_tracks.append(key_points)\n","\n","    return keypoint_tracks\n","\n","def calculate_tsmae(transformed_points: np.ndarray, ground_truth_points: np.ndarray) -> float:\n","    if transformed_points.shape != ground_truth_points.shape:\n","        raise ValueError(\"Shapes must match.\")\n","\n","    n = len(transformed_points)\n","    if n == 0:\n","        return 0.0\n","\n","    tsmae_sum = 0.0\n","    for t in range(n):\n","        S_t = transformed_points[t]\n","        R_t = ground_truth_points[t]\n","        abs_diff = np.abs(R_t - S_t)\n","        norm_diff = np.linalg.norm(abs_diff)  # Euclidean norm (L2)\n","        denominator = (np.linalg.norm(S_t) + np.linalg.norm(R_t)) / 2\n","        if denominator == 0:\n","            tsmae_sum += 0.0\n","        else:\n","            tsmae_sum += norm_diff / denominator\n","\n","    return tsmae_sum / n\n","\n","def calculate_overall_tsmae(reference_points: List[Dict[str, np.ndarray]]) -> Tuple[float, List[float]]:\n","    \"\"\"\n","    Calculate the overall TSMAE and TSMAE for each reference point.\n","\n","    Args:\n","        reference_points (List[Dict[str, np.ndarray]]): A list of dictionaries containing\n","            'transformed_pitch_coordinates' and 'ground_truth_pitch_coordinates'.\n","\n","    Returns:\n","        Tuple[float, List[float]]: The overall TSMAE and a list of TSMAE values for each reference point.\n","    \"\"\"\n","    tsmae_values = []\n","    for point in reference_points:\n","        transformed_points = point['transformed_pitch_coordinates']\n","        ground_truth_points = point['ground_truth_pitch_coordinates']\n","\n","        tsmae = calculate_tsmae(transformed_points, ground_truth_points)\n","        tsmae_values.append(tsmae)\n","\n","    overall_tsmae = np.mean(tsmae_values)\n","    return overall_tsmae, tsmae_values\n","\n","\n","# Specify the save directory in Google Drive\n","save_dir = \"/content/drive/MyDrive/Output_Videos/testingHomography/Testing35/\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","def test_homography_with_reference_points():\n","    # Load frames from video\n","    frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n","    frames = list(frame_generator)\n","\n","    # Get keypoint tracks\n","    keypoint_tracks = get_keypoint_tracks(frames)\n","\n","    # Initialize homography matrix\n","    M = deque(maxlen=5)\n","\n","    # Store TSMAE values for each frame\n","    frame_tsmae_values = []\n","    all_reference_points = []\n","\n","    # Open a file to save the output\n","    output_file_path = os.path.join(save_dir, \"homography_output.txt\")\n","    with open(output_file_path, \"w\") as output_file:\n","        for frame_count, (frame, key_points) in enumerate(zip(frames, keypoint_tracks)):\n","            # Filter keypoints with confidence > 0.5\n","            filter = key_points.confidence[0] > 0.5\n","            frame_reference_points = key_points.xy[0][filter]\n","            pitch_reference_points = np.array(CONFIG.vertices)[filter]\n","\n","            # Skip frames with no reference points\n","            if len(frame_reference_points) < 4:\n","                if frame_count % 10 == 0:\n","                    output_file.write(f\"Frame {frame_count}: No reference points detected.\\n\")\n","                continue\n","\n","            # Calculate homography matrix\n","            transformer = ViewTransformer(\n","                source=frame_reference_points,\n","                target=pitch_reference_points\n","            )\n","            M.append(transformer.m)\n","            transformer.m = np.mean(np.array(M), axis=0)\n","\n","            # Write the homography matrix to the file\n","            if frame_count % 10 == 0:\n","                output_file.write(f\"Frame {frame_count} Homography Matrix:\\n\")\n","                output_file.write(str(transformer.m) + \"\\n\")\n","                output_file.write(\"-\" * 40 + \"\\n\")\n","\n","            # Transform the detected reference points\n","            transformed_points = transformer.transform_points(points=frame_reference_points)\n","\n","            # Store reference points for TSMAE calculation\n","            reference_points = {\n","                'transformed_pitch_coordinates': transformed_points,\n","                'ground_truth_pitch_coordinates': pitch_reference_points\n","            }\n","            all_reference_points.append(reference_points)\n","\n","            # Calculate TSMAE for the current frame\n","            tsmae = calculate_tsmae(transformed_points, pitch_reference_points)\n","            frame_tsmae_values.append(tsmae)\n","\n","            # Write reference points and their transformed positions to the file\n","            if frame_count % 10 == 0:\n","                output_file.write(f\"Frame {frame_count}:\\n\")\n","                for idx, (img_point, pitch_point, transformed_point) in enumerate(zip(frame_reference_points, pitch_reference_points, transformed_points)):\n","                    output_file.write(f\"Reference Point {idx}:\\n\")\n","                    output_file.write(f\"  Image Coordinates: {img_point}\\n\")\n","                    output_file.write(f\"  Ground Truth Pitch Coordinates: {pitch_point}\\n\")\n","                    output_file.write(f\"  Transformed Pitch Coordinates: {transformed_point}\\n\")\n","                    output_file.write(\"-\" * 20 + \"\\n\")\n","                output_file.write(f\"TSMAE for Frame {frame_count}: {tsmae}\\n\")\n","                output_file.write(\"=\" * 40 + \"\\n\")\n","\n","        # Calculate overall TSMAE across all frames\n","        if len(frame_tsmae_values) > 0:\n","            overall_tsmae = np.mean(frame_tsmae_values)\n","            output_file.write(f\"Overall TSMAE across all frames: {overall_tsmae}\\n\")\n","        else:\n","            output_file.write(\"No valid frames with reference points detected.\\n\")\n","            return\n","\n","        # Calculate TSMAE for each reference point across all frames\n","        if len(all_reference_points) > 0:\n","            # Find the minimum number of reference points across all frames\n","            min_reference_points = min(len(frame['transformed_pitch_coordinates']) for frame in all_reference_points)\n","\n","            reference_point_tsmae_values = []\n","            for idx in range(min_reference_points):\n","                transformed_points = np.array([frame['transformed_pitch_coordinates'][idx] for frame in all_reference_points if len(frame['transformed_pitch_coordinates']) > idx])\n","                ground_truth_points = np.array([frame['ground_truth_pitch_coordinates'][idx] for frame in all_reference_points if len(frame['ground_truth_pitch_coordinates']) > idx])\n","\n","                if len(transformed_points) > 0 and len(ground_truth_points) > 0:\n","                    tsmae = calculate_tsmae(transformed_points, ground_truth_points)\n","                    reference_point_tsmae_values.append(tsmae)\n","                    output_file.write(f\"TSMAE for Reference Point {idx}: {tsmae}\\n\")\n","                else:\n","                    output_file.write(f\"Reference Point {idx}: Not enough data to calculate TSMAE.\\n\")\n","        else:\n","            output_file.write(\"No reference points detected in any frame.\\n\")\n","\n","    # Plot TSMAE (in percentage) for each frame\n","    if len(frame_tsmae_values) > 0:\n","        plt.figure(figsize=(12, 6))\n","        plt.plot(range(len(frame_tsmae_values)), [tsmae * 100 for tsmae in frame_tsmae_values], marker='o', linestyle='-', color='b')\n","        plt.title(\"TSMAE (Transformation Similarity Mean Absolute Error) per Frame\")\n","        plt.xlabel(\"Frame Number\")\n","        plt.ylabel(\"TSMAE (%)\")\n","        plt.grid(True)\n","\n","        # Save the plot to a file in Google Drive\n","        plot_file_path = os.path.join(save_dir, \"tsmae_plot.png\")\n","        plt.savefig(plot_file_path)\n","        plt.show()\n","\n","    return overall_tsmae, frame_tsmae_values, reference_point_tsmae_values\n","\n","if __name__ == '__main__':\n","    test_homography_with_reference_points()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-yDDPBnguN8G","executionInfo":{"status":"ok","timestamp":1742829558594,"user_tz":240,"elapsed":51862,"user":{"displayName":"Liam John","userId":"06685647300504122282"}},"outputId":"c786bdba-592f-4938-e6e8-f733dae88bcd","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 1 pitch, 58.1ms\n","Speed: 3.5ms preprocess, 58.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.2ms preprocess, 40.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.3ms preprocess, 40.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.1ms preprocess, 39.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.3ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.0ms\n","Speed: 4.0ms preprocess, 35.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.3ms preprocess, 35.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.4ms preprocess, 36.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.2ms\n","Speed: 3.4ms preprocess, 34.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.6ms\n","Speed: 3.4ms preprocess, 34.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.1ms\n","Speed: 3.6ms preprocess, 35.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.1ms\n","Speed: 3.4ms preprocess, 36.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 5.0ms preprocess, 37.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 32.5ms\n","Speed: 5.6ms preprocess, 32.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.6ms\n","Speed: 3.4ms preprocess, 35.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.4ms\n","Speed: 3.3ms preprocess, 35.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.1ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.1ms\n","Speed: 3.4ms preprocess, 35.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 4.0ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.9ms\n","Speed: 3.5ms preprocess, 34.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.0ms\n","Speed: 4.7ms preprocess, 35.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.0ms\n","Speed: 7.8ms preprocess, 35.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 3.2ms preprocess, 36.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.9ms\n","Speed: 3.3ms preprocess, 35.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.3ms preprocess, 36.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.4ms preprocess, 37.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 4.0ms preprocess, 35.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 3.5ms preprocess, 36.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.3ms preprocess, 36.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 5.4ms preprocess, 40.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 31.9ms\n","Speed: 3.0ms preprocess, 31.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.3ms preprocess, 35.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.1ms preprocess, 37.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.4ms preprocess, 35.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.1ms preprocess, 36.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.4ms\n","Speed: 7.3ms preprocess, 35.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.7ms\n","Speed: 3.1ms preprocess, 34.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 3.1ms preprocess, 36.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 3.1ms preprocess, 35.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 3.1ms preprocess, 36.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 3.1ms preprocess, 35.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.3ms preprocess, 39.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.6ms\n","Speed: 4.7ms preprocess, 34.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.3ms\n","Speed: 4.2ms preprocess, 35.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.6ms\n","Speed: 3.4ms preprocess, 35.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.1ms preprocess, 35.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.7ms\n","Speed: 3.0ms preprocess, 34.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 3.3ms preprocess, 36.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.1ms preprocess, 35.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 3.0ms preprocess, 36.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.1ms\n","Speed: 2.9ms preprocess, 35.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.4ms\n","Speed: 3.3ms preprocess, 41.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.2ms\n","Speed: 3.1ms preprocess, 36.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.0ms\n","Speed: 3.1ms preprocess, 35.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 2.8ms preprocess, 35.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.3ms\n","Speed: 3.2ms preprocess, 36.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 3.7ms preprocess, 35.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.7ms preprocess, 37.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.1ms preprocess, 35.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 4.2ms preprocess, 36.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 4.3ms preprocess, 38.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.6ms\n","Speed: 4.7ms preprocess, 35.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.1ms\n","Speed: 5.6ms preprocess, 35.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.9ms preprocess, 37.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.3ms\n","Speed: 3.8ms preprocess, 35.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 4.1ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.5ms preprocess, 37.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.0ms\n","Speed: 3.5ms preprocess, 36.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.6ms preprocess, 37.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 3.7ms preprocess, 35.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.0ms\n","Speed: 3.1ms preprocess, 36.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 4.5ms preprocess, 37.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.1ms\n","Speed: 3.7ms preprocess, 35.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.8ms preprocess, 38.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 3.3ms preprocess, 35.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.1ms\n","Speed: 3.8ms preprocess, 36.1ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.7ms preprocess, 36.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 7.2ms preprocess, 35.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.4ms\n","Speed: 4.9ms preprocess, 35.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 6.1ms preprocess, 37.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.5ms\n","Speed: 4.5ms preprocess, 34.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.2ms\n","Speed: 3.8ms preprocess, 35.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.4ms preprocess, 36.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.8ms preprocess, 38.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.6ms preprocess, 36.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 4.2ms preprocess, 37.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.7ms preprocess, 36.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.8ms preprocess, 35.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 4.2ms preprocess, 37.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.5ms\n","Speed: 3.0ms preprocess, 34.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.2ms preprocess, 39.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.8ms\n","Speed: 3.1ms preprocess, 34.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.1ms preprocess, 37.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.8ms\n","Speed: 3.1ms preprocess, 34.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.0ms\n","Speed: 3.4ms preprocess, 35.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.9ms\n","Speed: 3.4ms preprocess, 34.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.6ms\n","Speed: 4.1ms preprocess, 42.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 4.6ms preprocess, 37.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.3ms preprocess, 35.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.2ms\n","Speed: 4.3ms preprocess, 36.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.3ms\n","Speed: 3.9ms preprocess, 35.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.9ms\n","Speed: 3.7ms preprocess, 35.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.9ms preprocess, 37.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 3.7ms preprocess, 35.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 3.3ms preprocess, 36.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.9ms\n","Speed: 3.0ms preprocess, 34.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.0ms\n","Speed: 2.9ms preprocess, 36.0ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 47.9ms\n","Speed: 6.4ms preprocess, 47.9ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.9ms\n","Speed: 6.1ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.2ms\n","Speed: 3.2ms preprocess, 36.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.7ms\n","Speed: 3.3ms preprocess, 34.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 31.8ms\n","Speed: 12.1ms preprocess, 31.8ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.7ms\n","Speed: 3.2ms preprocess, 41.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 60.5ms\n","Speed: 9.0ms preprocess, 60.5ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.4ms\n","Speed: 8.0ms preprocess, 42.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 51.8ms\n","Speed: 3.1ms preprocess, 51.8ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 55.8ms\n","Speed: 3.2ms preprocess, 55.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 45.8ms\n","Speed: 3.3ms preprocess, 45.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.0ms preprocess, 38.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 9.6ms preprocess, 36.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 3.6ms preprocess, 36.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.2ms\n","Speed: 3.4ms preprocess, 35.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 12.0ms preprocess, 40.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.4ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 3.0ms preprocess, 36.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.0ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.6ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.0ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.0ms preprocess, 37.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.1ms preprocess, 38.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.2ms preprocess, 37.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.0ms preprocess, 36.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.4ms preprocess, 38.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 3.2ms preprocess, 36.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.1ms\n","Speed: 3.2ms preprocess, 36.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 2.9ms preprocess, 37.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 2.9ms preprocess, 36.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.2ms preprocess, 36.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.1ms preprocess, 38.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 3.2ms preprocess, 36.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.6ms preprocess, 37.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.1ms preprocess, 38.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.4ms preprocess, 36.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.2ms preprocess, 37.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.0ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.1ms preprocess, 37.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.4ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 3.2ms preprocess, 36.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.4ms preprocess, 37.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.5ms preprocess, 38.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 3.1ms preprocess, 36.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.9ms\n","Speed: 4.3ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 5.1ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 4.1ms preprocess, 36.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.0ms\n","Speed: 5.2ms preprocess, 35.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.5ms\n","Speed: 3.0ms preprocess, 35.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.9ms preprocess, 37.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.0ms\n","Speed: 7.4ms preprocess, 36.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.3ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.2ms preprocess, 37.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.1ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.1ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.1ms preprocess, 37.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.2ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.1ms preprocess, 38.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 3.1ms preprocess, 36.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.0ms preprocess, 38.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 4.6ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.2ms\n","Speed: 5.0ms preprocess, 36.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.2ms preprocess, 35.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.0ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.5ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.4ms preprocess, 36.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.1ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.8ms preprocess, 37.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.4ms preprocess, 36.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.4ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.3ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.7ms\n","Speed: 3.1ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 34.7ms\n","Speed: 3.1ms preprocess, 34.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.2ms preprocess, 36.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.1ms preprocess, 37.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.1ms preprocess, 36.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.4ms preprocess, 37.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.2ms preprocess, 37.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.6ms preprocess, 38.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.3ms\n","Speed: 4.9ms preprocess, 35.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.7ms preprocess, 37.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.5ms preprocess, 37.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.5ms preprocess, 36.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.4ms preprocess, 38.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.8ms\n","Speed: 3.8ms preprocess, 35.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.0ms preprocess, 37.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.1ms\n","Speed: 4.1ms preprocess, 36.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 4.5ms preprocess, 37.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 35.6ms\n","Speed: 3.3ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 3.1ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 2.9ms preprocess, 39.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 2.3ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 2.5ms preprocess, 36.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 2.8ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.4ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 3.7ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.0ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 2.8ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.3ms\n","Speed: 4.2ms preprocess, 36.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 2.9ms preprocess, 37.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.6ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.1ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 2.9ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 5.1ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 2.9ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.0ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 4.1ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.5ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.2ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 2.5ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 4.5ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 2.9ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.6ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.2ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 4.2ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 2.9ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.0ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 2.7ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.0ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.1ms preprocess, 38.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.1ms preprocess, 37.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.3ms\n","Speed: 4.2ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.1ms preprocess, 39.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.6ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 3.2ms preprocess, 36.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.5ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 2.8ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.1ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.0ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.2ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.5ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 2.9ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 2.9ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 2.9ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.0ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.2ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 2.7ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.0ms preprocess, 37.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.6ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 4.1ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 2.4ms preprocess, 36.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.0ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.3ms preprocess, 38.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.7ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.1ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.2ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.1ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.3ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 3.3ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.1ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.4ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.2ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.3ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.3ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.4ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.8ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.1ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.0ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.8ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 6.0ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.0ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.0ms preprocess, 37.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 2.9ms preprocess, 38.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 2.9ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.0ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.0ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.1ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.5ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 4.1ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 2.8ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 4.4ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.2ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 3.6ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.5ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.1ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.4ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.1ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.2ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.7ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.5ms preprocess, 37.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.2ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.5ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.4ms preprocess, 37.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 4.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.1ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 2.6ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.3ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.4ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.3ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 5.1ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.6ms preprocess, 36.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.6ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.2ms preprocess, 39.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.3ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.1ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.0ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.1ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.1ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.2ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.7ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 4.9ms preprocess, 36.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.2ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.4ms preprocess, 37.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 4.1ms preprocess, 37.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.1ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 2.9ms preprocess, 37.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.5ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 5.6ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.5ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.9ms preprocess, 38.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.2ms preprocess, 37.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.4ms\n","Speed: 3.6ms preprocess, 36.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.7ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 2.8ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 2.9ms preprocess, 36.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 5.5ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 2.6ms preprocess, 36.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.4ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.6ms\n","Speed: 6.2ms preprocess, 36.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.8ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.1ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.0ms preprocess, 37.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.4ms preprocess, 37.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.0ms preprocess, 38.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 2.8ms preprocess, 37.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.6ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 4.4ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.2ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 4.1ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.7ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.9ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 4.0ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 4.2ms preprocess, 36.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 4.1ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.8ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 4.0ms preprocess, 37.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 4.8ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 2.7ms preprocess, 37.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 4.0ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 4.5ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 4.2ms preprocess, 36.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 5.4ms preprocess, 37.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.0ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 4.8ms preprocess, 36.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.3ms preprocess, 38.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.3ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.5ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.5ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.5ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.4ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.4ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.7ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.5ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.4ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.3ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.4ms preprocess, 37.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.4ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.3ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.4ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.4ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.3ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 4.1ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 2.6ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.7ms preprocess, 37.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 4.1ms preprocess, 38.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.4ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 3.5ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.4ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.8ms preprocess, 37.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.1ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.5ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.2ms preprocess, 37.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.6ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.2ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.3ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 2.9ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.2ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.1ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.0ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.2ms preprocess, 37.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.2ms preprocess, 37.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 4.2ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.1ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 5.8ms preprocess, 37.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.2ms\n","Speed: 5.2ms preprocess, 36.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.6ms preprocess, 38.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.2ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.0ms preprocess, 37.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.9ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.1ms preprocess, 37.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 4.3ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.2ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 2.9ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.1ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 2.9ms preprocess, 39.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.4ms preprocess, 37.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.8ms preprocess, 38.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.4ms preprocess, 37.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.3ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.4ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.2ms preprocess, 38.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.4ms preprocess, 38.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.2ms preprocess, 37.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.4ms preprocess, 38.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.5ms preprocess, 39.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.4ms preprocess, 38.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 4.3ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 5.7ms preprocess, 36.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.6ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.5ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.3ms preprocess, 37.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.3ms preprocess, 37.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.2ms\n","Speed: 5.5ms preprocess, 36.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 4.1ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.3ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 3.3ms preprocess, 36.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.2ms preprocess, 37.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.3ms preprocess, 38.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.2ms preprocess, 40.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.2ms preprocess, 37.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 4.3ms preprocess, 36.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.3ms\n","Speed: 3.4ms preprocess, 36.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.2ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 5.5ms preprocess, 37.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 4.3ms preprocess, 39.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.3ms preprocess, 37.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.3ms preprocess, 39.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.3ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.4ms preprocess, 40.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.4ms preprocess, 37.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 3.5ms preprocess, 36.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.6ms preprocess, 38.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.6ms preprocess, 40.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 3.8ms preprocess, 36.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.5ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.6ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.0ms preprocess, 37.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.0ms preprocess, 38.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.1ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.2ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.3ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.3ms preprocess, 40.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.4ms preprocess, 38.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.2ms preprocess, 39.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 4.2ms preprocess, 37.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.3ms preprocess, 38.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.3ms preprocess, 39.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.2ms preprocess, 39.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.0ms preprocess, 37.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.1ms preprocess, 38.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.9ms preprocess, 39.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.7ms preprocess, 39.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.7ms preprocess, 40.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.5ms\n","Speed: 3.7ms preprocess, 36.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.6ms preprocess, 40.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.6ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.3ms preprocess, 39.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.7ms preprocess, 38.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.8ms preprocess, 38.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.7ms preprocess, 38.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 4.8ms preprocess, 37.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.2ms preprocess, 39.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.4ms preprocess, 37.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.4ms preprocess, 39.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.2ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 2.9ms preprocess, 38.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.1ms\n","Speed: 3.3ms preprocess, 41.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.4ms preprocess, 37.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.1ms preprocess, 39.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.1ms preprocess, 38.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.4ms preprocess, 39.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.2ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.3ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.3ms\n","Speed: 3.0ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.8ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.1ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 2.9ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.0ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 2.8ms preprocess, 38.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.7ms preprocess, 37.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.2ms preprocess, 40.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.7ms preprocess, 37.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.4ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.4ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.5ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.1ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.4ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.1ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.1ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.4ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.2ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.1ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.5ms preprocess, 38.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.2ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.8ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.5ms preprocess, 40.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 4.0ms preprocess, 37.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.6ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 4.3ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.6ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.2ms preprocess, 40.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.4ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.2ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.4ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.2ms preprocess, 37.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.8ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 2.6ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.2ms preprocess, 38.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.2ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.2ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.5ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.3ms\n","Speed: 3.3ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.3ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.3ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.3ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.5ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.4ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 4.1ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.5ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.7ms preprocess, 39.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.5ms preprocess, 37.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 5.5ms preprocess, 39.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 4.1ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.5ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.5ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.7ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.3ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.1ms preprocess, 37.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.4ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.5ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.3ms preprocess, 40.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.3ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 4.1ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 4.4ms preprocess, 39.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.2ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.5ms preprocess, 40.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.5ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.4ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.2ms preprocess, 40.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.7ms preprocess, 38.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 4.2ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 4.0ms preprocess, 37.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 4.2ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 4.0ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.5ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.3ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.5ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.2ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.3ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 4.1ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.1ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.4ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.5ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.3ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.4ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.5ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.1ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.5ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.3ms preprocess, 40.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.5ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.9ms preprocess, 38.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.5ms preprocess, 40.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.6ms preprocess, 37.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.2ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 4.3ms preprocess, 37.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.4ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.0ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.5ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.2ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.2ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.4ms\n","Speed: 3.4ms preprocess, 41.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.6ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.2ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.2ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 4.4ms preprocess, 36.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.4ms preprocess, 40.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.0ms preprocess, 38.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.6ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 4.7ms preprocess, 38.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.4ms preprocess, 37.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 6.2ms preprocess, 37.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 4.1ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.2ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 4.5ms preprocess, 37.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 4.0ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.5ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.6ms\n","Speed: 3.3ms preprocess, 41.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.3ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.3ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.4ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.8ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.3ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.5ms\n","Speed: 3.0ms preprocess, 41.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.1ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.8ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.5ms\n","Speed: 3.2ms preprocess, 41.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.9ms preprocess, 37.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.5ms preprocess, 38.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 2.9ms preprocess, 38.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.4ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.8ms preprocess, 37.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 2.5ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.1ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.3ms preprocess, 39.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.3ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.5ms preprocess, 38.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.6ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.3ms preprocess, 38.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.5ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.9ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.1ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.2ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.4ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.7ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.9ms preprocess, 39.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.8ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.2ms preprocess, 40.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.5ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 2.9ms preprocess, 40.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 4.9ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.8ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.4ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.6ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.1ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.0ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.2ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.2ms preprocess, 39.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 4.7ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.1ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.6ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.8ms preprocess, 38.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 4.0ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.7ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.5ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.4ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.4ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 4.7ms preprocess, 39.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.3ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 4.9ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.4ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.0ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.3ms\n","Speed: 3.3ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.1ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 4.1ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 4.2ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.1ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.3ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.3ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.0ms preprocess, 38.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.1ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.1ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.3ms\n","Speed: 3.2ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.3ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.2ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.5ms\n","Speed: 3.6ms preprocess, 41.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 4.4ms preprocess, 38.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.1ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.4ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.3ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 4.0ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 4.0ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.6ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.7ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.2ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.3ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.1ms preprocess, 39.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.2ms preprocess, 39.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.1ms preprocess, 39.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.5ms preprocess, 40.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.2ms preprocess, 38.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.6ms preprocess, 39.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.6ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.3ms preprocess, 38.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.1ms preprocess, 40.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.4ms preprocess, 37.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.5ms preprocess, 38.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.1ms preprocess, 39.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 4.8ms preprocess, 38.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.3ms preprocess, 39.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.1ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.0ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.0ms preprocess, 40.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.1ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.1ms preprocess, 40.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.3ms preprocess, 39.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.5ms preprocess, 38.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.7ms preprocess, 40.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.7ms preprocess, 38.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 5.3ms preprocess, 40.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.6ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.5ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["06942d01e6b442c488deeca868e36516","6d9e03e8fd374da2b57a837607efa407","4e7019bf8b7341c8b1752f68e4d7b05e","ec03d7a0232e4d9b8f555bf8a75fae69","437d5a85834a48d2b3a9eed6cfb09672","bc3c59ba17cd44b582e73b5fcadd57a0","c329197ce17743f28355b5544de1e41c","3a8bec973ebf4b84872ec4fd0ba057ab","f6fba0f26ef54c2c8659d68637bad77b","625f96cb7ae148f28c0f15bc81fd2971","50f01f7f6893439891a8e020d8f655c2","979e92cb7703444fa6e35ff8b7975aca","907c967e232f4560a1fa0fd4d36a973e","fb0d698459974939914e0391abc87a50","d5320351a0174162b8ffe9fec696164f","f4205447f61146a698dc75844963b17a","34a39dd49a5c446680d010b283fc2879","d62940ab184c47d791d265240ac95ea4","28c6bc2ae8da4732947674e79f133863","9742b201b9ca40ac8d55b9326f7b8586","49d0a178eb1848b192f4a604712e3ff9","85ea3182a168450c8dc66911f7a7dbcb"]},"id":"X8Ua5aidp0bg","outputId":"33dcdc1e-993c-4da0-afd7-7c9ad8317846","executionInfo":{"status":"ok","timestamp":1742913002491,"user_tz":240,"elapsed":369589,"user":{"displayName":"Liam John","userId":"06685647300504122282"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06942d01e6b442c488deeca868e36516"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/64.1M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"979e92cb7703444fa6e35ff8b7975aca"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 123.0ms\n","Speed: 26.9ms preprocess, 123.0ms inference, 373.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 1 referee, 118.4ms\n","Speed: 13.1ms preprocess, 118.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 120.6ms\n","Speed: 7.7ms preprocess, 120.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 107.6ms\n","Speed: 9.0ms preprocess, 107.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 1 referee, 122.3ms\n","Speed: 9.4ms preprocess, 122.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 1 referee, 121.4ms\n","Speed: 7.7ms preprocess, 121.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 118.3ms\n","Speed: 8.4ms preprocess, 118.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 18 players, 2 referees, 125.5ms\n","Speed: 8.1ms preprocess, 125.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 1 referee, 124.4ms\n","Speed: 7.6ms preprocess, 124.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 18 players, 2 referees, 121.7ms\n","Speed: 8.6ms preprocess, 121.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 123.0ms\n","Speed: 8.8ms preprocess, 123.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 18 players, 3 referees, 121.8ms\n","Speed: 7.9ms preprocess, 121.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 121.9ms\n","Speed: 7.6ms preprocess, 121.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 123.2ms\n","Speed: 8.9ms preprocess, 123.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 123.2ms\n","Speed: 7.1ms preprocess, 123.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 122.2ms\n","Speed: 8.1ms preprocess, 122.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 121.7ms\n","Speed: 7.6ms preprocess, 121.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 120.2ms\n","Speed: 10.7ms preprocess, 120.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 123.1ms\n","Speed: 7.3ms preprocess, 123.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 122.9ms\n","Speed: 8.0ms preprocess, 122.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 122.3ms\n","Speed: 7.9ms preprocess, 122.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 122.3ms\n","Speed: 7.3ms preprocess, 122.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 1 referee, 122.2ms\n","Speed: 7.6ms preprocess, 122.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 16 players, 3 referees, 124.0ms\n","Speed: 8.3ms preprocess, 124.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 16 players, 2 referees, 122.2ms\n","Speed: 7.3ms preprocess, 122.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 16 players, 121.7ms\n","Speed: 7.7ms preprocess, 121.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 122.9ms\n","Speed: 7.6ms preprocess, 122.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 1 referee, 123.7ms\n","Speed: 8.6ms preprocess, 123.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 18 players, 2 referees, 121.8ms\n","Speed: 11.7ms preprocess, 121.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 1 referee, 122.8ms\n","Speed: 9.0ms preprocess, 122.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 121.7ms\n","Speed: 7.8ms preprocess, 121.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 17 players, 3 referees, 122.3ms\n","Speed: 7.5ms preprocess, 122.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 123.8ms\n","Speed: 8.0ms preprocess, 123.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 123.2ms\n","Speed: 9.7ms preprocess, 123.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 18 players, 122.7ms\n","Speed: 7.9ms preprocess, 122.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 122.7ms\n","Speed: 10.8ms preprocess, 122.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 18 players, 2 referees, 122.3ms\n","Speed: 8.9ms preprocess, 122.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 1 referee, 121.6ms\n","Speed: 7.6ms preprocess, 121.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 17 players, 2 referees, 121.1ms\n","Speed: 13.2ms preprocess, 121.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 15 players, 3 referees, 124.2ms\n","Speed: 8.4ms preprocess, 124.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 17 players, 2 referees, 123.7ms\n","Speed: 7.8ms preprocess, 123.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 17 players, 1 referee, 122.8ms\n","Speed: 8.9ms preprocess, 122.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 122.7ms\n","Speed: 8.1ms preprocess, 122.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 122.8ms\n","Speed: 7.7ms preprocess, 122.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 19 players, 1 referee, 124.5ms\n","Speed: 8.4ms preprocess, 124.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 19 players, 1 referee, 124.1ms\n","Speed: 8.1ms preprocess, 124.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 122.8ms\n","Speed: 8.0ms preprocess, 122.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 21 players, 1 referee, 123.1ms\n","Speed: 8.3ms preprocess, 123.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 goalkeepers, 17 players, 1 referee, 123.5ms\n","Speed: 7.7ms preprocess, 123.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 18 players, 124.8ms\n","Speed: 8.5ms preprocess, 124.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 20 players, 123.1ms\n","Speed: 7.8ms preprocess, 123.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 19 players, 1 referee, 124.6ms\n","Speed: 8.2ms preprocess, 124.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 20 players, 1 referee, 122.2ms\n","Speed: 10.0ms preprocess, 122.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 23 players, 1 referee, 120.9ms\n","Speed: 11.1ms preprocess, 120.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 22 players, 2 referees, 121.8ms\n","Speed: 10.8ms preprocess, 121.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 121.5ms\n","Speed: 10.6ms preprocess, 121.5ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 18 players, 2 referees, 121.4ms\n","Speed: 11.8ms preprocess, 121.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 20 players, 2 referees, 121.7ms\n","Speed: 11.4ms preprocess, 121.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 121.6ms\n","Speed: 13.5ms preprocess, 121.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 121.6ms\n","Speed: 11.3ms preprocess, 121.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 122.6ms\n","Speed: 11.0ms preprocess, 122.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 122.6ms\n","Speed: 11.3ms preprocess, 122.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 122.8ms\n","Speed: 11.9ms preprocess, 122.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 122.0ms\n","Speed: 11.5ms preprocess, 122.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 122.7ms\n","Speed: 9.9ms preprocess, 122.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 123.3ms\n","Speed: 10.3ms preprocess, 123.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 121.7ms\n","Speed: 13.7ms preprocess, 121.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 120.9ms\n","Speed: 11.1ms preprocess, 120.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 121.3ms\n","Speed: 13.9ms preprocess, 121.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 122.4ms\n","Speed: 13.2ms preprocess, 122.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 1 referee, 122.9ms\n","Speed: 14.0ms preprocess, 122.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 122.4ms\n","Speed: 11.0ms preprocess, 122.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 122.1ms\n","Speed: 12.7ms preprocess, 122.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 121.6ms\n","Speed: 12.0ms preprocess, 121.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 121.9ms\n","Speed: 10.7ms preprocess, 121.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 122.1ms\n","Speed: 10.7ms preprocess, 122.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 122.0ms\n","Speed: 11.6ms preprocess, 122.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 122.4ms\n","Speed: 8.8ms preprocess, 122.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 124.3ms\n","Speed: 8.9ms preprocess, 124.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 126.3ms\n","Speed: 8.2ms preprocess, 126.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 124.3ms\n","Speed: 10.2ms preprocess, 124.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 125.3ms\n","Speed: 8.1ms preprocess, 125.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 124.7ms\n","Speed: 10.4ms preprocess, 124.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 1 referee, 124.9ms\n","Speed: 8.7ms preprocess, 124.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 1 referee, 124.8ms\n","Speed: 7.5ms preprocess, 124.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 124.6ms\n","Speed: 9.3ms preprocess, 124.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 124.6ms\n","Speed: 8.2ms preprocess, 124.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 124.1ms\n","Speed: 6.9ms preprocess, 124.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 1 referee, 122.8ms\n","Speed: 7.2ms preprocess, 122.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 124.1ms\n","Speed: 8.1ms preprocess, 124.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 121.8ms\n","Speed: 13.9ms preprocess, 121.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 123.4ms\n","Speed: 8.0ms preprocess, 123.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 123.6ms\n","Speed: 8.6ms preprocess, 123.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 1 referee, 125.4ms\n","Speed: 8.3ms preprocess, 125.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 126.3ms\n","Speed: 8.3ms preprocess, 126.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 126.0ms\n","Speed: 8.8ms preprocess, 126.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 125.0ms\n","Speed: 8.7ms preprocess, 125.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 125.8ms\n","Speed: 7.8ms preprocess, 125.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 3 referees, 125.0ms\n","Speed: 8.3ms preprocess, 125.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 125.5ms\n","Speed: 9.9ms preprocess, 125.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 125.5ms\n","Speed: 8.5ms preprocess, 125.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 123.1ms\n","Speed: 7.9ms preprocess, 123.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 123.9ms\n","Speed: 7.5ms preprocess, 123.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 123.2ms\n","Speed: 9.1ms preprocess, 123.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 125.7ms\n","Speed: 8.5ms preprocess, 125.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 126.3ms\n","Speed: 7.7ms preprocess, 126.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 3 referees, 125.8ms\n","Speed: 8.6ms preprocess, 125.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 4 referees, 125.9ms\n","Speed: 10.1ms preprocess, 125.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 125.5ms\n","Speed: 8.4ms preprocess, 125.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 3 referees, 125.8ms\n","Speed: 9.0ms preprocess, 125.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 125.7ms\n","Speed: 9.0ms preprocess, 125.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 125.4ms\n","Speed: 9.1ms preprocess, 125.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 125.1ms\n","Speed: 10.2ms preprocess, 125.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 1 referee, 124.6ms\n","Speed: 7.7ms preprocess, 124.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 124.9ms\n","Speed: 8.8ms preprocess, 124.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 3 referees, 124.2ms\n","Speed: 7.7ms preprocess, 124.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 3 referees, 124.3ms\n","Speed: 8.5ms preprocess, 124.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 4 referees, 124.1ms\n","Speed: 7.5ms preprocess, 124.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 123.4ms\n","Speed: 10.5ms preprocess, 123.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 124.7ms\n","Speed: 7.5ms preprocess, 124.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 125.8ms\n","Speed: 7.6ms preprocess, 125.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 1 referee, 124.8ms\n","Speed: 10.2ms preprocess, 124.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 3 referees, 125.2ms\n","Speed: 8.9ms preprocess, 125.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 125.8ms\n","Speed: 9.0ms preprocess, 125.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 3 referees, 126.6ms\n","Speed: 8.5ms preprocess, 126.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 4 referees, 127.4ms\n","Speed: 7.8ms preprocess, 127.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 4 referees, 126.6ms\n","Speed: 8.8ms preprocess, 126.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 3 referees, 125.3ms\n","Speed: 7.8ms preprocess, 125.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 3 referees, 126.2ms\n","Speed: 9.6ms preprocess, 126.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 127.6ms\n","Speed: 8.4ms preprocess, 127.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 127.5ms\n","Speed: 8.5ms preprocess, 127.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 126.4ms\n","Speed: 8.7ms preprocess, 126.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 126.3ms\n","Speed: 7.9ms preprocess, 126.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 3 referees, 127.0ms\n","Speed: 8.2ms preprocess, 127.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 3 referees, 126.0ms\n","Speed: 9.4ms preprocess, 126.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 4 referees, 126.7ms\n","Speed: 10.0ms preprocess, 126.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 3 referees, 126.8ms\n","Speed: 8.1ms preprocess, 126.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 3 referees, 126.5ms\n","Speed: 7.6ms preprocess, 126.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 4 referees, 126.1ms\n","Speed: 9.0ms preprocess, 126.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 4 referees, 127.6ms\n","Speed: 9.1ms preprocess, 127.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 4 referees, 127.5ms\n","Speed: 8.7ms preprocess, 127.5ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 4 referees, 123.2ms\n","Speed: 14.9ms preprocess, 123.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 1 referee, 124.9ms\n","Speed: 10.2ms preprocess, 124.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 125.9ms\n","Speed: 8.2ms preprocess, 125.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 3 referees, 125.2ms\n","Speed: 7.7ms preprocess, 125.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 2 referees, 125.0ms\n","Speed: 7.4ms preprocess, 125.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 2 referees, 126.3ms\n","Speed: 8.3ms preprocess, 126.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 3 referees, 127.2ms\n","Speed: 7.4ms preprocess, 127.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 125.0ms\n","Speed: 11.1ms preprocess, 125.0ms inference, 4.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 2 referees, 118.5ms\n","Speed: 10.4ms preprocess, 118.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 3 referees, 124.1ms\n","Speed: 13.0ms preprocess, 124.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 3 referees, 123.6ms\n","Speed: 12.3ms preprocess, 123.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 3 referees, 123.5ms\n","Speed: 14.8ms preprocess, 123.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 4 referees, 124.4ms\n","Speed: 13.1ms preprocess, 124.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 4 referees, 125.7ms\n","Speed: 10.9ms preprocess, 125.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 3 referees, 123.6ms\n","Speed: 11.0ms preprocess, 123.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 14 players, 4 referees, 125.2ms\n","Speed: 10.4ms preprocess, 125.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 3 referees, 123.9ms\n","Speed: 11.8ms preprocess, 123.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 5 referees, 125.4ms\n","Speed: 12.1ms preprocess, 125.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 3 referees, 125.0ms\n","Speed: 12.1ms preprocess, 125.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 3 referees, 123.9ms\n","Speed: 10.9ms preprocess, 123.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 5 referees, 124.6ms\n","Speed: 10.3ms preprocess, 124.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 14 players, 2 referees, 124.9ms\n","Speed: 12.1ms preprocess, 124.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 2 referees, 107.9ms\n","Speed: 16.4ms preprocess, 107.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 128.4ms\n","Speed: 10.3ms preprocess, 128.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 14 players, 3 referees, 125.9ms\n","Speed: 13.1ms preprocess, 125.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 4 referees, 125.8ms\n","Speed: 12.5ms preprocess, 125.8ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 3 referees, 123.6ms\n","Speed: 10.7ms preprocess, 123.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 4 referees, 124.8ms\n","Speed: 10.2ms preprocess, 124.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 4 referees, 127.3ms\n","Speed: 7.9ms preprocess, 127.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 16 players, 4 referees, 125.6ms\n","Speed: 8.6ms preprocess, 125.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 4 referees, 125.8ms\n","Speed: 8.1ms preprocess, 125.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 4 referees, 125.2ms\n","Speed: 9.4ms preprocess, 125.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 17 players, 4 referees, 126.0ms\n","Speed: 9.5ms preprocess, 126.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 17 players, 4 referees, 126.1ms\n","Speed: 8.2ms preprocess, 126.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 4 referees, 126.3ms\n","Speed: 7.5ms preprocess, 126.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 3 referees, 126.9ms\n","Speed: 7.7ms preprocess, 126.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 5 referees, 126.3ms\n","Speed: 7.6ms preprocess, 126.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 3 referees, 127.1ms\n","Speed: 9.8ms preprocess, 127.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 4 referees, 127.2ms\n","Speed: 7.1ms preprocess, 127.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 4 referees, 126.3ms\n","Speed: 8.3ms preprocess, 126.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 4 referees, 127.0ms\n","Speed: 8.0ms preprocess, 127.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 3 referees, 126.8ms\n","Speed: 9.2ms preprocess, 126.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 3 referees, 125.9ms\n","Speed: 8.9ms preprocess, 125.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 4 referees, 125.0ms\n","Speed: 8.6ms preprocess, 125.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 3 referees, 126.9ms\n","Speed: 8.7ms preprocess, 126.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 17 players, 3 referees, 127.0ms\n","Speed: 8.3ms preprocess, 127.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 2 referees, 127.0ms\n","Speed: 8.6ms preprocess, 127.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 3 referees, 127.4ms\n","Speed: 9.4ms preprocess, 127.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 3 referees, 126.7ms\n","Speed: 8.9ms preprocess, 126.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 3 referees, 125.7ms\n","Speed: 9.2ms preprocess, 125.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 3 referees, 125.5ms\n","Speed: 10.3ms preprocess, 125.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 3 referees, 126.8ms\n","Speed: 8.7ms preprocess, 126.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 3 referees, 125.4ms\n","Speed: 9.0ms preprocess, 125.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 4 referees, 127.3ms\n","Speed: 8.2ms preprocess, 127.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 3 referees, 126.2ms\n","Speed: 8.0ms preprocess, 126.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 2 referees, 126.7ms\n","Speed: 8.5ms preprocess, 126.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 2 referees, 125.7ms\n","Speed: 8.5ms preprocess, 125.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 5 referees, 127.0ms\n","Speed: 7.9ms preprocess, 127.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 4 referees, 125.4ms\n","Speed: 13.4ms preprocess, 125.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 4 referees, 126.5ms\n","Speed: 9.8ms preprocess, 126.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 3 referees, 126.2ms\n","Speed: 8.6ms preprocess, 126.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 1 referee, 126.4ms\n","Speed: 8.4ms preprocess, 126.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 17 players, 1 referee, 126.3ms\n","Speed: 9.8ms preprocess, 126.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 17 players, 2 referees, 125.8ms\n","Speed: 9.1ms preprocess, 125.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 17 players, 3 referees, 126.8ms\n","Speed: 7.3ms preprocess, 126.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 21 players, 3 referees, 127.3ms\n","Speed: 10.6ms preprocess, 127.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 2 referees, 127.6ms\n","Speed: 8.6ms preprocess, 127.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 3 referees, 128.6ms\n","Speed: 7.7ms preprocess, 128.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 4 referees, 129.0ms\n","Speed: 9.6ms preprocess, 129.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 4 referees, 126.4ms\n","Speed: 8.6ms preprocess, 126.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 2 referees, 128.1ms\n","Speed: 9.3ms preprocess, 128.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 2 referees, 125.9ms\n","Speed: 9.7ms preprocess, 125.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 16 players, 3 referees, 126.5ms\n","Speed: 9.7ms preprocess, 126.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 15 players, 4 referees, 125.6ms\n","Speed: 7.9ms preprocess, 125.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 4 referees, 126.6ms\n","Speed: 7.9ms preprocess, 126.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 14 players, 4 referees, 125.3ms\n","Speed: 8.5ms preprocess, 125.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 15 players, 4 referees, 125.3ms\n","Speed: 8.9ms preprocess, 125.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 4 referees, 126.5ms\n","Speed: 7.0ms preprocess, 126.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 127.1ms\n","Speed: 9.4ms preprocess, 127.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 127.9ms\n","Speed: 8.7ms preprocess, 127.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 126.6ms\n","Speed: 8.1ms preprocess, 126.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 2 referees, 126.7ms\n","Speed: 9.8ms preprocess, 126.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 126.8ms\n","Speed: 7.7ms preprocess, 126.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 126.9ms\n","Speed: 9.1ms preprocess, 126.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 127.7ms\n","Speed: 10.0ms preprocess, 127.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 128.5ms\n","Speed: 7.3ms preprocess, 128.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 127.3ms\n","Speed: 7.8ms preprocess, 127.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 128.1ms\n","Speed: 8.8ms preprocess, 128.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 128.5ms\n","Speed: 10.6ms preprocess, 128.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 4 referees, 129.0ms\n","Speed: 8.8ms preprocess, 129.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 127.1ms\n","Speed: 8.1ms preprocess, 127.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 126.2ms\n","Speed: 13.5ms preprocess, 126.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 126.8ms\n","Speed: 9.2ms preprocess, 126.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 127.6ms\n","Speed: 8.9ms preprocess, 127.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 125.3ms\n","Speed: 13.1ms preprocess, 125.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 129.5ms\n","Speed: 9.5ms preprocess, 129.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 130.1ms\n","Speed: 8.8ms preprocess, 130.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 126.9ms\n","Speed: 9.4ms preprocess, 126.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 125.6ms\n","Speed: 10.4ms preprocess, 125.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 126.8ms\n","Speed: 13.5ms preprocess, 126.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 128.5ms\n","Speed: 11.3ms preprocess, 128.5ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 124.8ms\n","Speed: 15.1ms preprocess, 124.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 127.3ms\n","Speed: 10.2ms preprocess, 127.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 1 referee, 128.7ms\n","Speed: 10.4ms preprocess, 128.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 1 referee, 113.8ms\n","Speed: 10.2ms preprocess, 113.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 1 referee, 131.4ms\n","Speed: 13.2ms preprocess, 131.4ms inference, 4.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 127.7ms\n","Speed: 13.6ms preprocess, 127.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 128.4ms\n","Speed: 11.1ms preprocess, 128.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 130.0ms\n","Speed: 9.9ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 127.2ms\n","Speed: 10.5ms preprocess, 127.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 127.2ms\n","Speed: 9.5ms preprocess, 127.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 127.5ms\n","Speed: 9.7ms preprocess, 127.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 127.8ms\n","Speed: 9.7ms preprocess, 127.8ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 125.0ms\n","Speed: 12.0ms preprocess, 125.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 1 referee, 128.9ms\n","Speed: 10.3ms preprocess, 128.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 128.4ms\n","Speed: 10.2ms preprocess, 128.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 127.5ms\n","Speed: 9.6ms preprocess, 127.5ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 126.2ms\n","Speed: 17.2ms preprocess, 126.2ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 129.7ms\n","Speed: 12.3ms preprocess, 129.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 125.6ms\n","Speed: 16.7ms preprocess, 125.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 128.1ms\n","Speed: 9.3ms preprocess, 128.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 2 referees, 130.8ms\n","Speed: 9.2ms preprocess, 130.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 127.4ms\n","Speed: 9.6ms preprocess, 127.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 127.9ms\n","Speed: 8.4ms preprocess, 127.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 128.0ms\n","Speed: 9.1ms preprocess, 128.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 128.1ms\n","Speed: 12.1ms preprocess, 128.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 128.8ms\n","Speed: 10.3ms preprocess, 128.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 130.5ms\n","Speed: 7.9ms preprocess, 130.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 129.1ms\n","Speed: 9.5ms preprocess, 129.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 127.3ms\n","Speed: 8.2ms preprocess, 127.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 128.8ms\n","Speed: 9.5ms preprocess, 128.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 128.5ms\n","Speed: 10.2ms preprocess, 128.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 1 referee, 129.8ms\n","Speed: 8.7ms preprocess, 129.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 1 referee, 131.0ms\n","Speed: 9.5ms preprocess, 131.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 1 referee, 128.6ms\n","Speed: 9.5ms preprocess, 128.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 128.0ms\n","Speed: 9.3ms preprocess, 128.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 1 referee, 128.3ms\n","Speed: 9.2ms preprocess, 128.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 26 players, 1 referee, 128.6ms\n","Speed: 9.3ms preprocess, 128.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 129.3ms\n","Speed: 9.5ms preprocess, 129.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 129.9ms\n","Speed: 7.3ms preprocess, 129.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 131.1ms\n","Speed: 9.7ms preprocess, 131.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 128.4ms\n","Speed: 9.9ms preprocess, 128.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 127.8ms\n","Speed: 8.9ms preprocess, 127.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 128.2ms\n","Speed: 8.2ms preprocess, 128.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 128.8ms\n","Speed: 9.6ms preprocess, 128.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 129.5ms\n","Speed: 9.1ms preprocess, 129.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.2ms\n","Speed: 8.0ms preprocess, 130.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 129.0ms\n","Speed: 8.3ms preprocess, 129.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 128.6ms\n","Speed: 9.4ms preprocess, 128.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 128.1ms\n","Speed: 9.3ms preprocess, 128.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 127.9ms\n","Speed: 7.9ms preprocess, 127.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 128.8ms\n","Speed: 8.5ms preprocess, 128.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 2 referees, 131.5ms\n","Speed: 8.8ms preprocess, 131.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 2 referees, 129.9ms\n","Speed: 9.2ms preprocess, 129.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 128.6ms\n","Speed: 10.1ms preprocess, 128.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 2 referees, 128.7ms\n","Speed: 7.1ms preprocess, 128.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 2 referees, 129.7ms\n","Speed: 8.8ms preprocess, 129.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 129.8ms\n","Speed: 9.2ms preprocess, 129.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 131.4ms\n","Speed: 9.7ms preprocess, 131.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 128.8ms\n","Speed: 10.6ms preprocess, 128.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 128.2ms\n","Speed: 8.2ms preprocess, 128.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 129.7ms\n","Speed: 9.1ms preprocess, 129.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 130.7ms\n","Speed: 10.1ms preprocess, 130.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 131.3ms\n","Speed: 9.3ms preprocess, 131.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 128.1ms\n","Speed: 9.1ms preprocess, 128.1ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 129.0ms\n","Speed: 9.1ms preprocess, 129.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 3 referees, 130.0ms\n","Speed: 8.0ms preprocess, 130.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 129.3ms\n","Speed: 10.6ms preprocess, 129.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 131.3ms\n","Speed: 7.9ms preprocess, 131.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 129.3ms\n","Speed: 9.5ms preprocess, 129.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 129.2ms\n","Speed: 10.5ms preprocess, 129.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.2ms\n","Speed: 8.1ms preprocess, 130.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 130.0ms\n","Speed: 11.9ms preprocess, 130.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 129.1ms\n","Speed: 8.7ms preprocess, 129.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 129.2ms\n","Speed: 8.9ms preprocess, 129.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 129.9ms\n","Speed: 10.3ms preprocess, 129.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.2ms\n","Speed: 7.8ms preprocess, 132.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 129.9ms\n","Speed: 8.4ms preprocess, 129.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 129.0ms\n","Speed: 10.6ms preprocess, 129.0ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.2ms\n","Speed: 10.7ms preprocess, 130.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 131.0ms\n","Speed: 10.4ms preprocess, 131.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 128.4ms\n","Speed: 10.1ms preprocess, 128.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 129.2ms\n","Speed: 11.0ms preprocess, 129.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.8ms\n","Speed: 8.1ms preprocess, 132.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 130.0ms\n","Speed: 9.6ms preprocess, 130.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 2 referees, 130.7ms\n","Speed: 8.1ms preprocess, 130.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.0ms\n","Speed: 8.8ms preprocess, 132.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.7ms\n","Speed: 9.4ms preprocess, 132.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 129.2ms\n","Speed: 9.9ms preprocess, 129.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 129.6ms\n","Speed: 10.9ms preprocess, 129.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 130.7ms\n","Speed: 11.3ms preprocess, 130.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 130.0ms\n","Speed: 11.2ms preprocess, 130.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 130.2ms\n","Speed: 11.0ms preprocess, 130.2ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 131.0ms\n","Speed: 12.2ms preprocess, 131.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 23 players, 2 referees, 130.2ms\n","Speed: 12.9ms preprocess, 130.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 129.8ms\n","Speed: 12.6ms preprocess, 129.8ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 2 referees, 129.8ms\n","Speed: 11.8ms preprocess, 129.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 23 players, 2 referees, 129.2ms\n","Speed: 13.4ms preprocess, 129.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 2 referees, 130.0ms\n","Speed: 13.9ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 131.1ms\n","Speed: 12.1ms preprocess, 131.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 21 players, 2 referees, 131.6ms\n","Speed: 12.4ms preprocess, 131.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 2 referees, 130.5ms\n","Speed: 11.4ms preprocess, 130.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 21 players, 2 referees, 130.8ms\n","Speed: 11.5ms preprocess, 130.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.6ms\n","Speed: 11.9ms preprocess, 132.6ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 130.2ms\n","Speed: 12.0ms preprocess, 130.2ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 129.7ms\n","Speed: 12.7ms preprocess, 129.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 129.2ms\n","Speed: 13.0ms preprocess, 129.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.7ms\n","Speed: 11.2ms preprocess, 130.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 131.4ms\n","Speed: 12.2ms preprocess, 131.4ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 129.5ms\n","Speed: 12.7ms preprocess, 129.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 131.2ms\n","Speed: 10.0ms preprocess, 131.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 133.8ms\n","Speed: 9.1ms preprocess, 133.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.4ms\n","Speed: 8.8ms preprocess, 130.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.3ms\n","Speed: 8.1ms preprocess, 132.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 141.5ms\n","Speed: 10.6ms preprocess, 141.5ms inference, 4.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 127.4ms\n","Speed: 14.1ms preprocess, 127.4ms inference, 9.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 128.7ms\n","Speed: 16.7ms preprocess, 128.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.5ms\n","Speed: 10.5ms preprocess, 130.5ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 129.2ms\n","Speed: 11.2ms preprocess, 129.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 130.6ms\n","Speed: 19.2ms preprocess, 130.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 131.4ms\n","Speed: 10.6ms preprocess, 131.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 140.9ms\n","Speed: 17.6ms preprocess, 140.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 131.8ms\n","Speed: 9.8ms preprocess, 131.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.9ms\n","Speed: 8.5ms preprocess, 130.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.6ms\n","Speed: 10.2ms preprocess, 132.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 134.4ms\n","Speed: 10.1ms preprocess, 134.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 131.3ms\n","Speed: 8.3ms preprocess, 131.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.1ms\n","Speed: 13.0ms preprocess, 132.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.7ms\n","Speed: 8.0ms preprocess, 130.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 131.4ms\n","Speed: 10.4ms preprocess, 131.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.0ms\n","Speed: 8.4ms preprocess, 132.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 131.3ms\n","Speed: 10.6ms preprocess, 131.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 136.8ms\n","Speed: 10.0ms preprocess, 136.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 133.8ms\n","Speed: 8.9ms preprocess, 133.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 131.0ms\n","Speed: 10.5ms preprocess, 131.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.4ms\n","Speed: 9.7ms preprocess, 132.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.9ms\n","Speed: 9.4ms preprocess, 132.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 131.0ms\n","Speed: 9.7ms preprocess, 131.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 131.8ms\n","Speed: 10.4ms preprocess, 131.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 24 players, 2 referees, 133.0ms\n","Speed: 10.2ms preprocess, 133.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.1ms\n","Speed: 8.4ms preprocess, 132.1ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.3ms\n","Speed: 9.9ms preprocess, 132.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 134.4ms\n","Speed: 8.9ms preprocess, 134.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.9ms\n","Speed: 8.5ms preprocess, 132.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 132.9ms\n","Speed: 9.0ms preprocess, 132.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.8ms\n","Speed: 9.3ms preprocess, 130.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.0ms\n","Speed: 9.9ms preprocess, 132.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 133.2ms\n","Speed: 10.2ms preprocess, 133.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.1ms\n","Speed: 19.1ms preprocess, 130.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 133.8ms\n","Speed: 9.1ms preprocess, 133.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 131.8ms\n","Speed: 10.0ms preprocess, 131.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 131.9ms\n","Speed: 9.1ms preprocess, 131.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 133.6ms\n","Speed: 8.8ms preprocess, 133.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 130.9ms\n","Speed: 10.5ms preprocess, 130.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 133.1ms\n","Speed: 10.2ms preprocess, 133.1ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.5ms\n","Speed: 11.1ms preprocess, 132.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 131.5ms\n","Speed: 24.7ms preprocess, 131.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 136.3ms\n","Speed: 21.3ms preprocess, 136.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 137.9ms\n","Speed: 27.8ms preprocess, 137.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 127.3ms\n","Speed: 31.2ms preprocess, 127.3ms inference, 10.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 129.2ms\n","Speed: 29.8ms preprocess, 129.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 129.5ms\n","Speed: 12.2ms preprocess, 129.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 129.8ms\n","Speed: 25.5ms preprocess, 129.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 133.4ms\n","Speed: 9.8ms preprocess, 133.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 2 referees, 133.7ms\n","Speed: 10.2ms preprocess, 133.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 2 referees, 138.2ms\n","Speed: 9.1ms preprocess, 138.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 24 players, 2 referees, 131.9ms\n","Speed: 10.4ms preprocess, 131.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 25 players, 2 referees, 132.4ms\n","Speed: 9.8ms preprocess, 132.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 25 players, 2 referees, 134.3ms\n","Speed: 11.5ms preprocess, 134.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 1 referee, 131.5ms\n","Speed: 8.6ms preprocess, 131.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 1 referee, 133.3ms\n","Speed: 8.7ms preprocess, 133.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 132.4ms\n","Speed: 9.6ms preprocess, 132.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 131.9ms\n","Speed: 14.9ms preprocess, 131.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 131.4ms\n","Speed: 9.4ms preprocess, 131.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 1 referee, 133.6ms\n","Speed: 12.2ms preprocess, 133.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 1 referee, 132.5ms\n","Speed: 10.9ms preprocess, 132.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 1 referee, 132.7ms\n","Speed: 13.7ms preprocess, 132.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 133.2ms\n","Speed: 11.1ms preprocess, 133.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 134.0ms\n","Speed: 10.3ms preprocess, 134.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 1 referee, 131.7ms\n","Speed: 13.9ms preprocess, 131.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 135.5ms\n","Speed: 10.5ms preprocess, 135.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 134.1ms\n","Speed: 9.8ms preprocess, 134.1ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 132.9ms\n","Speed: 11.5ms preprocess, 132.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.1ms\n","Speed: 12.3ms preprocess, 132.1ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 132.6ms\n","Speed: 9.4ms preprocess, 132.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 1 referee, 132.2ms\n","Speed: 14.9ms preprocess, 132.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.9ms\n","Speed: 10.0ms preprocess, 132.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 133.1ms\n","Speed: 10.2ms preprocess, 133.1ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 24 players, 1 referee, 134.8ms\n","Speed: 10.3ms preprocess, 134.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.5ms\n","Speed: 15.6ms preprocess, 132.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 2 referees, 134.4ms\n","Speed: 10.7ms preprocess, 134.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 2 referees, 134.9ms\n","Speed: 10.0ms preprocess, 134.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 2 referees, 131.3ms\n","Speed: 14.5ms preprocess, 131.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 2 referees, 132.9ms\n","Speed: 10.8ms preprocess, 132.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 2 referees, 135.1ms\n","Speed: 11.6ms preprocess, 135.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 25 players, 2 referees, 133.5ms\n","Speed: 15.4ms preprocess, 133.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 2 referees, 133.8ms\n","Speed: 10.2ms preprocess, 133.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 2 referees, 134.5ms\n","Speed: 9.9ms preprocess, 134.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 135.7ms\n","Speed: 10.3ms preprocess, 135.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 135.1ms\n","Speed: 8.4ms preprocess, 135.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 136.7ms\n","Speed: 10.7ms preprocess, 136.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 133.4ms\n","Speed: 7.7ms preprocess, 133.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 135.6ms\n","Speed: 10.2ms preprocess, 135.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 133.7ms\n","Speed: 9.9ms preprocess, 133.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 132.5ms\n","Speed: 12.3ms preprocess, 132.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 2 referees, 134.7ms\n","Speed: 11.2ms preprocess, 134.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 135.0ms\n","Speed: 11.3ms preprocess, 135.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 134.5ms\n","Speed: 8.8ms preprocess, 134.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 135.1ms\n","Speed: 10.9ms preprocess, 135.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 136.3ms\n","Speed: 10.0ms preprocess, 136.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 135.3ms\n","Speed: 10.3ms preprocess, 135.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 135.3ms\n","Speed: 8.8ms preprocess, 135.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 135.4ms\n","Speed: 8.7ms preprocess, 135.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 135.2ms\n","Speed: 12.6ms preprocess, 135.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 134.3ms\n","Speed: 12.5ms preprocess, 134.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 21 players, 2 referees, 138.0ms\n","Speed: 9.6ms preprocess, 138.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 1 referee, 135.5ms\n","Speed: 9.8ms preprocess, 135.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 1 referee, 134.2ms\n","Speed: 8.9ms preprocess, 134.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 135.8ms\n","Speed: 10.0ms preprocess, 135.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 135.6ms\n","Speed: 11.0ms preprocess, 135.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 24 players, 135.2ms\n","Speed: 10.0ms preprocess, 135.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 2 referees, 135.2ms\n","Speed: 11.1ms preprocess, 135.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 2 referees, 138.7ms\n","Speed: 10.5ms preprocess, 138.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 135.6ms\n","Speed: 11.1ms preprocess, 135.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 21 players, 2 referees, 135.2ms\n","Speed: 8.4ms preprocess, 135.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 135.7ms\n","Speed: 10.6ms preprocess, 135.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 1 referee, 134.7ms\n","Speed: 11.6ms preprocess, 134.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 21 players, 1 referee, 135.0ms\n","Speed: 9.6ms preprocess, 135.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 1 referee, 134.1ms\n","Speed: 9.6ms preprocess, 134.1ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 135.7ms\n","Speed: 10.7ms preprocess, 135.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 136.6ms\n","Speed: 8.1ms preprocess, 136.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 136.9ms\n","Speed: 9.4ms preprocess, 136.9ms inference, 3.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 1 referee, 134.9ms\n","Speed: 15.9ms preprocess, 134.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 1 referee, 137.0ms\n","Speed: 8.5ms preprocess, 137.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 133.8ms\n","Speed: 10.9ms preprocess, 133.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 136.2ms\n","Speed: 10.4ms preprocess, 136.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 133.9ms\n","Speed: 10.8ms preprocess, 133.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 138.8ms\n","Speed: 8.3ms preprocess, 138.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 136.2ms\n","Speed: 11.3ms preprocess, 136.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 136.7ms\n","Speed: 7.8ms preprocess, 136.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 137.2ms\n","Speed: 12.1ms preprocess, 137.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 120.0ms\n","Speed: 9.9ms preprocess, 120.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 145.6ms\n","Speed: 9.7ms preprocess, 145.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 2 referees, 137.8ms\n","Speed: 11.3ms preprocess, 137.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 138.0ms\n","Speed: 11.0ms preprocess, 138.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 2 referees, 138.5ms\n","Speed: 11.3ms preprocess, 138.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 136.4ms\n","Speed: 10.7ms preprocess, 136.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 137.1ms\n","Speed: 10.3ms preprocess, 137.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 135.8ms\n","Speed: 11.1ms preprocess, 135.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 2 referees, 137.2ms\n","Speed: 10.9ms preprocess, 137.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 2 referees, 138.1ms\n","Speed: 10.3ms preprocess, 138.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 24 players, 2 referees, 136.2ms\n","Speed: 10.5ms preprocess, 136.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 2 referees, 139.2ms\n","Speed: 10.5ms preprocess, 139.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 3 referees, 138.2ms\n","Speed: 9.8ms preprocess, 138.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 135.0ms\n","Speed: 11.2ms preprocess, 135.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 138.0ms\n","Speed: 10.8ms preprocess, 138.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 138.0ms\n","Speed: 9.1ms preprocess, 138.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 3 referees, 138.0ms\n","Speed: 9.8ms preprocess, 138.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 138.4ms\n","Speed: 10.0ms preprocess, 138.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 3 referees, 136.8ms\n","Speed: 9.8ms preprocess, 136.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 3 referees, 138.5ms\n","Speed: 9.2ms preprocess, 138.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 138.4ms\n","Speed: 10.5ms preprocess, 138.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 136.7ms\n","Speed: 14.0ms preprocess, 136.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 3 referees, 134.8ms\n","Speed: 11.6ms preprocess, 134.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 137.9ms\n","Speed: 11.2ms preprocess, 137.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 136.7ms\n","Speed: 11.8ms preprocess, 136.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 3 referees, 137.3ms\n","Speed: 10.9ms preprocess, 137.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 3 referees, 137.1ms\n","Speed: 14.3ms preprocess, 137.1ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 136.0ms\n","Speed: 14.7ms preprocess, 136.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 133.9ms\n","Speed: 14.5ms preprocess, 133.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 137.4ms\n","Speed: 12.1ms preprocess, 137.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 3 referees, 136.1ms\n","Speed: 11.9ms preprocess, 136.1ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 3 referees, 136.1ms\n","Speed: 16.6ms preprocess, 136.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 138.1ms\n","Speed: 10.7ms preprocess, 138.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 2 goalkeepers, 20 players, 3 referees, 137.5ms\n","Speed: 11.4ms preprocess, 137.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 135.6ms\n","Speed: 18.1ms preprocess, 135.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 18 players, 3 referees, 135.1ms\n","Speed: 15.4ms preprocess, 135.1ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 3 referees, 135.1ms\n","Speed: 14.6ms preprocess, 135.1ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 138.4ms\n","Speed: 11.1ms preprocess, 138.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 3 referees, 145.2ms\n","Speed: 14.6ms preprocess, 145.2ms inference, 4.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 137.5ms\n","Speed: 11.6ms preprocess, 137.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 138.8ms\n","Speed: 7.7ms preprocess, 138.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 140.5ms\n","Speed: 10.7ms preprocess, 140.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 3 referees, 140.8ms\n","Speed: 11.7ms preprocess, 140.8ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 24 players, 2 referees, 136.5ms\n","Speed: 11.0ms preprocess, 136.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 141.3ms\n","Speed: 10.5ms preprocess, 141.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 135.5ms\n","Speed: 11.5ms preprocess, 135.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 1 referee, 139.0ms\n","Speed: 12.1ms preprocess, 139.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 2 referees, 139.8ms\n","Speed: 10.7ms preprocess, 139.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 140.4ms\n","Speed: 10.4ms preprocess, 140.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 140.6ms\n","Speed: 10.4ms preprocess, 140.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 19 players, 4 referees, 141.7ms\n","Speed: 10.6ms preprocess, 141.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 4 referees, 139.7ms\n","Speed: 9.5ms preprocess, 139.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 138.7ms\n","Speed: 11.2ms preprocess, 138.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 139.5ms\n","Speed: 9.9ms preprocess, 139.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 140.1ms\n","Speed: 10.9ms preprocess, 140.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 140.8ms\n","Speed: 11.1ms preprocess, 140.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 19 players, 3 referees, 140.9ms\n","Speed: 11.0ms preprocess, 140.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 19 players, 3 referees, 141.0ms\n","Speed: 10.8ms preprocess, 141.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 140.4ms\n","Speed: 9.1ms preprocess, 140.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 139.8ms\n","Speed: 11.0ms preprocess, 139.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 3 referees, 138.4ms\n","Speed: 16.0ms preprocess, 138.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 140.1ms\n","Speed: 12.4ms preprocess, 140.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 139.0ms\n","Speed: 11.0ms preprocess, 139.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 139.5ms\n","Speed: 10.5ms preprocess, 139.5ms inference, 3.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 3 referees, 139.1ms\n","Speed: 10.8ms preprocess, 139.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 3 referees, 144.4ms\n","Speed: 10.3ms preprocess, 144.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 141.5ms\n","Speed: 10.6ms preprocess, 141.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 141.5ms\n","Speed: 9.8ms preprocess, 141.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 2 referees, 140.6ms\n","Speed: 12.1ms preprocess, 140.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 140.2ms\n","Speed: 10.4ms preprocess, 140.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 19 players, 1 referee, 139.8ms\n","Speed: 10.9ms preprocess, 139.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 19 players, 3 referees, 142.2ms\n","Speed: 12.2ms preprocess, 142.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 140.0ms\n","Speed: 10.8ms preprocess, 140.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 141.6ms\n","Speed: 11.0ms preprocess, 141.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 3 referees, 140.4ms\n","Speed: 11.1ms preprocess, 140.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 3 referees, 138.4ms\n","Speed: 10.9ms preprocess, 138.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 4 referees, 143.1ms\n","Speed: 10.3ms preprocess, 143.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 18 players, 4 referees, 142.5ms\n","Speed: 10.8ms preprocess, 142.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 18 players, 3 referees, 140.3ms\n","Speed: 9.4ms preprocess, 140.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 18 players, 1 referee, 142.1ms\n","Speed: 10.1ms preprocess, 142.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 4 referees, 140.5ms\n","Speed: 16.1ms preprocess, 140.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 140.2ms\n","Speed: 12.7ms preprocess, 140.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 142.6ms\n","Speed: 9.7ms preprocess, 142.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 3 referees, 141.8ms\n","Speed: 10.0ms preprocess, 141.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 4 referees, 142.9ms\n","Speed: 8.7ms preprocess, 142.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 142.7ms\n","Speed: 9.4ms preprocess, 142.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 21 players, 3 referees, 143.6ms\n","Speed: 11.0ms preprocess, 143.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 4 referees, 142.9ms\n","Speed: 11.2ms preprocess, 142.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 3 referees, 142.5ms\n","Speed: 8.8ms preprocess, 142.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 140.0ms\n","Speed: 10.6ms preprocess, 140.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 140.9ms\n","Speed: 10.6ms preprocess, 140.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 2 referees, 146.0ms\n","Speed: 9.8ms preprocess, 146.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 3 referees, 145.5ms\n","Speed: 10.1ms preprocess, 145.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 3 referees, 145.7ms\n","Speed: 10.4ms preprocess, 145.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 3 referees, 142.4ms\n","Speed: 8.8ms preprocess, 142.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 3 referees, 145.2ms\n","Speed: 10.4ms preprocess, 145.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 140.9ms\n","Speed: 11.3ms preprocess, 140.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 140.3ms\n","Speed: 11.5ms preprocess, 140.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 141.2ms\n","Speed: 10.6ms preprocess, 141.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 141.6ms\n","Speed: 11.4ms preprocess, 141.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 18 players, 3 referees, 143.1ms\n","Speed: 8.3ms preprocess, 143.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 3 referees, 144.0ms\n","Speed: 9.8ms preprocess, 144.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 21 players, 3 referees, 143.9ms\n","Speed: 9.7ms preprocess, 143.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 23 players, 2 referees, 142.3ms\n","Speed: 15.6ms preprocess, 142.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 24 players, 2 referees, 142.0ms\n","Speed: 11.7ms preprocess, 142.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 1 referee, 143.4ms\n","Speed: 12.2ms preprocess, 143.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 1 referee, 142.6ms\n","Speed: 11.9ms preprocess, 142.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 142.5ms\n","Speed: 13.0ms preprocess, 142.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 146.9ms\n","Speed: 11.5ms preprocess, 146.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 142.4ms\n","Speed: 11.3ms preprocess, 142.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 3 referees, 142.3ms\n","Speed: 13.4ms preprocess, 142.3ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 141.5ms\n","Speed: 11.1ms preprocess, 141.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 142.0ms\n","Speed: 12.7ms preprocess, 142.0ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 142.0ms\n","Speed: 16.8ms preprocess, 142.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 24 players, 2 referees, 141.1ms\n","Speed: 11.1ms preprocess, 141.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 25 players, 1 referee, 144.9ms\n","Speed: 11.5ms preprocess, 144.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 1 referee, 141.8ms\n","Speed: 12.3ms preprocess, 141.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 24 players, 1 referee, 142.6ms\n","Speed: 12.1ms preprocess, 142.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 143.4ms\n","Speed: 11.5ms preprocess, 143.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 3 referees, 143.3ms\n","Speed: 10.3ms preprocess, 143.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 2 referees, 142.1ms\n","Speed: 11.3ms preprocess, 142.1ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 22 players, 4 referees, 142.0ms\n","Speed: 13.2ms preprocess, 142.0ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 19 players, 4 referees, 143.0ms\n","Speed: 12.6ms preprocess, 143.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 144.4ms\n","Speed: 11.1ms preprocess, 144.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 4 referees, 143.4ms\n","Speed: 10.4ms preprocess, 143.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 144.7ms\n","Speed: 10.2ms preprocess, 144.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 19 players, 2 referees, 143.3ms\n","Speed: 10.0ms preprocess, 143.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 3 referees, 143.1ms\n","Speed: 9.9ms preprocess, 143.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 3 referees, 143.7ms\n","Speed: 10.1ms preprocess, 143.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 144.1ms\n","Speed: 12.4ms preprocess, 144.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 3 referees, 144.6ms\n","Speed: 10.0ms preprocess, 144.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 3 referees, 144.1ms\n","Speed: 9.4ms preprocess, 144.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 3 referees, 141.8ms\n","Speed: 9.9ms preprocess, 141.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 4 referees, 144.0ms\n","Speed: 11.7ms preprocess, 144.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 4 referees, 143.2ms\n","Speed: 11.9ms preprocess, 143.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 19 players, 4 referees, 144.9ms\n","Speed: 10.8ms preprocess, 144.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 142.8ms\n","Speed: 10.8ms preprocess, 142.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 143.9ms\n","Speed: 11.5ms preprocess, 143.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 143.8ms\n","Speed: 11.3ms preprocess, 143.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 4 referees, 144.0ms\n","Speed: 11.0ms preprocess, 144.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 144.1ms\n","Speed: 12.6ms preprocess, 144.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 145.6ms\n","Speed: 10.3ms preprocess, 145.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 142.9ms\n","Speed: 13.6ms preprocess, 142.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 144.4ms\n","Speed: 12.5ms preprocess, 144.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 2 referees, 142.3ms\n","Speed: 9.7ms preprocess, 142.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 144.1ms\n","Speed: 10.2ms preprocess, 144.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 142.7ms\n","Speed: 11.3ms preprocess, 142.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 3 referees, 147.3ms\n","Speed: 9.8ms preprocess, 147.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 1 referee, 146.5ms\n","Speed: 9.4ms preprocess, 146.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 145.7ms\n","Speed: 11.2ms preprocess, 145.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 4 referees, 142.6ms\n","Speed: 15.0ms preprocess, 142.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 3 referees, 142.3ms\n","Speed: 9.7ms preprocess, 142.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 140.9ms\n","Speed: 12.6ms preprocess, 140.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 142.1ms\n","Speed: 11.7ms preprocess, 142.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 4 referees, 143.6ms\n","Speed: 12.1ms preprocess, 143.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 3 referees, 148.2ms\n","Speed: 10.1ms preprocess, 148.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 1 referee, 143.7ms\n","Speed: 11.2ms preprocess, 143.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 2 referees, 145.2ms\n","Speed: 9.8ms preprocess, 145.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 144.6ms\n","Speed: 10.6ms preprocess, 144.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 142.0ms\n","Speed: 9.7ms preprocess, 142.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 143.4ms\n","Speed: 11.4ms preprocess, 143.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 3 referees, 144.3ms\n","Speed: 11.3ms preprocess, 144.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 balls, 1 goalkeeper, 22 players, 2 referees, 144.7ms\n","Speed: 9.7ms preprocess, 144.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 2 referees, 144.9ms\n","Speed: 11.4ms preprocess, 144.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 2 referees, 144.5ms\n","Speed: 9.6ms preprocess, 144.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 4 referees, 142.1ms\n","Speed: 12.1ms preprocess, 142.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 141.1ms\n","Speed: 10.2ms preprocess, 141.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 142.3ms\n","Speed: 11.3ms preprocess, 142.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 24 players, 2 referees, 143.1ms\n","Speed: 10.2ms preprocess, 143.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 goalkeepers, 24 players, 2 referees, 142.1ms\n","Speed: 11.4ms preprocess, 142.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 3 referees, 143.8ms\n","Speed: 11.2ms preprocess, 143.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 144.1ms\n","Speed: 9.7ms preprocess, 144.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 142.8ms\n","Speed: 10.4ms preprocess, 142.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 1 referee, 139.6ms\n","Speed: 12.5ms preprocess, 139.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 144.8ms\n","Speed: 11.4ms preprocess, 144.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 20 players, 3 referees, 143.5ms\n","Speed: 8.9ms preprocess, 143.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 142.9ms\n","Speed: 10.6ms preprocess, 142.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 140.0ms\n","Speed: 11.3ms preprocess, 140.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 142.7ms\n","Speed: 10.4ms preprocess, 142.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 141.2ms\n","Speed: 10.6ms preprocess, 141.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 141.3ms\n","Speed: 12.4ms preprocess, 141.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 141.5ms\n","Speed: 9.0ms preprocess, 141.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 19 players, 2 referees, 141.9ms\n","Speed: 15.8ms preprocess, 141.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 141.6ms\n","Speed: 10.9ms preprocess, 141.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 142.8ms\n","Speed: 10.6ms preprocess, 142.8ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 140.4ms\n","Speed: 10.8ms preprocess, 140.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 140.1ms\n","Speed: 11.2ms preprocess, 140.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 142.4ms\n","Speed: 9.9ms preprocess, 142.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 140.5ms\n","Speed: 11.8ms preprocess, 140.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 140.4ms\n","Speed: 10.8ms preprocess, 140.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 139.0ms\n","Speed: 13.3ms preprocess, 139.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 139.1ms\n","Speed: 16.5ms preprocess, 139.1ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 135.9ms\n","Speed: 12.2ms preprocess, 135.9ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 19 players, 2 referees, 138.6ms\n","Speed: 14.7ms preprocess, 138.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 2 referees, 139.6ms\n","Speed: 11.7ms preprocess, 139.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 3 referees, 139.6ms\n","Speed: 13.4ms preprocess, 139.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 140.3ms\n","Speed: 17.9ms preprocess, 140.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 138.4ms\n","Speed: 14.6ms preprocess, 138.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 142.0ms\n","Speed: 14.8ms preprocess, 142.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 140.1ms\n","Speed: 11.1ms preprocess, 140.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 140.3ms\n","Speed: 10.8ms preprocess, 140.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 141.0ms\n","Speed: 11.0ms preprocess, 141.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 139.4ms\n","Speed: 12.9ms preprocess, 139.4ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 138.5ms\n","Speed: 12.7ms preprocess, 138.5ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 140.0ms\n","Speed: 14.7ms preprocess, 140.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 138.6ms\n","Speed: 13.1ms preprocess, 138.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 3 referees, 141.7ms\n","Speed: 9.6ms preprocess, 141.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 141.0ms\n","Speed: 9.2ms preprocess, 141.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 138.7ms\n","Speed: 14.0ms preprocess, 138.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 3 referees, 142.7ms\n","Speed: 11.5ms preprocess, 142.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 3 referees, 140.5ms\n","Speed: 9.5ms preprocess, 140.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 2 referees, 138.6ms\n","Speed: 9.4ms preprocess, 138.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 138.7ms\n","Speed: 11.6ms preprocess, 138.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 142.2ms\n","Speed: 11.1ms preprocess, 142.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 141.1ms\n","Speed: 10.7ms preprocess, 141.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 139.4ms\n","Speed: 9.2ms preprocess, 139.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 3 referees, 140.4ms\n","Speed: 10.5ms preprocess, 140.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 137.3ms\n","Speed: 9.4ms preprocess, 137.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 141.9ms\n","Speed: 11.6ms preprocess, 141.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 139.0ms\n","Speed: 10.0ms preprocess, 139.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 138.8ms\n","Speed: 10.9ms preprocess, 138.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 137.1ms\n","Speed: 10.6ms preprocess, 137.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 3 referees, 141.8ms\n","Speed: 10.5ms preprocess, 141.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 140.0ms\n","Speed: 13.1ms preprocess, 140.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 138.8ms\n","Speed: 11.1ms preprocess, 138.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 138.6ms\n","Speed: 11.3ms preprocess, 138.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 139.4ms\n","Speed: 11.4ms preprocess, 139.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 138.6ms\n","Speed: 11.6ms preprocess, 138.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 139.0ms\n","Speed: 10.9ms preprocess, 139.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 139.7ms\n","Speed: 10.7ms preprocess, 139.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 139.0ms\n","Speed: 9.7ms preprocess, 139.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 139.4ms\n","Speed: 10.1ms preprocess, 139.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 2 referees, 139.7ms\n","Speed: 10.4ms preprocess, 139.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 137.7ms\n","Speed: 12.5ms preprocess, 137.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 137.1ms\n","Speed: 11.1ms preprocess, 137.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 141.3ms\n","Speed: 11.6ms preprocess, 141.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 139.4ms\n","Speed: 11.2ms preprocess, 139.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 138.3ms\n","Speed: 11.3ms preprocess, 138.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 1 referee, 138.6ms\n","Speed: 10.1ms preprocess, 138.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 1 referee, 140.1ms\n","Speed: 10.6ms preprocess, 140.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 1 referee, 137.7ms\n","Speed: 10.0ms preprocess, 137.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 137.4ms\n","Speed: 11.7ms preprocess, 137.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 138.1ms\n","Speed: 13.6ms preprocess, 138.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 139.3ms\n","Speed: 11.1ms preprocess, 139.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 136.9ms\n","Speed: 11.3ms preprocess, 136.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 139.9ms\n","Speed: 11.1ms preprocess, 139.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 138.5ms\n","Speed: 9.4ms preprocess, 138.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 19 players, 2 referees, 137.9ms\n","Speed: 10.6ms preprocess, 137.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 137.1ms\n","Speed: 11.1ms preprocess, 137.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 139.3ms\n","Speed: 13.4ms preprocess, 139.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 139.2ms\n","Speed: 8.9ms preprocess, 139.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 136.8ms\n","Speed: 10.2ms preprocess, 136.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 139.9ms\n","Speed: 10.2ms preprocess, 139.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 138.2ms\n","Speed: 9.7ms preprocess, 138.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 136.7ms\n","Speed: 11.1ms preprocess, 136.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 2 referees, 138.4ms\n","Speed: 10.8ms preprocess, 138.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 23 players, 2 referees, 137.7ms\n","Speed: 11.3ms preprocess, 137.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 135.9ms\n","Speed: 10.3ms preprocess, 135.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 138.3ms\n","Speed: 11.3ms preprocess, 138.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 137.7ms\n","Speed: 11.0ms preprocess, 137.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 20 players, 1 referee, 139.7ms\n","Speed: 10.5ms preprocess, 139.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 24 players, 1 referee, 137.6ms\n","Speed: 10.2ms preprocess, 137.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 23 players, 2 referees, 134.7ms\n","Speed: 11.7ms preprocess, 134.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 21 players, 2 referees, 137.6ms\n","Speed: 10.0ms preprocess, 137.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 22 players, 3 referees, 137.8ms\n","Speed: 10.9ms preprocess, 137.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 20 players, 2 referees, 137.2ms\n","Speed: 10.6ms preprocess, 137.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 ball, 1 goalkeeper, 23 players, 2 referees, 137.8ms\n","Speed: 10.2ms preprocess, 137.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 goalkeeper, 22 players, 1 referee, 138.0ms\n","Speed: 10.7ms preprocess, 138.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 384x640 1 pitch, 146.5ms\n","Speed: 4.0ms preprocess, 146.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 32.1ms\n","Speed: 3.3ms preprocess, 32.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 5.8ms preprocess, 40.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.4ms preprocess, 37.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.4ms preprocess, 38.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.6ms preprocess, 40.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.5ms preprocess, 37.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 4.2ms preprocess, 39.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 5.8ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.8ms preprocess, 39.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.5ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.2ms preprocess, 39.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.1ms\n","Speed: 3.2ms preprocess, 41.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 4.7ms preprocess, 38.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 4.6ms preprocess, 39.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 4.5ms preprocess, 37.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 4.4ms preprocess, 39.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.4ms preprocess, 38.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 4.0ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.5ms preprocess, 38.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.8ms preprocess, 39.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.5ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.7ms preprocess, 38.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.5ms preprocess, 40.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.3ms preprocess, 38.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.6ms preprocess, 38.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.3ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 4.5ms preprocess, 38.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.6ms preprocess, 40.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.3ms preprocess, 39.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.3ms preprocess, 40.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.3ms preprocess, 37.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.2ms preprocess, 39.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.3ms preprocess, 39.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.3ms preprocess, 37.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.2ms preprocess, 39.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.4ms preprocess, 37.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.4ms preprocess, 40.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.8ms\n","Speed: 3.3ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.9ms\n","Speed: 3.4ms preprocess, 41.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.3ms preprocess, 38.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.6ms preprocess, 39.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.4ms preprocess, 39.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 4.5ms preprocess, 40.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.9ms preprocess, 39.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.1ms preprocess, 38.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.2ms preprocess, 37.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.1ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.3ms preprocess, 37.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.4ms preprocess, 38.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 5.1ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.1ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.1ms preprocess, 40.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.2ms preprocess, 38.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.2ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.3ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.1ms\n","Speed: 3.1ms preprocess, 41.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.7ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.0ms preprocess, 38.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.4ms\n","Speed: 3.4ms preprocess, 41.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.4ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.4ms preprocess, 38.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.3ms preprocess, 40.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.2ms preprocess, 40.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.1ms preprocess, 40.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.8ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.3ms preprocess, 40.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.4ms\n","Speed: 3.7ms preprocess, 41.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.2ms preprocess, 40.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.1ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.4ms preprocess, 38.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.1ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 2.9ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 4.1ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.2ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.6ms preprocess, 38.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 4.2ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.7ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.6ms preprocess, 40.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.3ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.3ms preprocess, 40.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.7ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.3ms preprocess, 39.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.3ms preprocess, 39.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.7ms preprocess, 37.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 4.2ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 4.5ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.2ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.3ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.6ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.3ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.1ms preprocess, 37.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.0ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.0ms\n","Speed: 3.1ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.0ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.5ms\n","Speed: 3.2ms preprocess, 42.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.6ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.8ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.3ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.2ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.0ms\n","Speed: 3.7ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.4ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.3ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 6.5ms preprocess, 37.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 6.2ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.6ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.1ms preprocess, 38.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.4ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.9ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.4ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.2ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.4ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.4ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.2ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.4ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.6ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.4ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.2ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.4ms preprocess, 38.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.2ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.3ms preprocess, 38.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.6ms preprocess, 38.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 4.5ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.6ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.3ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.2ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.3ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.4ms preprocess, 40.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.4ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.1ms\n","Speed: 3.3ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.4ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.4ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.3ms preprocess, 40.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.4ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.6ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.1ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.0ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.1ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.2ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.0ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.7ms preprocess, 40.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 4.6ms preprocess, 37.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 4.0ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.2ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.6ms preprocess, 39.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 4.0ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.4ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.1ms\n","Speed: 3.2ms preprocess, 42.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.5ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.6ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 4.2ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.4ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.3ms\n","Speed: 3.3ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.3ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.5ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.6ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.4ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.5ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.9ms preprocess, 38.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 5.1ms preprocess, 39.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 4.5ms preprocess, 37.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.7ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 4.0ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.7ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.2ms\n","Speed: 3.5ms preprocess, 41.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.2ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.2ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.1ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.8ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.3ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.4ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.6ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.4ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.3ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.3ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.5ms preprocess, 40.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 4.4ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.7ms preprocess, 39.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 4.8ms preprocess, 38.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.3ms preprocess, 38.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.4ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 4.3ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.8ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.1ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.3ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.3ms preprocess, 40.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.2ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.7ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.1ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.4ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.4ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 4.0ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.8ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 4.7ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.9ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.1ms\n","Speed: 3.3ms preprocess, 41.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.4ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.2ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.3ms preprocess, 40.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.1ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.5ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.7ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.0ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.1ms preprocess, 39.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 4.3ms preprocess, 38.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 2.6ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.5ms\n","Speed: 3.3ms preprocess, 41.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.5ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 4.4ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.3ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.3ms\n","Speed: 3.4ms preprocess, 41.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.5ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.4ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.6ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.7ms preprocess, 38.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.6ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 5.7ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.6ms preprocess, 37.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.3ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 5.0ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.5ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 2.8ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.6ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.1ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.4ms preprocess, 39.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.1ms preprocess, 37.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 2.9ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.4ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.2ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.7ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.7ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.2ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.4ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.3ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.5ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 4.2ms preprocess, 39.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.5ms preprocess, 37.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.4ms preprocess, 38.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.4ms preprocess, 38.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.5ms preprocess, 39.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.5ms preprocess, 37.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.8ms preprocess, 39.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.5ms preprocess, 39.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.6ms preprocess, 39.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 4.3ms preprocess, 37.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 4.3ms preprocess, 40.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.3ms preprocess, 37.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.3ms preprocess, 39.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.2ms\n","Speed: 3.3ms preprocess, 41.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.3ms preprocess, 37.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 4.6ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.3ms preprocess, 38.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 13.0ms preprocess, 37.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.7ms\n","Speed: 7.4ms preprocess, 36.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.4ms preprocess, 37.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 4.7ms preprocess, 37.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.3ms preprocess, 37.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.3ms preprocess, 38.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.4ms preprocess, 39.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.2ms preprocess, 39.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.5ms preprocess, 37.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 4.4ms preprocess, 37.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.7ms preprocess, 39.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.2ms preprocess, 37.9ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.3ms preprocess, 38.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.5ms preprocess, 39.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.6ms preprocess, 37.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 4.7ms preprocess, 39.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.3ms preprocess, 38.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.4ms preprocess, 39.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.3ms preprocess, 37.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.5ms preprocess, 38.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 6.4ms preprocess, 37.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.4ms preprocess, 37.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.2ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.6ms\n","Speed: 3.6ms preprocess, 41.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.4ms preprocess, 38.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.5ms preprocess, 39.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.5ms preprocess, 40.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.4ms preprocess, 39.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.4ms preprocess, 37.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.3ms preprocess, 39.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.6ms preprocess, 38.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 4.1ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.2ms preprocess, 39.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.4ms\n","Speed: 3.6ms preprocess, 41.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.7ms preprocess, 37.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.7ms preprocess, 40.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.5ms preprocess, 39.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 4.1ms preprocess, 38.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.3ms preprocess, 38.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.7ms preprocess, 40.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.6ms preprocess, 38.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.2ms preprocess, 38.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.3ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.1ms preprocess, 38.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.5ms preprocess, 40.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.3ms preprocess, 38.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.4ms preprocess, 38.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.7ms preprocess, 39.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.4ms preprocess, 37.9ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.3ms preprocess, 37.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.4ms preprocess, 39.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.3ms preprocess, 37.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.6ms preprocess, 40.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.5ms preprocess, 38.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 4.8ms preprocess, 38.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.9ms\n","Speed: 3.5ms preprocess, 36.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.7ms\n","Speed: 3.4ms preprocess, 41.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 5.5ms preprocess, 38.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.3ms preprocess, 38.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.2ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.6ms preprocess, 40.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.3ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.3ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.4ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.8ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.5ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.1ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.3ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 4.0ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.1ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.1ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.3ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.1ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.6ms preprocess, 39.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.2ms preprocess, 38.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.8ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.5ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.9ms preprocess, 38.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.7ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.2ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.0ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 4.2ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.3ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.5ms preprocess, 37.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.9ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.9ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 4.2ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.0ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.4ms preprocess, 39.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.4ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.7ms\n","Speed: 3.3ms preprocess, 41.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.3ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.4ms preprocess, 38.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 4.7ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.3ms preprocess, 39.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.1ms preprocess, 40.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.4ms preprocess, 37.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.3ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 4.4ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.5ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.5ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.4ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.2ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 5.0ms preprocess, 37.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.8ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 4.0ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.4ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 6.0ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.4ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 4.1ms preprocess, 37.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.5ms preprocess, 38.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.8ms preprocess, 40.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 6.3ms preprocess, 38.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.4ms preprocess, 39.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.9ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.4ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.6ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.4ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.6ms\n","Speed: 3.4ms preprocess, 41.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.2ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.3ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.1ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.1ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.2ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.0ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.5ms preprocess, 38.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.8ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.7ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.3ms preprocess, 39.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 4.1ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 4.7ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.3ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.1ms preprocess, 40.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.3ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.2ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 4.1ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.3ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.1ms preprocess, 39.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.7ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.1ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.1ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.1ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.1ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.2ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.5ms\n","Speed: 3.2ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.8ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.1ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.6ms preprocess, 38.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.4ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.1ms preprocess, 39.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.2ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.5ms preprocess, 38.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.3ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 4.0ms preprocess, 40.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.3ms preprocess, 37.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.2ms\n","Speed: 3.3ms preprocess, 37.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 4.0ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.3ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.1ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.1ms\n","Speed: 3.2ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.1ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.2ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.4ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 4.0ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.5ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.3ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.2ms preprocess, 40.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.5ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.2ms\n","Speed: 3.2ms preprocess, 41.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.3ms preprocess, 37.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.5ms preprocess, 40.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.3ms preprocess, 39.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.4ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.3ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.2ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.2ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.4ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 4.3ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.9ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.9ms preprocess, 39.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 4.0ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 4.1ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.3ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.5ms preprocess, 37.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.3ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.5ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.2ms\n","Speed: 3.4ms preprocess, 42.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.8ms preprocess, 38.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.9ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 4.4ms preprocess, 38.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 5.5ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.1ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.6ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.4ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.1ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.4ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.6ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.7ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.5ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.4ms\n","Speed: 4.5ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.6ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 4.0ms preprocess, 39.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.1ms preprocess, 40.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.7ms preprocess, 37.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.7ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.6ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 6.0ms preprocess, 38.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.4ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.8ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.6ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.3ms preprocess, 40.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.5ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.3ms preprocess, 39.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.5ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.8ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.4ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.2ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 4.3ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 4.4ms preprocess, 39.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 4.0ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.5ms preprocess, 39.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.2ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.8ms preprocess, 40.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.6ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 2.9ms preprocess, 40.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.8ms preprocess, 37.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.3ms preprocess, 40.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.1ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 2.9ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 4.1ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.7ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.2ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 4.5ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 3.2ms preprocess, 37.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.3ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.2ms preprocess, 40.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.6ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.5ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 4.2ms preprocess, 37.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.6ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.1ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 4.7ms preprocess, 38.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.1ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.4ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.4ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.1ms preprocess, 38.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.3ms preprocess, 37.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.6ms\n","Speed: 3.4ms preprocess, 41.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.4ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.4ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.5ms preprocess, 40.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.7ms preprocess, 39.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.2ms preprocess, 40.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.0ms preprocess, 39.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.1ms preprocess, 40.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.1ms preprocess, 38.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.3ms preprocess, 39.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.3ms preprocess, 38.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.3ms preprocess, 40.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.3ms preprocess, 37.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.9ms preprocess, 39.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.5ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.2ms\n","Speed: 3.8ms preprocess, 42.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.7ms preprocess, 38.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.8ms preprocess, 40.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 4.4ms preprocess, 38.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.6ms preprocess, 40.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.8ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 4.4ms preprocess, 38.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.1ms preprocess, 39.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.6ms preprocess, 38.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.4ms preprocess, 40.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.9ms preprocess, 37.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.1ms preprocess, 38.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.8ms preprocess, 39.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.7ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.7ms preprocess, 40.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.6ms preprocess, 37.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.7ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 4.2ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.9ms preprocess, 38.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.4ms preprocess, 40.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.8ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.6ms preprocess, 38.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.6ms preprocess, 40.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.2ms\n","Speed: 3.8ms preprocess, 38.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 43.3ms\n","Speed: 3.5ms preprocess, 43.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 36.2ms\n","Speed: 6.8ms preprocess, 36.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.3ms preprocess, 40.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.3ms\n","Speed: 5.3ms preprocess, 37.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.4ms\n","Speed: 3.5ms preprocess, 41.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.2ms preprocess, 39.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.1ms preprocess, 37.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.1ms preprocess, 39.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.1ms preprocess, 38.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.0ms preprocess, 38.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.2ms preprocess, 40.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.1ms preprocess, 37.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.1ms preprocess, 40.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.1ms preprocess, 38.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.3ms preprocess, 40.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.2ms preprocess, 40.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 4.9ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.8ms\n","Speed: 3.2ms preprocess, 41.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 5.6ms preprocess, 37.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 4.0ms preprocess, 40.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.1ms preprocess, 38.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.4ms preprocess, 38.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 5.0ms preprocess, 37.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.6ms\n","Speed: 3.7ms preprocess, 40.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.1ms\n","Speed: 3.0ms preprocess, 37.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.5ms\n","Speed: 2.6ms preprocess, 42.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.1ms preprocess, 38.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.2ms\n","Speed: 3.1ms preprocess, 41.2ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.3ms preprocess, 37.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.3ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 4.2ms preprocess, 38.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.1ms preprocess, 40.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.3ms\n","Speed: 3.2ms preprocess, 42.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.4ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.1ms preprocess, 38.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.6ms preprocess, 40.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.6ms preprocess, 40.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.2ms preprocess, 40.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.1ms preprocess, 38.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.0ms preprocess, 39.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.4ms\n","Speed: 3.4ms preprocess, 37.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.1ms\n","Speed: 3.4ms preprocess, 42.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 4.4ms preprocess, 37.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.0ms preprocess, 39.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.1ms preprocess, 38.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 2.9ms preprocess, 39.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.2ms preprocess, 38.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.1ms preprocess, 39.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.6ms\n","Speed: 3.0ms preprocess, 37.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 2.8ms preprocess, 39.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 3.4ms preprocess, 37.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.1ms preprocess, 40.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.5ms\n","Speed: 3.2ms preprocess, 37.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 4.3ms preprocess, 38.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.0ms\n","Speed: 3.2ms preprocess, 41.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.1ms\n","Speed: 3.2ms preprocess, 38.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.0ms\n","Speed: 3.3ms preprocess, 37.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 2.9ms preprocess, 39.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.9ms preprocess, 39.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.3ms preprocess, 38.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.3ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.7ms\n","Speed: 3.2ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.2ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 3.0ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.0ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.1ms preprocess, 40.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.0ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.0ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 5.1ms preprocess, 40.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.3ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.6ms preprocess, 40.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.5ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.1ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.2ms\n","Speed: 3.4ms preprocess, 40.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.2ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.3ms preprocess, 39.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 4.8ms preprocess, 38.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.3ms preprocess, 38.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.1ms preprocess, 40.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.2ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.7ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.4ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.1ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.2ms\n","Speed: 3.0ms preprocess, 41.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.6ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.1ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.1ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 4.4ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.3ms\n","Speed: 3.2ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.6ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 4.0ms preprocess, 38.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.3ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.0ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.9ms\n","Speed: 3.0ms preprocess, 41.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.1ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 4.5ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 5.3ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.2ms\n","Speed: 3.5ms preprocess, 39.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.4ms\n","Speed: 4.7ms preprocess, 41.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 3.6ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 42.8ms\n","Speed: 3.9ms preprocess, 42.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.7ms\n","Speed: 3.3ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.3ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.1ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.4ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.3ms\n","Speed: 3.9ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.3ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.2ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.3ms\n","Speed: 3.1ms preprocess, 40.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 2.9ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.2ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.6ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.9ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.8ms\n","Speed: 3.0ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.8ms\n","Speed: 4.3ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 5.1ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.8ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.7ms\n","Speed: 4.0ms preprocess, 39.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 5.0ms preprocess, 38.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 4.8ms preprocess, 38.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.9ms\n","Speed: 3.1ms preprocess, 38.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 4.1ms preprocess, 38.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.1ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.0ms\n","Speed: 3.3ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.0ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.8ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.7ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.9ms\n","Speed: 3.8ms preprocess, 39.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.3ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.9ms\n","Speed: 4.3ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 4.3ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.1ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.3ms\n","Speed: 3.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.0ms\n","Speed: 3.4ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.0ms\n","Speed: 3.6ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.6ms\n","Speed: 3.1ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 37.9ms\n","Speed: 3.6ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.7ms\n","Speed: 3.0ms preprocess, 40.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.1ms\n","Speed: 3.5ms preprocess, 40.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.5ms\n","Speed: 3.6ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.1ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.5ms\n","Speed: 3.1ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.1ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.4ms\n","Speed: 3.2ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.1ms\n","Speed: 3.4ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 39.4ms\n","Speed: 3.0ms preprocess, 39.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.5ms\n","Speed: 3.0ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.8ms\n","Speed: 3.0ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.4ms\n","Speed: 3.2ms preprocess, 40.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.6ms\n","Speed: 3.4ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 41.5ms\n","Speed: 3.0ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 38.3ms\n","Speed: 3.6ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.0ms\n","Speed: 3.1ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 pitch, 40.8ms\n","Speed: 3.0ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:   0%|          | 0/25 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 134.8ms\n","Speed: 14.3ms preprocess, 134.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:   4%|â–         | 1/25 [00:00<00:04,  5.69it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 17 players, 131.3ms\n","Speed: 10.9ms preprocess, 131.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:   8%|â–Š         | 2/25 [00:00<00:03,  6.24it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 19 players, 136.4ms\n","Speed: 13.3ms preprocess, 136.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  12%|â–ˆâ–        | 3/25 [00:00<00:03,  6.29it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 19 players, 1 referee, 136.6ms\n","Speed: 10.8ms preprocess, 136.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  16%|â–ˆâ–Œ        | 4/25 [00:00<00:03,  6.34it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 17 players, 2 referees, 136.6ms\n","Speed: 12.2ms preprocess, 136.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  20%|â–ˆâ–ˆ        | 5/25 [00:00<00:03,  6.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 15 players, 3 referees, 138.2ms\n","Speed: 13.6ms preprocess, 138.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  24%|â–ˆâ–ˆâ–       | 6/25 [00:00<00:03,  6.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 2 goalkeepers, 16 players, 4 referees, 140.8ms\n","Speed: 12.1ms preprocess, 140.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  28%|â–ˆâ–ˆâ–Š       | 7/25 [00:01<00:02,  6.27it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 2 goalkeepers, 16 players, 4 referees, 136.5ms\n","Speed: 11.1ms preprocess, 136.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:01<00:02,  6.30it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 21 players, 1 referee, 133.5ms\n","Speed: 11.1ms preprocess, 133.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:01<00:02,  6.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 21 players, 2 referees, 134.1ms\n","Speed: 10.2ms preprocess, 134.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:01<00:02,  6.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 22 players, 2 referees, 137.7ms\n","Speed: 11.1ms preprocess, 137.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:01<00:02,  6.39it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 19 players, 2 referees, 135.9ms\n","Speed: 11.5ms preprocess, 135.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:01<00:02,  6.34it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 19 players, 2 referees, 137.8ms\n","Speed: 11.2ms preprocess, 137.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:02<00:01,  6.33it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 20 players, 2 referees, 137.4ms\n","Speed: 10.9ms preprocess, 137.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:02<00:01,  6.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 22 players, 1 referee, 137.2ms\n","Speed: 11.1ms preprocess, 137.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:02<00:01,  6.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 20 players, 2 referees, 137.0ms\n","Speed: 11.1ms preprocess, 137.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:02<00:01,  6.37it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 137.9ms\n","Speed: 10.9ms preprocess, 137.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:02<00:01,  6.38it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 ball, 1 goalkeeper, 21 players, 3 referees, 137.7ms\n","Speed: 11.9ms preprocess, 137.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:02<00:01,  6.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 22 players, 2 referees, 136.7ms\n","Speed: 11.4ms preprocess, 136.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:02<00:00,  6.38it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 3 referees, 137.7ms\n","Speed: 10.6ms preprocess, 137.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:03<00:00,  6.39it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 ball, 1 goalkeeper, 22 players, 2 referees, 137.6ms\n","Speed: 11.1ms preprocess, 137.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:03<00:00,  6.38it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 ball, 1 goalkeeper, 20 players, 1 referee, 135.6ms\n","Speed: 11.0ms preprocess, 135.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:03<00:00,  6.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 21 players, 2 referees, 138.3ms\n","Speed: 11.2ms preprocess, 138.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:03<00:00,  6.39it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 20 players, 1 referee, 138.1ms\n","Speed: 11.2ms preprocess, 138.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["\rcollecting player crops:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:03<00:00,  6.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","0: 736x1280 1 goalkeeper, 22 players, 1 referee, 137.0ms\n","Speed: 11.2ms preprocess, 137.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"output_type":"stream","name":"stderr","text":["collecting player crops: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  6.34it/s]\n","Embedding extraction: 15it [00:01, 13.80it/s]\n","Embedding extraction: 1it [00:00, 19.05it/s]\n","Embedding extraction: 1it [00:00, 19.78it/s]\n","Embedding extraction: 1it [00:00, 20.40it/s]\n","Embedding extraction: 1it [00:00, 20.77it/s]\n","Embedding extraction: 1it [00:00, 19.36it/s]\n","Embedding extraction: 1it [00:00, 20.72it/s]\n","Embedding extraction: 1it [00:00, 20.81it/s]\n","Embedding extraction: 1it [00:00, 20.67it/s]\n","Embedding extraction: 1it [00:00, 20.51it/s]\n","Embedding extraction: 1it [00:00, 20.11it/s]\n","Embedding extraction: 1it [00:00, 20.77it/s]\n","Embedding extraction: 1it [00:00, 20.14it/s]\n","Embedding extraction: 1it [00:00, 20.52it/s]\n","Embedding extraction: 1it [00:00, 20.32it/s]\n","Embedding extraction: 1it [00:00, 19.90it/s]\n","Embedding extraction: 1it [00:00, 20.35it/s]\n","Embedding extraction: 1it [00:00, 20.41it/s]\n","Embedding extraction: 1it [00:00, 20.34it/s]\n","Embedding extraction: 1it [00:00, 20.67it/s]\n","Embedding extraction: 1it [00:00, 20.67it/s]\n","Embedding extraction: 1it [00:00, 20.70it/s]\n","Embedding extraction: 1it [00:00, 22.10it/s]\n","Embedding extraction: 1it [00:00, 22.88it/s]\n","Embedding extraction: 1it [00:00, 22.84it/s]\n","Embedding extraction: 1it [00:00, 24.01it/s]\n","Embedding extraction: 1it [00:00, 21.34it/s]\n","Embedding extraction: 1it [00:00, 22.93it/s]\n","Embedding extraction: 1it [00:00, 20.61it/s]\n","Embedding extraction: 1it [00:00, 20.22it/s]\n","Embedding extraction: 1it [00:00, 22.85it/s]\n","Embedding extraction: 1it [00:00, 22.87it/s]\n","Embedding extraction: 1it [00:00, 23.11it/s]\n","Embedding extraction: 1it [00:00, 23.06it/s]\n","Embedding extraction: 1it [00:00, 22.60it/s]\n","Embedding extraction: 1it [00:00, 22.54it/s]\n","Embedding extraction: 1it [00:00, 22.73it/s]\n","Embedding extraction: 1it [00:00, 22.66it/s]\n","Embedding extraction: 1it [00:00, 23.88it/s]\n","Embedding extraction: 1it [00:00, 23.29it/s]\n","Embedding extraction: 1it [00:00, 23.06it/s]\n","Embedding extraction: 1it [00:00, 24.21it/s]\n","Embedding extraction: 1it [00:00, 22.85it/s]\n","Embedding extraction: 1it [00:00, 22.78it/s]\n","Embedding extraction: 1it [00:00, 22.90it/s]\n","Embedding extraction: 1it [00:00, 22.29it/s]\n","Embedding extraction: 1it [00:00, 23.21it/s]\n","Embedding extraction: 1it [00:00, 22.79it/s]\n","Embedding extraction: 1it [00:00, 22.89it/s]\n","Embedding extraction: 1it [00:00, 22.78it/s]\n","Embedding extraction: 1it [00:00, 20.34it/s]\n","Embedding extraction: 1it [00:00, 19.82it/s]\n","Embedding extraction: 1it [00:00, 20.54it/s]\n","Embedding extraction: 1it [00:00, 20.40it/s]\n","Embedding extraction: 1it [00:00, 19.68it/s]\n","Embedding extraction: 1it [00:00, 20.71it/s]\n","Embedding extraction: 1it [00:00, 19.84it/s]\n","Embedding extraction: 1it [00:00, 19.58it/s]\n","Embedding extraction: 1it [00:00, 19.83it/s]\n","Embedding extraction: 1it [00:00, 20.33it/s]\n","Embedding extraction: 1it [00:00, 19.56it/s]\n","Embedding extraction: 1it [00:00, 19.71it/s]\n","Embedding extraction: 1it [00:00, 20.54it/s]\n","Embedding extraction: 1it [00:00, 20.61it/s]\n","Embedding extraction: 1it [00:00, 19.87it/s]\n","Embedding extraction: 1it [00:00, 19.94it/s]\n","Embedding extraction: 1it [00:00, 17.88it/s]\n","Embedding extraction: 1it [00:00, 19.90it/s]\n","Embedding extraction: 1it [00:00, 19.34it/s]\n","Embedding extraction: 1it [00:00, 20.80it/s]\n","Embedding extraction: 1it [00:00, 19.74it/s]\n","Embedding extraction: 1it [00:00, 19.48it/s]\n","Embedding extraction: 1it [00:00, 23.17it/s]\n","Embedding extraction: 1it [00:00, 19.92it/s]\n","Embedding extraction: 1it [00:00, 17.63it/s]\n","Embedding extraction: 1it [00:00, 17.03it/s]\n","Embedding extraction: 1it [00:00, 16.93it/s]\n","Embedding extraction: 1it [00:00, 17.57it/s]\n","Embedding extraction: 1it [00:00, 16.64it/s]\n","Embedding extraction: 1it [00:00, 18.73it/s]\n","Embedding extraction: 1it [00:00, 19.61it/s]\n","Embedding extraction: 1it [00:00, 19.90it/s]\n","Embedding extraction: 1it [00:00, 19.20it/s]\n","Embedding extraction: 1it [00:00, 19.45it/s]\n","Embedding extraction: 1it [00:00, 18.65it/s]\n","Embedding extraction: 1it [00:00, 18.76it/s]\n","Embedding extraction: 1it [00:00, 18.81it/s]\n","Embedding extraction: 1it [00:00, 18.66it/s]\n","Embedding extraction: 1it [00:00, 18.06it/s]\n","Embedding extraction: 1it [00:00, 19.81it/s]\n","Embedding extraction: 1it [00:00, 19.88it/s]\n","Embedding extraction: 1it [00:00, 19.43it/s]\n","Embedding extraction: 1it [00:00, 19.50it/s]\n","Embedding extraction: 1it [00:00, 17.40it/s]\n","Embedding extraction: 1it [00:00, 16.70it/s]\n","Embedding extraction: 1it [00:00, 18.52it/s]\n","Embedding extraction: 1it [00:00, 18.52it/s]\n","Embedding extraction: 1it [00:00, 17.61it/s]\n","Embedding extraction: 1it [00:00, 19.56it/s]\n","Embedding extraction: 1it [00:00, 20.28it/s]\n","Embedding extraction: 1it [00:00, 19.63it/s]\n","Embedding extraction: 1it [00:00, 20.44it/s]\n","Embedding extraction: 1it [00:00, 22.58it/s]\n","Embedding extraction: 1it [00:00, 20.27it/s]\n","Embedding extraction: 1it [00:00, 20.34it/s]\n","Embedding extraction: 1it [00:00, 19.57it/s]\n","Embedding extraction: 1it [00:00, 19.45it/s]\n","Embedding extraction: 1it [00:00, 20.35it/s]\n","Embedding extraction: 1it [00:00, 20.39it/s]\n","Embedding extraction: 1it [00:00, 24.56it/s]\n","Embedding extraction: 1it [00:00, 24.24it/s]\n","Embedding extraction: 1it [00:00, 25.29it/s]\n","Embedding extraction: 1it [00:00, 24.38it/s]\n","Embedding extraction: 1it [00:00, 23.97it/s]\n","Embedding extraction: 1it [00:00, 25.28it/s]\n","Embedding extraction: 1it [00:00, 25.16it/s]\n","Embedding extraction: 1it [00:00, 25.04it/s]\n","Embedding extraction: 1it [00:00, 24.82it/s]\n","Embedding extraction: 1it [00:00, 24.18it/s]\n","Embedding extraction: 1it [00:00, 24.02it/s]\n","Embedding extraction: 1it [00:00, 24.45it/s]\n","Embedding extraction: 1it [00:00, 23.65it/s]\n","Embedding extraction: 1it [00:00, 22.71it/s]\n","Embedding extraction: 1it [00:00, 22.59it/s]\n","Embedding extraction: 1it [00:00, 23.51it/s]\n","Embedding extraction: 1it [00:00, 22.82it/s]\n","Embedding extraction: 1it [00:00, 22.69it/s]\n","Embedding extraction: 1it [00:00, 23.38it/s]\n","Embedding extraction: 1it [00:00, 23.68it/s]\n","Embedding extraction: 1it [00:00, 23.87it/s]\n","Embedding extraction: 1it [00:00, 22.76it/s]\n","Embedding extraction: 1it [00:00, 22.47it/s]\n","Embedding extraction: 1it [00:00, 20.55it/s]\n","Embedding extraction: 1it [00:00, 22.87it/s]\n","Embedding extraction: 1it [00:00, 20.61it/s]\n","Embedding extraction: 1it [00:00, 24.29it/s]\n","Embedding extraction: 1it [00:00, 22.71it/s]\n","Embedding extraction: 1it [00:00, 23.74it/s]\n","Embedding extraction: 1it [00:00, 22.82it/s]\n","Embedding extraction: 1it [00:00, 22.70it/s]\n","Embedding extraction: 1it [00:00, 23.06it/s]\n","Embedding extraction: 1it [00:00, 23.90it/s]\n","Embedding extraction: 1it [00:00, 24.35it/s]\n","Embedding extraction: 1it [00:00, 22.47it/s]\n","Embedding extraction: 1it [00:00, 23.38it/s]\n","Embedding extraction: 1it [00:00, 24.09it/s]\n","Embedding extraction: 1it [00:00, 24.01it/s]\n","Embedding extraction: 1it [00:00, 22.60it/s]\n","Embedding extraction: 1it [00:00, 22.98it/s]\n","Embedding extraction: 1it [00:00, 23.14it/s]\n","Embedding extraction: 1it [00:00, 23.13it/s]\n","Embedding extraction: 1it [00:00, 23.92it/s]\n","Embedding extraction: 1it [00:00, 24.25it/s]\n","Embedding extraction: 1it [00:00, 24.09it/s]\n","Embedding extraction: 1it [00:00, 23.46it/s]\n","Embedding extraction: 1it [00:00, 23.93it/s]\n","Embedding extraction: 1it [00:00, 21.72it/s]\n","Embedding extraction: 1it [00:00, 20.60it/s]\n","Embedding extraction: 1it [00:00, 23.02it/s]\n","Embedding extraction: 1it [00:00, 23.73it/s]\n","Embedding extraction: 1it [00:00, 23.47it/s]\n","Embedding extraction: 1it [00:00, 22.74it/s]\n","Embedding extraction: 1it [00:00, 23.98it/s]\n","Embedding extraction: 1it [00:00, 24.24it/s]\n","Embedding extraction: 1it [00:00, 24.47it/s]\n","Embedding extraction: 1it [00:00, 24.47it/s]\n","Embedding extraction: 1it [00:00, 24.42it/s]\n","Embedding extraction: 1it [00:00, 21.18it/s]\n","Embedding extraction: 1it [00:00, 21.02it/s]\n","Embedding extraction: 1it [00:00, 23.90it/s]\n","Embedding extraction: 1it [00:00, 23.72it/s]\n","Embedding extraction: 1it [00:00, 23.70it/s]\n","Embedding extraction: 1it [00:00, 24.02it/s]\n","Embedding extraction: 1it [00:00, 23.88it/s]\n","Embedding extraction: 1it [00:00, 23.77it/s]\n","Embedding extraction: 1it [00:00, 23.61it/s]\n","Embedding extraction: 1it [00:00, 23.70it/s]\n","Embedding extraction: 1it [00:00, 23.54it/s]\n","Embedding extraction: 1it [00:00, 24.66it/s]\n","Embedding extraction: 1it [00:00, 23.77it/s]\n","Embedding extraction: 1it [00:00, 23.64it/s]\n","Embedding extraction: 1it [00:00, 23.76it/s]\n","Embedding extraction: 1it [00:00, 23.84it/s]\n","Embedding extraction: 1it [00:00, 24.44it/s]\n","Embedding extraction: 1it [00:00, 24.10it/s]\n","Embedding extraction: 1it [00:00, 24.54it/s]\n","Embedding extraction: 1it [00:00, 24.52it/s]\n","Embedding extraction: 1it [00:00, 24.15it/s]\n","Embedding extraction: 1it [00:00, 26.52it/s]\n","Embedding extraction: 1it [00:00, 24.06it/s]\n","Embedding extraction: 1it [00:00, 24.57it/s]\n","Embedding extraction: 1it [00:00, 28.79it/s]\n","Embedding extraction: 1it [00:00, 27.96it/s]\n","Embedding extraction: 1it [00:00, 23.86it/s]\n","Embedding extraction: 1it [00:00, 24.32it/s]\n","Embedding extraction: 1it [00:00, 24.37it/s]\n","Embedding extraction: 1it [00:00, 23.86it/s]\n","Embedding extraction: 1it [00:00, 24.05it/s]\n","Embedding extraction: 1it [00:00, 24.26it/s]\n","Embedding extraction: 1it [00:00, 24.57it/s]\n","Embedding extraction: 1it [00:00, 24.14it/s]\n","Embedding extraction: 1it [00:00, 24.53it/s]\n","Embedding extraction: 1it [00:00, 23.19it/s]\n","Embedding extraction: 1it [00:00, 24.21it/s]\n","Embedding extraction: 1it [00:00, 23.64it/s]\n","Embedding extraction: 1it [00:00, 23.57it/s]\n","Embedding extraction: 1it [00:00, 23.80it/s]\n","Embedding extraction: 1it [00:00, 23.69it/s]\n","Embedding extraction: 1it [00:00, 22.84it/s]\n","Embedding extraction: 1it [00:00, 23.40it/s]\n","Embedding extraction: 1it [00:00, 24.20it/s]\n","Embedding extraction: 1it [00:00, 23.69it/s]\n","Embedding extraction: 1it [00:00, 23.76it/s]\n","Embedding extraction: 1it [00:00, 23.90it/s]\n","Embedding extraction: 1it [00:00, 23.95it/s]\n","Embedding extraction: 1it [00:00, 24.15it/s]\n","Embedding extraction: 1it [00:00, 27.69it/s]\n","Embedding extraction: 1it [00:00, 28.47it/s]\n","Embedding extraction: 1it [00:00, 28.10it/s]\n","Embedding extraction: 1it [00:00, 24.05it/s]\n","Embedding extraction: 1it [00:00, 23.04it/s]\n","Embedding extraction: 1it [00:00, 22.84it/s]\n","Embedding extraction: 1it [00:00, 20.40it/s]\n","Embedding extraction: 1it [00:00, 18.21it/s]\n","Embedding extraction: 1it [00:00, 19.73it/s]\n","Embedding extraction: 1it [00:00, 20.37it/s]\n","Embedding extraction: 1it [00:00, 17.33it/s]\n","Embedding extraction: 1it [00:00, 19.55it/s]\n","Embedding extraction: 1it [00:00, 18.74it/s]\n","Embedding extraction: 1it [00:00, 16.84it/s]\n","Embedding extraction: 1it [00:00, 18.82it/s]\n","Embedding extraction: 1it [00:00, 19.35it/s]\n","Embedding extraction: 1it [00:00, 18.43it/s]\n","Embedding extraction: 1it [00:00, 17.59it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 18.04it/s]\n","Embedding extraction: 1it [00:00, 17.68it/s]\n","Embedding extraction: 1it [00:00, 17.68it/s]\n","Embedding extraction: 1it [00:00, 17.66it/s]\n","Embedding extraction: 1it [00:00, 17.54it/s]\n","Embedding extraction: 1it [00:00, 16.65it/s]\n","Embedding extraction: 1it [00:00, 17.47it/s]\n","Embedding extraction: 1it [00:00, 17.10it/s]\n","Embedding extraction: 1it [00:00, 17.55it/s]\n","Embedding extraction: 1it [00:00, 18.52it/s]\n","Embedding extraction: 1it [00:00, 17.37it/s]\n","Embedding extraction: 1it [00:00, 16.70it/s]\n","Embedding extraction: 1it [00:00, 16.87it/s]\n","Embedding extraction: 1it [00:00, 17.23it/s]\n","Embedding extraction: 1it [00:00, 16.70it/s]\n","Embedding extraction: 1it [00:00, 18.66it/s]\n","Embedding extraction: 1it [00:00, 17.29it/s]\n","Embedding extraction: 1it [00:00, 18.62it/s]\n","Embedding extraction: 1it [00:00, 17.38it/s]\n","Embedding extraction: 1it [00:00, 17.38it/s]\n","Embedding extraction: 1it [00:00, 18.56it/s]\n","Embedding extraction: 1it [00:00, 17.36it/s]\n","Embedding extraction: 1it [00:00, 18.70it/s]\n","Embedding extraction: 1it [00:00, 18.76it/s]\n","Embedding extraction: 1it [00:00, 18.53it/s]\n","Embedding extraction: 1it [00:00, 17.65it/s]\n","Embedding extraction: 1it [00:00, 17.64it/s]\n","Embedding extraction: 1it [00:00, 17.61it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 17.67it/s]\n","Embedding extraction: 1it [00:00, 17.52it/s]\n","Embedding extraction: 1it [00:00, 16.88it/s]\n","Embedding extraction: 1it [00:00, 17.16it/s]\n","Embedding extraction: 1it [00:00, 18.59it/s]\n","Embedding extraction: 1it [00:00, 18.51it/s]\n","Embedding extraction: 1it [00:00, 17.27it/s]\n","Embedding extraction: 1it [00:00, 17.24it/s]\n","Embedding extraction: 1it [00:00, 18.50it/s]\n","Embedding extraction: 1it [00:00, 18.10it/s]\n","Embedding extraction: 1it [00:00, 17.39it/s]\n","Embedding extraction: 1it [00:00, 17.59it/s]\n","Embedding extraction: 1it [00:00, 17.39it/s]\n","Embedding extraction: 1it [00:00, 18.58it/s]\n","Embedding extraction: 1it [00:00, 18.48it/s]\n","Embedding extraction: 1it [00:00, 16.85it/s]\n","Embedding extraction: 1it [00:00, 16.71it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 17.26it/s]\n","Embedding extraction: 1it [00:00, 18.44it/s]\n","Embedding extraction: 1it [00:00, 18.66it/s]\n","Embedding extraction: 1it [00:00, 17.41it/s]\n","Embedding extraction: 1it [00:00, 17.38it/s]\n","Embedding extraction: 1it [00:00, 17.41it/s]\n","Embedding extraction: 1it [00:00, 17.43it/s]\n","Embedding extraction: 1it [00:00, 17.68it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 14.85it/s]\n","Embedding extraction: 1it [00:00, 11.79it/s]\n","Embedding extraction: 1it [00:00, 15.00it/s]\n","Embedding extraction: 1it [00:00, 18.10it/s]\n","Embedding extraction: 1it [00:00, 17.26it/s]\n","Embedding extraction: 1it [00:00, 16.39it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 16.94it/s]\n","Embedding extraction: 1it [00:00, 18.64it/s]\n","Embedding extraction: 1it [00:00, 16.81it/s]\n","Embedding extraction: 1it [00:00, 16.65it/s]\n","Embedding extraction: 1it [00:00, 16.16it/s]\n","Embedding extraction: 1it [00:00, 17.63it/s]\n","Embedding extraction: 1it [00:00, 16.70it/s]\n","Embedding extraction: 1it [00:00, 18.24it/s]\n","Embedding extraction: 1it [00:00, 18.05it/s]\n","Embedding extraction: 1it [00:00, 18.68it/s]\n","Embedding extraction: 1it [00:00, 19.52it/s]\n","Embedding extraction: 1it [00:00, 18.60it/s]\n","Embedding extraction: 1it [00:00, 17.62it/s]\n","Embedding extraction: 1it [00:00, 17.59it/s]\n","Embedding extraction: 1it [00:00, 17.35it/s]\n","Embedding extraction: 1it [00:00, 17.27it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 17.58it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 16.61it/s]\n","Embedding extraction: 1it [00:00, 17.54it/s]\n","Embedding extraction: 1it [00:00, 17.01it/s]\n","Embedding extraction: 1it [00:00, 17.39it/s]\n","Embedding extraction: 1it [00:00, 17.55it/s]\n","Embedding extraction: 1it [00:00, 17.44it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 16.92it/s]\n","Embedding extraction: 1it [00:00, 17.41it/s]\n","Embedding extraction: 1it [00:00, 16.06it/s]\n","Embedding extraction: 1it [00:00, 17.35it/s]\n","Embedding extraction: 1it [00:00, 17.34it/s]\n","Embedding extraction: 1it [00:00, 17.41it/s]\n","Embedding extraction: 1it [00:00, 17.34it/s]\n","Embedding extraction: 1it [00:00, 18.55it/s]\n","Embedding extraction: 1it [00:00, 18.78it/s]\n","Embedding extraction: 1it [00:00, 18.48it/s]\n","Embedding extraction: 1it [00:00, 18.96it/s]\n","Embedding extraction: 1it [00:00, 18.70it/s]\n","Embedding extraction: 1it [00:00, 17.58it/s]\n","Embedding extraction: 1it [00:00, 17.61it/s]\n","Embedding extraction: 1it [00:00, 17.17it/s]\n","Embedding extraction: 1it [00:00, 17.30it/s]\n","Embedding extraction: 1it [00:00, 17.98it/s]\n","Embedding extraction: 1it [00:00, 18.86it/s]\n","Embedding extraction: 1it [00:00, 19.11it/s]\n","Embedding extraction: 1it [00:00, 18.72it/s]\n","Embedding extraction: 1it [00:00, 18.70it/s]\n","Embedding extraction: 1it [00:00, 17.75it/s]\n","Embedding extraction: 1it [00:00, 17.84it/s]\n","Embedding extraction: 1it [00:00, 17.27it/s]\n","Embedding extraction: 1it [00:00, 17.21it/s]\n","Embedding extraction: 1it [00:00, 17.34it/s]\n","Embedding extraction: 1it [00:00, 17.68it/s]\n","Embedding extraction: 1it [00:00, 17.26it/s]\n","Embedding extraction: 1it [00:00, 17.24it/s]\n","Embedding extraction: 1it [00:00, 17.61it/s]\n","Embedding extraction: 1it [00:00, 17.58it/s]\n","Embedding extraction: 1it [00:00, 17.46it/s]\n","Embedding extraction: 1it [00:00, 17.23it/s]\n","Embedding extraction: 1it [00:00, 17.63it/s]\n","Embedding extraction: 1it [00:00, 17.50it/s]\n","Embedding extraction: 1it [00:00, 18.76it/s]\n","Embedding extraction: 1it [00:00, 18.59it/s]\n","Embedding extraction: 1it [00:00, 18.59it/s]\n","Embedding extraction: 1it [00:00, 18.47it/s]\n","Embedding extraction: 1it [00:00, 17.41it/s]\n","Embedding extraction: 1it [00:00, 17.65it/s]\n","Embedding extraction: 1it [00:00, 17.64it/s]\n","Embedding extraction: 1it [00:00, 17.66it/s]\n","Embedding extraction: 1it [00:00, 16.47it/s]\n","Embedding extraction: 1it [00:00, 17.27it/s]\n","Embedding extraction: 1it [00:00, 17.22it/s]\n","Embedding extraction: 1it [00:00, 17.52it/s]\n","Embedding extraction: 1it [00:00, 17.49it/s]\n","Embedding extraction: 1it [00:00, 17.50it/s]\n","Embedding extraction: 1it [00:00, 17.70it/s]\n","Embedding extraction: 1it [00:00, 17.64it/s]\n","Embedding extraction: 1it [00:00, 17.43it/s]\n","Embedding extraction: 1it [00:00, 17.54it/s]\n","Embedding extraction: 1it [00:00, 16.91it/s]\n","Embedding extraction: 1it [00:00, 17.54it/s]\n","Embedding extraction: 1it [00:00, 16.63it/s]\n","Embedding extraction: 1it [00:00, 16.85it/s]\n","Embedding extraction: 1it [00:00, 17.39it/s]\n","Embedding extraction: 1it [00:00, 16.98it/s]\n","Embedding extraction: 1it [00:00, 18.49it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 17.58it/s]\n","Embedding extraction: 1it [00:00, 17.32it/s]\n","Embedding extraction: 1it [00:00, 17.29it/s]\n","Embedding extraction: 1it [00:00, 17.56it/s]\n","Embedding extraction: 1it [00:00, 17.58it/s]\n","Embedding extraction: 1it [00:00, 17.23it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 17.28it/s]\n","Embedding extraction: 1it [00:00, 17.13it/s]\n","Embedding extraction: 1it [00:00, 18.13it/s]\n","Embedding extraction: 1it [00:00, 17.59it/s]\n","Embedding extraction: 1it [00:00, 17.57it/s]\n","Embedding extraction: 1it [00:00, 17.39it/s]\n","Embedding extraction: 1it [00:00, 17.64it/s]\n","Embedding extraction: 1it [00:00, 17.43it/s]\n","Embedding extraction: 1it [00:00, 17.25it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 17.44it/s]\n","Embedding extraction: 1it [00:00, 17.72it/s]\n","Embedding extraction: 1it [00:00, 17.56it/s]\n","Embedding extraction: 1it [00:00, 17.35it/s]\n","Embedding extraction: 1it [00:00, 18.46it/s]\n","Embedding extraction: 1it [00:00, 18.71it/s]\n","Embedding extraction: 1it [00:00, 17.33it/s]\n","Embedding extraction: 1it [00:00, 18.68it/s]\n","Embedding extraction: 1it [00:00, 16.96it/s]\n","Embedding extraction: 1it [00:00, 18.43it/s]\n","Embedding extraction: 1it [00:00, 18.35it/s]\n","Embedding extraction: 1it [00:00, 18.70it/s]\n","Embedding extraction: 1it [00:00, 18.69it/s]\n","Embedding extraction: 1it [00:00, 18.73it/s]\n","Embedding extraction: 1it [00:00, 18.62it/s]\n","Embedding extraction: 1it [00:00, 18.73it/s]\n","Embedding extraction: 1it [00:00, 19.40it/s]\n","Embedding extraction: 1it [00:00, 19.43it/s]\n","Embedding extraction: 1it [00:00, 19.35it/s]\n","Embedding extraction: 1it [00:00, 19.71it/s]\n","Embedding extraction: 1it [00:00, 18.72it/s]\n","Embedding extraction: 1it [00:00, 16.81it/s]\n","Embedding extraction: 1it [00:00, 18.27it/s]\n","Embedding extraction: 1it [00:00, 18.63it/s]\n","Embedding extraction: 1it [00:00, 18.65it/s]\n","Embedding extraction: 1it [00:00, 18.56it/s]\n","Embedding extraction: 1it [00:00, 18.22it/s]\n","Embedding extraction: 1it [00:00, 17.91it/s]\n","Embedding extraction: 1it [00:00, 18.70it/s]\n","Embedding extraction: 1it [00:00, 18.51it/s]\n","Embedding extraction: 1it [00:00, 17.47it/s]\n","Embedding extraction: 1it [00:00, 17.31it/s]\n","Embedding extraction: 1it [00:00, 17.45it/s]\n","Embedding extraction: 1it [00:00, 16.59it/s]\n","Embedding extraction: 1it [00:00, 16.84it/s]\n","Embedding extraction: 1it [00:00, 16.81it/s]\n","Embedding extraction: 1it [00:00, 17.65it/s]\n","Embedding extraction: 1it [00:00, 17.20it/s]\n","Embedding extraction: 1it [00:00, 17.61it/s]\n","Embedding extraction: 1it [00:00, 17.33it/s]\n","Embedding extraction: 1it [00:00, 17.28it/s]\n","Embedding extraction: 1it [00:00, 17.32it/s]\n","Embedding extraction: 1it [00:00, 17.71it/s]\n","Embedding extraction: 1it [00:00, 17.52it/s]\n","Embedding extraction: 1it [00:00, 16.93it/s]\n","Embedding extraction: 1it [00:00, 17.54it/s]\n","Embedding extraction: 1it [00:00, 17.62it/s]\n","Embedding extraction: 1it [00:00, 17.37it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 17.40it/s]\n","Embedding extraction: 1it [00:00, 17.64it/s]\n","Embedding extraction: 1it [00:00, 17.40it/s]\n","Embedding extraction: 1it [00:00, 17.00it/s]\n","Embedding extraction: 1it [00:00, 17.40it/s]\n","Embedding extraction: 1it [00:00, 17.54it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 17.60it/s]\n","Embedding extraction: 1it [00:00, 17.26it/s]\n","Embedding extraction: 1it [00:00, 17.43it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 16.83it/s]\n","Embedding extraction: 1it [00:00, 17.66it/s]\n","Embedding extraction: 1it [00:00, 17.38it/s]\n","Embedding extraction: 1it [00:00, 17.71it/s]\n","Embedding extraction: 1it [00:00, 17.63it/s]\n","Embedding extraction: 1it [00:00, 17.55it/s]\n","Embedding extraction: 1it [00:00, 17.41it/s]\n","Embedding extraction: 1it [00:00, 17.43it/s]\n","Embedding extraction: 1it [00:00, 17.48it/s]\n","Embedding extraction: 1it [00:00, 17.48it/s]\n","Embedding extraction: 1it [00:00, 17.44it/s]\n","Embedding extraction: 1it [00:00, 17.60it/s]\n","Embedding extraction: 1it [00:00, 17.27it/s]\n","Embedding extraction: 1it [00:00, 17.65it/s]\n","Embedding extraction: 1it [00:00, 17.33it/s]\n","Embedding extraction: 1it [00:00, 17.33it/s]\n","Embedding extraction: 1it [00:00, 18.78it/s]\n","Embedding extraction: 1it [00:00, 17.26it/s]\n","Embedding extraction: 1it [00:00, 17.38it/s]\n","Embedding extraction: 1it [00:00, 18.85it/s]\n","Embedding extraction: 1it [00:00, 17.96it/s]\n","Embedding extraction: 1it [00:00, 19.31it/s]\n","Embedding extraction: 1it [00:00, 19.15it/s]\n","Embedding extraction: 1it [00:00, 18.61it/s]\n","Embedding extraction: 1it [00:00, 19.29it/s]\n","Embedding extraction: 1it [00:00, 19.03it/s]\n","Embedding extraction: 1it [00:00, 19.12it/s]\n","Embedding extraction: 1it [00:00, 17.79it/s]\n","Embedding extraction: 1it [00:00, 19.08it/s]\n","Embedding extraction: 1it [00:00, 19.34it/s]\n","Embedding extraction: 1it [00:00, 18.55it/s]\n","Embedding extraction: 1it [00:00, 17.40it/s]\n","Embedding extraction: 1it [00:00, 17.51it/s]\n","Embedding extraction: 1it [00:00, 17.29it/s]\n","Embedding extraction: 1it [00:00, 17.55it/s]\n","Embedding extraction: 1it [00:00, 17.61it/s]\n","Embedding extraction: 1it [00:00, 17.48it/s]\n","Embedding extraction: 1it [00:00, 17.62it/s]\n","Embedding extraction: 1it [00:00, 17.49it/s]\n","Embedding extraction: 1it [00:00, 17.64it/s]\n","Embedding extraction: 1it [00:00, 17.35it/s]\n","Embedding extraction: 1it [00:00, 17.46it/s]\n","Embedding extraction: 1it [00:00, 17.57it/s]\n","Embedding extraction: 1it [00:00, 16.15it/s]\n","Embedding extraction: 1it [00:00, 18.60it/s]\n","Embedding extraction: 1it [00:00, 19.84it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 17.66it/s]\n","Embedding extraction: 1it [00:00, 17.35it/s]\n","Embedding extraction: 1it [00:00, 19.88it/s]\n","Embedding extraction: 1it [00:00, 18.62it/s]\n","Embedding extraction: 1it [00:00, 17.61it/s]\n","Embedding extraction: 1it [00:00, 19.27it/s]\n","Embedding extraction: 1it [00:00, 19.68it/s]\n","Embedding extraction: 1it [00:00, 19.76it/s]\n","Embedding extraction: 1it [00:00, 19.76it/s]\n","Embedding extraction: 1it [00:00, 20.50it/s]\n","Embedding extraction: 1it [00:00, 19.77it/s]\n","Embedding extraction: 1it [00:00, 19.64it/s]\n","Embedding extraction: 1it [00:00, 18.75it/s]\n","Embedding extraction: 1it [00:00, 18.93it/s]\n","Embedding extraction: 1it [00:00, 18.19it/s]\n","Embedding extraction: 1it [00:00, 17.98it/s]\n","Embedding extraction: 1it [00:00, 17.32it/s]\n","Embedding extraction: 1it [00:00, 17.72it/s]\n","Embedding extraction: 1it [00:00, 18.07it/s]\n","Embedding extraction: 1it [00:00, 17.89it/s]\n","Embedding extraction: 1it [00:00, 17.50it/s]\n","Embedding extraction: 1it [00:00, 17.98it/s]\n","Embedding extraction: 1it [00:00, 19.35it/s]\n","Embedding extraction: 1it [00:00, 18.95it/s]\n","Embedding extraction: 1it [00:00, 18.58it/s]\n","Embedding extraction: 1it [00:00, 17.60it/s]\n","Embedding extraction: 1it [00:00, 18.65it/s]\n","Embedding extraction: 1it [00:00, 18.76it/s]\n","Embedding extraction: 1it [00:00, 18.55it/s]\n","Embedding extraction: 1it [00:00, 18.71it/s]\n","Embedding extraction: 1it [00:00, 18.55it/s]\n","Embedding extraction: 1it [00:00, 18.71it/s]\n","Embedding extraction: 1it [00:00, 16.80it/s]\n","Embedding extraction: 1it [00:00, 18.27it/s]\n","Embedding extraction: 1it [00:00, 17.38it/s]\n","Embedding extraction: 1it [00:00, 17.62it/s]\n","Embedding extraction: 1it [00:00, 18.47it/s]\n","Embedding extraction: 1it [00:00, 18.23it/s]\n","Embedding extraction: 1it [00:00, 18.71it/s]\n","Embedding extraction: 1it [00:00, 18.53it/s]\n","Embedding extraction: 1it [00:00, 17.29it/s]\n","Embedding extraction: 1it [00:00, 19.64it/s]\n","Embedding extraction: 1it [00:00, 19.50it/s]\n","Embedding extraction: 1it [00:00, 19.78it/s]\n","Embedding extraction: 1it [00:00, 19.62it/s]\n","Embedding extraction: 1it [00:00, 19.52it/s]\n","Embedding extraction: 1it [00:00, 19.32it/s]\n","Embedding extraction: 1it [00:00, 19.70it/s]\n","Embedding extraction: 1it [00:00, 18.54it/s]\n","Embedding extraction: 1it [00:00, 18.61it/s]\n","Embedding extraction: 1it [00:00, 18.55it/s]\n","Embedding extraction: 1it [00:00, 20.56it/s]\n","Embedding extraction: 1it [00:00, 20.61it/s]\n","Embedding extraction: 1it [00:00, 20.69it/s]\n","Embedding extraction: 1it [00:00, 19.07it/s]\n","Embedding extraction: 1it [00:00, 18.81it/s]\n","Embedding extraction: 1it [00:00, 18.61it/s]\n","Embedding extraction: 1it [00:00, 17.40it/s]\n","Embedding extraction: 1it [00:00, 18.29it/s]\n","Embedding extraction: 1it [00:00, 18.75it/s]\n","Embedding extraction: 1it [00:00, 18.51it/s]\n","Embedding extraction: 1it [00:00, 19.77it/s]\n","Embedding extraction: 1it [00:00, 18.51it/s]\n","Embedding extraction: 1it [00:00, 18.45it/s]\n","Embedding extraction: 1it [00:00, 18.77it/s]\n","Embedding extraction: 1it [00:00, 18.63it/s]\n","Embedding extraction: 1it [00:00, 17.60it/s]\n","Embedding extraction: 1it [00:00, 19.67it/s]\n","Embedding extraction: 1it [00:00, 18.68it/s]\n","Embedding extraction: 1it [00:00, 18.65it/s]\n","Embedding extraction: 1it [00:00, 17.73it/s]\n","Embedding extraction: 1it [00:00, 18.71it/s]\n","Embedding extraction: 1it [00:00, 17.44it/s]\n","Embedding extraction: 1it [00:00, 17.21it/s]\n","Embedding extraction: 1it [00:00, 19.87it/s]\n","Embedding extraction: 1it [00:00, 18.85it/s]\n","Embedding extraction: 1it [00:00, 17.62it/s]\n","Embedding extraction: 1it [00:00, 16.22it/s]\n","Embedding extraction: 1it [00:00, 16.48it/s]\n","Embedding extraction: 1it [00:00, 16.58it/s]\n","Embedding extraction: 1it [00:00, 16.89it/s]\n","Embedding extraction: 1it [00:00, 16.82it/s]\n","Embedding extraction: 1it [00:00, 15.92it/s]\n","Embedding extraction: 1it [00:00, 18.68it/s]\n","Embedding extraction: 1it [00:00, 17.58it/s]\n","Embedding extraction: 1it [00:00, 18.73it/s]\n","Embedding extraction: 1it [00:00, 19.80it/s]\n","Embedding extraction: 1it [00:00, 17.59it/s]\n","Embedding extraction: 1it [00:00, 17.50it/s]\n","Embedding extraction: 1it [00:00, 15.20it/s]\n","Embedding extraction: 1it [00:00, 15.80it/s]\n","Embedding extraction: 1it [00:00, 15.80it/s]\n","Embedding extraction: 1it [00:00, 16.93it/s]\n","Embedding extraction: 1it [00:00, 16.75it/s]\n","Embedding extraction: 1it [00:00, 16.76it/s]\n","Embedding extraction: 1it [00:00, 17.63it/s]\n","Embedding extraction: 1it [00:00, 19.32it/s]\n","Embedding extraction: 1it [00:00, 16.89it/s]\n","Embedding extraction: 1it [00:00, 17.55it/s]\n","Embedding extraction: 1it [00:00, 18.09it/s]\n","Embedding extraction: 1it [00:00, 18.73it/s]\n","Embedding extraction: 1it [00:00, 17.54it/s]\n","Embedding extraction: 1it [00:00, 16.54it/s]\n","Embedding extraction: 1it [00:00, 17.43it/s]\n","Embedding extraction: 1it [00:00, 16.83it/s]\n","Embedding extraction: 1it [00:00, 16.99it/s]\n","Embedding extraction: 1it [00:00, 16.79it/s]\n","Embedding extraction: 1it [00:00, 17.57it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 18.67it/s]\n","Embedding extraction: 1it [00:00, 18.57it/s]\n","Embedding extraction: 1it [00:00, 18.38it/s]\n","Embedding extraction: 1it [00:00, 17.40it/s]\n","Embedding extraction: 1it [00:00, 18.73it/s]\n","Embedding extraction: 1it [00:00, 19.50it/s]\n","Embedding extraction: 1it [00:00, 17.27it/s]\n","Embedding extraction: 1it [00:00, 17.32it/s]\n","Embedding extraction: 1it [00:00, 17.64it/s]\n","Embedding extraction: 1it [00:00, 17.57it/s]\n","Embedding extraction: 1it [00:00, 17.46it/s]\n","Embedding extraction: 1it [00:00, 17.56it/s]\n","Embedding extraction: 1it [00:00, 17.35it/s]\n","Embedding extraction: 1it [00:00, 17.65it/s]\n","Embedding extraction: 1it [00:00, 18.54it/s]\n","Embedding extraction: 1it [00:00, 18.73it/s]\n","Embedding extraction: 1it [00:00, 17.50it/s]\n","Embedding extraction: 1it [00:00, 17.43it/s]\n","Embedding extraction: 1it [00:00, 17.52it/s]\n","Embedding extraction: 1it [00:00, 17.65it/s]\n","Embedding extraction: 1it [00:00, 16.80it/s]\n","Embedding extraction: 1it [00:00, 16.49it/s]\n","Embedding extraction: 1it [00:00, 16.78it/s]\n","Embedding extraction: 1it [00:00, 16.77it/s]\n","Embedding extraction: 1it [00:00, 17.66it/s]\n","Embedding extraction: 1it [00:00, 18.57it/s]\n","Embedding extraction: 1it [00:00, 15.93it/s]\n","Embedding extraction: 1it [00:00, 17.67it/s]\n","Embedding extraction: 1it [00:00, 16.80it/s]\n","Embedding extraction: 1it [00:00, 16.69it/s]\n","Embedding extraction: 1it [00:00, 17.32it/s]\n","Embedding extraction: 1it [00:00, 16.69it/s]\n","Embedding extraction: 1it [00:00, 16.82it/s]\n","Embedding extraction: 1it [00:00, 16.58it/s]\n","Embedding extraction: 1it [00:00, 16.73it/s]\n","Embedding extraction: 1it [00:00, 16.89it/s]\n","Embedding extraction: 1it [00:00, 16.66it/s]\n","Embedding extraction: 1it [00:00, 16.59it/s]\n","Embedding extraction: 1it [00:00, 16.50it/s]\n","Embedding extraction: 1it [00:00, 16.90it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 16.75it/s]\n","Embedding extraction: 1it [00:00, 16.97it/s]\n","Embedding extraction: 1it [00:00, 17.02it/s]\n","Embedding extraction: 1it [00:00, 16.69it/s]\n","Embedding extraction: 1it [00:00, 17.59it/s]\n","Embedding extraction: 1it [00:00, 17.36it/s]\n","Embedding extraction: 1it [00:00, 18.60it/s]\n","Embedding extraction: 1it [00:00, 17.70it/s]\n","Embedding extraction: 1it [00:00, 17.96it/s]\n","Embedding extraction: 1it [00:00, 17.78it/s]\n","Embedding extraction: 1it [00:00, 17.69it/s]\n","Embedding extraction: 1it [00:00, 17.16it/s]\n","Embedding extraction: 1it [00:00, 17.01it/s]\n","Embedding extraction: 1it [00:00, 17.10it/s]\n","Embedding extraction: 1it [00:00, 17.23it/s]\n","Embedding extraction: 1it [00:00, 16.82it/s]\n","Embedding extraction: 1it [00:00, 18.64it/s]\n","Embedding extraction: 1it [00:00, 18.77it/s]\n","Embedding extraction: 1it [00:00, 18.50it/s]\n","Embedding extraction: 1it [00:00, 18.63it/s]\n","Embedding extraction: 1it [00:00, 18.38it/s]\n","Embedding extraction: 1it [00:00, 17.05it/s]\n","Embedding extraction: 1it [00:00, 18.76it/s]\n","Embedding extraction: 1it [00:00, 18.55it/s]\n","Embedding extraction: 1it [00:00, 18.70it/s]\n","Embedding extraction: 1it [00:00, 19.53it/s]\n","Embedding extraction: 1it [00:00, 17.52it/s]\n","Embedding extraction: 1it [00:00, 18.72it/s]\n","Embedding extraction: 1it [00:00, 18.76it/s]\n","Embedding extraction: 1it [00:00, 17.38it/s]\n","Embedding extraction: 1it [00:00, 17.40it/s]\n","Embedding extraction: 1it [00:00, 17.63it/s]\n","Embedding extraction: 1it [00:00, 17.39it/s]\n","Embedding extraction: 1it [00:00, 17.41it/s]\n","Embedding extraction: 1it [00:00, 17.65it/s]\n","Embedding extraction: 1it [00:00, 17.49it/s]\n","Embedding extraction: 1it [00:00, 17.30it/s]\n","Embedding extraction: 1it [00:00, 17.42it/s]\n","Embedding extraction: 1it [00:00, 17.51it/s]\n","Embedding extraction: 1it [00:00, 18.54it/s]\n","Embedding extraction: 1it [00:00, 18.71it/s]\n","Embedding extraction: 1it [00:00, 17.34it/s]\n","Embedding extraction: 1it [00:00, 17.63it/s]\n","Embedding extraction: 1it [00:00, 17.65it/s]\n","Embedding extraction: 1it [00:00, 18.58it/s]\n","Embedding extraction: 1it [00:00, 18.44it/s]\n","Embedding extraction: 1it [00:00, 18.40it/s]\n","Embedding extraction: 1it [00:00, 17.14it/s]\n","Embedding extraction: 1it [00:00, 17.66it/s]\n","Embedding extraction: 1it [00:00, 17.50it/s]\n","Embedding extraction: 1it [00:00, 17.39it/s]\n","Embedding extraction: 1it [00:00, 18.54it/s]\n","Embedding extraction: 1it [00:00, 18.06it/s]\n","Embedding extraction: 1it [00:00, 18.71it/s]\n","Embedding extraction: 1it [00:00, 17.25it/s]\n","Embedding extraction: 1it [00:00, 17.37it/s]\n","Embedding extraction: 1it [00:00, 18.83it/s]\n","Embedding extraction: 1it [00:00, 17.41it/s]\n","Embedding extraction: 1it [00:00, 17.48it/s]\n","Embedding extraction: 1it [00:00, 16.92it/s]\n","Embedding extraction: 1it [00:00, 17.50it/s]\n","Embedding extraction: 1it [00:00, 16.77it/s]\n","Embedding extraction: 1it [00:00, 16.70it/s]\n","Embedding extraction: 1it [00:00, 16.67it/s]\n","Embedding extraction: 1it [00:00, 16.91it/s]\n","Embedding extraction: 1it [00:00, 17.45it/s]\n","Embedding extraction: 1it [00:00, 18.57it/s]\n","Embedding extraction: 1it [00:00, 17.98it/s]\n","Embedding extraction: 1it [00:00, 16.86it/s]\n","Embedding extraction: 1it [00:00, 16.77it/s]\n","Embedding extraction: 1it [00:00, 18.56it/s]\n","Embedding extraction: 1it [00:00, 18.72it/s]\n","Embedding extraction: 1it [00:00, 17.61it/s]\n","Embedding extraction: 1it [00:00, 17.20it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 17.47it/s]\n","Embedding extraction: 1it [00:00, 17.66it/s]\n","Embedding extraction: 1it [00:00, 17.48it/s]\n","Embedding extraction: 1it [00:00, 17.53it/s]\n","Embedding extraction: 1it [00:00, 16.91it/s]\n","Embedding extraction: 1it [00:00, 16.74it/s]\n","Embedding extraction: 1it [00:00, 17.44it/s]\n","Embedding extraction: 1it [00:00, 17.40it/s]\n","Embedding extraction: 1it [00:00, 17.58it/s]\n","Embedding extraction: 1it [00:00, 17.41it/s]\n","Embedding extraction: 1it [00:00, 16.59it/s]\n","Embedding extraction: 1it [00:00, 16.69it/s]\n","Embedding extraction: 1it [00:00, 16.74it/s]\n","Embedding extraction: 1it [00:00, 16.58it/s]\n","Embedding extraction: 1it [00:00, 17.59it/s]\n","Embedding extraction: 1it [00:00, 17.37it/s]\n","Embedding extraction: 1it [00:00, 16.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Final Game Statistics:\n","TEAM A Possession: 0.0%\n","TEAM A Total Passes: 0\n","TEAM B Possession: 0.0%\n","TEAM B Total Passes: 0\n"]}],"source":["from PIL import Image, ImageDraw, ImageFont\n","import matplotlib.pyplot as plt\n","import os\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n","from scipy.ndimage import gaussian_filter\n","\n","CONFIG = SoccerPitchConfiguration()\n","\n","#Constants\n","PLAYER_DETECTION_MODEL_PATH = '/content/drive/MyDrive/YOLOv8_PlayerDetection/YOLOv8_PlayerDetection/best.pt'\n","FIELD_DETECTION_MODEL_PATH = '/content/drive/MyDrive/YOLOv8_weights/YOLOv8_weights/football_field_keypoints/weights/best.pt'\n","SOURCE_VIDEO_PATH = \"/content/drive/MyDrive/Input_Videos/testing/2.mp4\"\n","TARGET_VIDEO_PATH = \"/content/drive/MyDrive/Output_Videos/results.mp4\"\n","BALL_ID = 0\n","GOALKEEPER_ID = 1\n","PLAYER_ID = 2\n","REFEREE_ID = 3\n","STRIDE = 30\n","MAXLEN = 5\n","MAX_DISTANCE_THRESHOLD = 500\n","team_classifier = TeamClassifier(device=\"cuda\")\n","\n","PLAYER_DETECTION_MODEL = YOLO(PLAYER_DETECTION_MODEL_PATH)\n","FIELD_DETECTION_MODEL = YOLO(FIELD_DETECTION_MODEL_PATH)\n","\n","#Function to track players across frames\n","def get_object_tracks(frames):\n","    tracks =[]\n","\n","    # Run detection for each frame\n","    for frame in frames:\n","        player_result = PLAYER_DETECTION_MODEL.predict(frame, conf=0.3)[0] #Detect players in the current frame using the trained YOLOv8 model\n","        detections = sv.Detections.from_ultralytics(player_result) #converts detection results to a standarized format (supervision)\n","\n","        # Collect the detections into a tracks list\n","        tracks.append(detections)\n","\n","    return tracks\n","\n","#Function to track keypoints across the frames\n","def get_keypoint_tracks(frames):\n","    keypoint_tracks = []\n","    # Run keypoint detection for each frame\n","    for frame in frames:\n","        field_result = FIELD_DETECTION_MODEL.predict(frame, conf=0.3)[0]\n","        key_points = sv.KeyPoints.from_ultralytics(field_result)\n","        keypoint_tracks.append(key_points)\n","\n","    return keypoint_tracks\n","\n","#Function to collect crops of players across frames\n","def collect_player_crops(frames, player_id=2, stride=STRIDE): #Frame sampling interval to reduce processing\n","\n","    crops = []\n","    frame_generator = frames[::stride]  # Skip frames based on stride\n","\n","    for frame in tqdm(frame_generator, desc='collecting player crops'):\n","        result = PLAYER_DETECTION_MODEL.predict(frame, conf=0.3)[0]\n","        detections = sv.Detections.from_ultralytics(result)\n","        detections = detections.with_nms(threshold=0.5, class_agnostic=True) #Applies a non-max suppresion to remove overlapping detections\n","        detections = detections[detections.class_id == player_id] #Filter detections for the player class\n","\n","        # Crop each detected player and add to crops list\n","        for xyxy in detections.xyxy:\n","            crop = sv.crop_image(frame, xyxy)\n","            crops.append(crop)\n","\n","    team_classifier.fit(crops) #Train a team classifier with the collected crops\n","\n","    return crops\n","\n","#Function to Determine the team ID of goalkeepers based on team centroids\n","def resolve_goalkeepers_team_id(\n","    players: sv.Detections,\n","    goalkeepers: sv.Detections\n",") -> np.ndarray:\n","\n","    #Get anchor points for goalkeepers and players\n","    goalkeepers_xy = goalkeepers.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n","    players_xy = players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n","\n","    #Calculate the centroids for each team(with class_id 0 and 1)\n","    team_0_centroid = players_xy[players.class_id == 0].mean(axis=0)\n","    team_1_centroid = players_xy[players.class_id == 1].mean(axis=0)\n","    goalkeepers_team_id = []\n","\n","    #Assign each goalkeeper to the nearest team's centroid\n","    for goalkeeper_xy in goalkeepers_xy:\n","        dist_0 = np.linalg.norm(goalkeeper_xy - team_0_centroid)\n","        dist_1 = np.linalg.norm(goalkeeper_xy - team_1_centroid)\n","        goalkeepers_team_id.append(0 if dist_0 < dist_1 else 1)\n","\n","    return np.array(goalkeepers_team_id)\n","\n","#Function to calculate the center of a bounding box\n","def get_bbox_center(bbox):\n","    x1, y1, x2, y2 = bbox\n","    center_x = (x1 + x2) / 2\n","    center_y = (y1 + y2) / 2\n","    return np.array([center_x, center_y])\n","\n","#Generates an annotated pitch overlay and adds it as a semi-transparent overlay\n","def add_transparent_overlay(\n","    frame, #frame (np.array): The original video frame\n","    CONFIG, #Configuration settings for the pitch drawing functions\n","    pitch_ball_xy, #Coordinates for the ball on the pitch\n","    pitch_players_xy, #Coordinates for players on the pitch\n","    players_detections, #Detections indicating player classes (team 0 and team 1)\n","    pitch_referees_xy, #Coordinates for referees on the pitch\n","    overlay_scale=0.45, #Scale for resizing the overlay relative to the frame\n","    alpha=0.6, #Transparency level for the overlay (0 = fully transparent, 1 = fully opaque)\n","    x_offset=10, #X-position offset for placing the overlay on the frame\n","    y_offset=None): #Y-position offset for placing the overlay. If None, positions it near the bottom of the frame\n","\n","    # Step 1: Generate the annotated pitch overlay\n","    annotated_pitch = draw_pitch(CONFIG)\n","    annotated_pitch = draw_points_on_pitch(\n","        config=CONFIG,\n","        xy=pitch_ball_xy,\n","        face_color=sv.Color.WHITE,\n","        edge_color=sv.Color.BLACK,\n","        radius=10,\n","        pitch=annotated_pitch\n","    )\n","    annotated_pitch = draw_points_on_pitch(\n","        config=CONFIG,\n","        xy=pitch_players_xy[players_detections.class_id == 0],\n","        face_color=sv.Color.from_hex('00BFFF'),\n","        edge_color=sv.Color.BLACK,\n","        radius=16,\n","        pitch=annotated_pitch\n","    )\n","    annotated_pitch = draw_points_on_pitch(\n","        config=CONFIG,\n","        xy=pitch_players_xy[players_detections.class_id == 1],\n","        face_color=sv.Color.from_hex('FF1493'),\n","        edge_color=sv.Color.BLACK,\n","        radius=16,\n","        pitch=annotated_pitch\n","    )\n","    annotated_pitch = draw_points_on_pitch(\n","        config=CONFIG,\n","        xy=pitch_referees_xy,\n","        face_color=sv.Color.from_hex('FFD700'),\n","        edge_color=sv.Color.BLACK,\n","        radius=16,\n","        pitch=annotated_pitch\n","    )\n","\n","    # Step 2: Resize the annotated pitch overlay\n","    overlay_height, overlay_width = int(annotated_pitch.shape[0] * overlay_scale), int(annotated_pitch.shape[1] * overlay_scale)\n","    resized_overlay = cv2.resize(annotated_pitch, (overlay_width, overlay_height))\n","\n","    # Step 3: Determine the position for the overlay\n","    frame_height, frame_width = frame.shape[:2]\n","    if y_offset is None:\n","        y_offset = frame_height - overlay_height - 10  # Position near the bottom of the frame if y_offset is not specified\n","\n","    # Step 4: Define the region of interest (ROI) in the frame where the overlay will be placed\n","    roi = frame[y_offset:y_offset+overlay_height, x_offset:x_offset+overlay_width]\n","\n","    # Step 5: Blend the overlay with the ROI\n","    blended_overlay = cv2.addWeighted(roi, 1 - alpha, resized_overlay, alpha, 0)\n","\n","    # Step 6: Insert the blended overlay back into the frame\n","    frame[y_offset:y_offset+overlay_height, x_offset:x_offset+overlay_width] = blended_overlay\n","\n","    return frame\n","\n","#Functions to draw a Voronoi Diagram representing the control areas of the two teams\n","def draw_pitch_voronoi_diagram_2(\n","    config: SoccerPitchConfiguration, #Contains pitch dimensions\n","    team_1_xy: np.ndarray, #Positions of team 1 players\n","    team_2_xy: np.ndarray, #Positions of team 2 players\n","    team_1_color: sv.Color = sv.Color.RED, #Color for team 1\n","    team_2_color: sv.Color = sv.Color.WHITE, #Color for team 2\n","    opacity: float = 0.5, #Transparency of the overlay\n","    padding: int = 50, #Padding around the pitch\n","    scale: float = 0.1, #Scale factor for dimensions\n","    pitch: Optional[np.ndarray] = None #Optional existing pitch image\n",") -> np.ndarray: #Image of football field with the Voronoi Diagram overlay\n","\n","    if pitch is None:\n","        pitch = draw_pitch(\n","            config=config,\n","            padding=padding,\n","            scale=scale\n","        )\n","\n","    scaled_width = int(config.width * scale)\n","    scaled_length = int(config.length * scale)\n","\n","    voronoi = np.zeros_like(pitch, dtype=np.uint8)\n","\n","    team_1_color_bgr = np.array(team_1_color.as_bgr(), dtype=np.uint8)\n","    team_2_color_bgr = np.array(team_2_color.as_bgr(), dtype=np.uint8)\n","\n","    y_coordinates, x_coordinates = np.indices((\n","        scaled_width + 2 * padding,\n","        scaled_length + 2 * padding\n","    ))\n","\n","    y_coordinates -= padding\n","    x_coordinates -= padding\n","\n","    def calculate_distances(xy, x_coordinates, y_coordinates):\n","        return np.sqrt((xy[:, 0][:, None, None] * scale - x_coordinates) ** 2 +\n","                        (xy[:, 1][:, None, None] * scale - y_coordinates) ** 2)\n","\n","    distances_team_1 = calculate_distances(team_1_xy, x_coordinates, y_coordinates)\n","    distances_team_2 = calculate_distances(team_2_xy, x_coordinates, y_coordinates)\n","\n","    min_distances_team_1 = np.min(distances_team_1, axis=0)\n","    min_distances_team_2 = np.min(distances_team_2, axis=0)\n","\n","    # Increase steepness of the blend effect\n","    steepness = 15  # Increased steepness for sharper transition\n","    distance_ratio = min_distances_team_2 / np.clip(min_distances_team_1 + min_distances_team_2, a_min=1e-5, a_max=None)\n","    blend_factor = np.tanh((distance_ratio - 0.5) * steepness) * 0.5 + 0.5\n","\n","    # Create the smooth color transition\n","    for c in range(3):  # Iterate over the B, G, R channels\n","        voronoi[:, :, c] = (blend_factor * team_1_color_bgr[c] +\n","                            (1 - blend_factor) * team_2_color_bgr[c]).astype(np.uint8)\n","\n","    overlay = cv2.addWeighted(voronoi, opacity, pitch, 1 - opacity, 0)\n","\n","    return overlay\n","\n","\n","def add_voronoi_transparent_overlay(frame, CONFIG, pitch_ball_xy, pitch_players_xy, players_detections,\n","                              overlay_scale=0.45, alpha=0.6, x_offset=10, y_offset=None):\n","\n","    # Step 1: Generate the base pitch\n","    annotated_pitch = draw_pitch(\n","        config=CONFIG,\n","        background_color=sv.Color.WHITE,\n","        line_color=sv.Color.BLACK\n","    )\n","\n","    # Step 2: Add Voronoi diagram\n","    annotated_pitch = draw_pitch_voronoi_diagram_2(\n","        config=CONFIG,\n","        team_1_xy=pitch_players_xy[players_detections.class_id == 0],\n","        team_2_xy=pitch_players_xy[players_detections.class_id == 1],\n","        team_1_color=sv.Color.from_hex('00BFFF'),  # Light Blue\n","        team_2_color=sv.Color.from_hex('FF1493'),  # Pink\n","        pitch=annotated_pitch\n","    )\n","\n","    # Step 3: Add ball and player markers\n","    annotated_pitch = draw_points_on_pitch(\n","        config=CONFIG,\n","        xy=pitch_ball_xy,\n","        face_color=sv.Color.WHITE,\n","        edge_color=sv.Color.WHITE,\n","        radius=8,\n","        thickness=1,\n","        pitch=annotated_pitch\n","    )\n","\n","    # Add team 1 players\n","    annotated_pitch = draw_points_on_pitch(\n","        config=CONFIG,\n","        xy=pitch_players_xy[players_detections.class_id == 0],\n","        face_color=sv.Color.from_hex('00BFFF'),\n","        edge_color=sv.Color.WHITE,\n","        radius=16,\n","        thickness=1,\n","        pitch=annotated_pitch\n","    )\n","\n","    # Add team 2 players\n","    annotated_pitch = draw_points_on_pitch(\n","        config=CONFIG,\n","        xy=pitch_players_xy[players_detections.class_id == 1],\n","        face_color=sv.Color.from_hex('FF1493'),\n","        edge_color=sv.Color.WHITE,\n","        radius=16,\n","        thickness=1,\n","        pitch=annotated_pitch\n","    )\n","\n","    # Step 4: Resize the annotated pitch overlay\n","    overlay_height = int(annotated_pitch.shape[0] * overlay_scale)\n","    overlay_width = int(annotated_pitch.shape[1] * overlay_scale)\n","    resized_overlay = cv2.resize(annotated_pitch, (overlay_width, overlay_height))\n","\n","    # Step 5: Determine the position for the overlay\n","    frame_height, frame_width = frame.shape[:2]\n","    if y_offset is None:\n","        y_offset = frame_height - overlay_height - 10\n","\n","    # Step 6: Define the region of interest (ROI) in the frame\n","    roi = frame[y_offset:y_offset+overlay_height, x_offset:x_offset+overlay_width]\n","\n","    # Step 7: Blend the overlay with the ROI\n","    blended_overlay = cv2.addWeighted(roi, 1 - alpha, resized_overlay, alpha, 0)\n","\n","    # Step 8: Insert the blended overlay back into the frame\n","    frame[y_offset:y_offset+overlay_height, x_offset:x_offset+overlay_width] = blended_overlay\n","\n","    return frame\n","\n","class SpeedEstimator:\n","    def __init__(self, config: Any, fps: float,\n","                 position_smoothing_window: int = 5,\n","                 speed_smoothing_window: int = 15,\n","                 max_acceleration: float = 6.0) -> None:\n","        \"\"\"\n","        Initialize the SpeedEstimator with improved smoothing and outlier rejection.\n","\n","        Args:\n","            config (Any): Configuration containing pitch dimensions.\n","            fps (float): Frames per second of the video.\n","            position_smoothing_window (int): Number of frames to consider for position smoothing.\n","            speed_smoothing_window (int): Number of frames to consider for speed smoothing.\n","            max_acceleration (float): Maximum realistic acceleration in m/sÂ² for outlier rejection.\n","        \"\"\"\n","        self.config = config\n","        self.fps = fps\n","        self.position_history: Dict[Any, deque] = {}\n","        self.speed_history: Dict[Any, deque] = {}\n","        self.last_calculated_speed: Dict[Any, float] = {}\n","        self.position_smoothing_window = position_smoothing_window\n","        self.speed_smoothing_window = speed_smoothing_window\n","        self.max_acceleration = max_acceleration\n","\n","        # Real field dimensions in meters\n","        real_field_length = 105\n","        real_field_width = 68\n","\n","        # Calculate scaling factors based on pitch dimensions\n","        self.scale_x = real_field_length / self.config.length  # Meters per pixel (length)\n","        self.scale_y = real_field_width / self.config.width    # Meters per pixel (width)\n","\n","        # Maximum realistic speed (km/h)\n","        self.max_speed = 40.0\n","\n","        # Time window for speed calculation (in frames)\n","        self.speed_calc_window = 3  # Calculate speed over this many frames instead of frame-by-frame\n","\n","    def calculate_speed(self, tracks: Dict[str, Any], frame_number: int) -> Dict[str, Any]:\n","        \"\"\"\n","        Calculate the speed of players with improved smoothing and outlier rejection.\n","\n","        Args:\n","            tracks (Dict[str, Any]): A dictionary containing tracking information for players.\n","            frame_number (int): The current frame number of the video.\n","\n","        Returns:\n","            Dict[str, Any]: Updated tracks with calculated speeds.\n","        \"\"\"\n","        for track_type in tracks:\n","            for player_id, track in tracks[track_type].items():\n","                if 'projection' in track:\n","                    current_position = track['projection']\n","\n","                    # Initialize history if it's a new player\n","                    if player_id not in self.position_history:\n","                        self.position_history[player_id] = deque(\n","                            [(current_position, frame_number)] * self.position_smoothing_window,\n","                            maxlen=self.position_smoothing_window\n","                        )\n","                        self.speed_history[player_id] = deque(\n","                            [0.0] * self.speed_smoothing_window,\n","                            maxlen=self.speed_smoothing_window\n","                        )\n","                        self.last_calculated_speed[player_id] = 0.0\n","                        tracks[track_type][player_id]['speed'] = 0.0\n","                        continue\n","\n","                    # Add current position to history\n","                    self.position_history[player_id].append((current_position, frame_number))\n","\n","                    # Get smoothed current position\n","                    smoothed_position = self._smooth_position(player_id)\n","\n","                    # Calculate speed only if we have enough history\n","                    if len(self.position_history[player_id]) >= self.speed_calc_window:\n","                        # Get position from n frames ago for speed calculation\n","                        prev_pos_data = self.position_history[player_id][-self.speed_calc_window]\n","                        prev_position, prev_frame = prev_pos_data\n","\n","                        # Calculate distance in meters\n","                        distance = self._calculate_distance(prev_position, smoothed_position)\n","\n","                        # Calculate time difference in seconds\n","                        time_diff = (frame_number - prev_frame) / self.fps\n","\n","                        # Calculate speed in km/h\n","                        speed = (distance / time_diff) * 3.6 if time_diff > 0 else 0.0\n","\n","                        # Apply maximum speed check\n","                        speed = min(speed, self.max_speed)\n","\n","                        # Check if acceleration is reasonable\n","                        prev_speed = self.last_calculated_speed[player_id]\n","                        accel = abs(speed - prev_speed) / time_diff  # m/sÂ²\n","\n","                        if accel > self.max_acceleration * 3.6:  # Convert to km/h/s\n","                            # If acceleration is too high, limit the change\n","                            direction = 1 if speed > prev_speed else -1\n","                            speed = prev_speed + direction * self.max_acceleration * 3.6 * time_diff\n","\n","                        # Apply smoothing\n","                        smoothed_speed = self._smooth_speed(player_id, speed)\n","\n","                        # Store the current speed for next iteration\n","                        self.last_calculated_speed[player_id] = smoothed_speed\n","\n","                        # Add speed to track\n","                        tracks[track_type][player_id]['speed'] = round(smoothed_speed, 1)\n","                else:\n","                    # If there's no projection, set speed to 0\n","                    tracks[track_type][player_id]['speed'] = 0.0\n","\n","        return tracks\n","\n","    def _calculate_distance(self, pos1: Tuple[float, float], pos2: Tuple[float, float]) -> float:\n","        \"\"\"\n","        Calculate the Euclidean distance between two positions.\n","\n","        Args:\n","            pos1 (Tuple[float, float]): The first position (x, y).\n","            pos2 (Tuple[float, float]): The second position (x, y).\n","\n","        Returns:\n","            float: The distance in meters.\n","        \"\"\"\n","        dx = (pos2[0] - pos1[0]) * self.scale_x\n","        dy = (pos2[1] - pos1[1]) * self.scale_y\n","        return math.sqrt(dx**2 + dy**2)\n","\n","    def _smooth_position(self, player_id: Any) -> Tuple[float, float]:\n","        \"\"\"\n","        Calculate a smoothed position using a weighted average of recent positions.\n","        More recent positions are weighted more heavily.\n","\n","        Args:\n","            player_id (Any): The identifier for the player.\n","\n","        Returns:\n","            Tuple[float, float]: The smoothed position.\n","        \"\"\"\n","        positions = [pos for pos, _ in self.position_history[player_id]]\n","\n","        # Apply weighted average with more weight to recent positions\n","        total_weight = 0\n","        smoothed_x = 0\n","        smoothed_y = 0\n","\n","        for i, pos in enumerate(positions):\n","            # Linear weighting: newer positions get higher weights\n","            weight = i + 1\n","            smoothed_x += pos[0] * weight\n","            smoothed_y += pos[1] * weight\n","            total_weight += weight\n","\n","        if total_weight > 0:\n","            return (smoothed_x / total_weight, smoothed_y / total_weight)\n","        else:\n","            return positions[-1] if positions else (0, 0)\n","\n","    def _smooth_speed(self, player_id: Any, speed: float) -> float:\n","        \"\"\"\n","        Smooth the speed measurement using a weighted moving average.\n","        More recent speeds are weighted more heavily.\n","\n","        Args:\n","            player_id (Any): The identifier for the player.\n","            speed (float): The calculated speed to be smoothed.\n","\n","        Returns:\n","            float: The smoothed speed value.\n","        \"\"\"\n","        self.speed_history[player_id].append(speed)\n","\n","        # Weighted average with more weight to recent speeds\n","        weights = np.linspace(0.5, 1.0, len(self.speed_history[player_id]))\n","        speeds = np.array(self.speed_history[player_id])\n","\n","        return np.average(speeds, weights=weights)\n","\n","    def get_player_speed(self, player_id: Any) -> float:\n","        \"\"\"\n","        Get the current speed of a player.\n","\n","        Args:\n","            player_id (Any): The identifier for the player.\n","\n","        Returns:\n","            float: The current speed in km/h.\n","        \"\"\"\n","        return self.last_calculated_speed.get(player_id, 0.0)\n","\n","    def reset(self) -> None:\n","        \"\"\"\n","        Reset the tracking history.\n","        Call this at the start of a new video or when needed.\n","        \"\"\"\n","        self.position_history = {}\n","        self.speed_history = {}\n","        self.last_calculated_speed = {}\n","\n","class Team(IntEnum):\n","    TEAM_A = 0\n","    TEAM_B = 1\n","\n","@dataclass\n","class GameStatsConfig:\n","    possession_threshold: float = 50.0  # Distance threshold for possession in pixels\n","    min_confidence: float = 0.3  # Minimum confidence for detections\n","    possession_smoothing_window: int = 5  # Frames to smooth possession over\n","    significant_pass_distance: float = 75.0  # Minimum distance to count as a pass\n","    pass_cooldown_frames: int = 10  # Cooldown period in frames\n","    bbox_padding: int = 15  # Pixels to expand player bboxes\n","    display_config: Dict = None\n","\n","    def __post_init__(self):\n","        if self.display_config is None:\n","            self.display_config = {\n","                'font': cv2.FONT_HERSHEY_SIMPLEX,\n","                'font_scale': 0.6,\n","                'text_color': (255, 255, 255),\n","                'box_color': (0, 0, 0),\n","                'thickness': 1,\n","                'padding': 5,\n","                'position': (10, 30),\n","                'team_names': {Team.TEAM_A: \"Team A\", Team.TEAM_B: \"Team B\"}\n","            }\n","\n","class GameStatsTracker:\n","    def __init__(self, config: GameStatsConfig = None, fps: float = 25.0, smoothing_window: int = 5):\n","        self.config = config or GameStatsConfig()\n","        self.fps = fps  # Frame rate of the video\n","        self.smoothing_window = smoothing_window  # Number of frames for smoothing\n","\n","        # Possession tracking\n","        self.possession_time = {Team.TEAM_A: 0, Team.TEAM_B: 0}\n","        self.total_frames = 0\n","        self.possession_history: List[Optional[Team]] = []\n","        self.current_possession: Optional[Team] = None\n","\n","        # Pass tracking\n","        self.passes = {\n","            Team.TEAM_A: {'total_passes': 0},\n","            Team.TEAM_B: {'total_passes': 0}\n","        }\n","        self.last_ball_carrier = None\n","        self.last_ball_carrier_player_idx = None\n","        self.last_ball_position = None\n","\n","\n","    def _get_bbox_center(self, bbox: np.ndarray) -> np.ndarray:\n","        x1, y1, x2, y2 = bbox\n","        return np.array([(x1 + x2) / 2, (y1 + y2) / 2])\n","\n","\n","    def _get_closest_player_for_possession(self, ball_center: np.ndarray, player_detections: sv.Detections) -> Tuple[Optional[Team], float]:\n","        \"\"\"\n","        Find the closest player to the ball for possession tracking.\n","        :param ball_center: Center coordinates of the ball (x, y).\n","        :param player_detections: Detections of players.\n","        :return: Tuple of (team_id, min_distance).\n","        \"\"\"\n","        closest_team = None\n","        min_distance = float('inf')\n","\n","        for idx, player_box in enumerate(player_detections.xyxy):\n","            player_center = self._get_bbox_center(player_box)\n","            distance = np.linalg.norm(player_center - ball_center)\n","\n","            if distance < min_distance and distance < self.config.possession_threshold:\n","                min_distance = distance\n","                closest_team = player_detections.class_id[idx]\n","\n","        return closest_team, min_distance\n","\n","    def _get_closest_player_for_passing(self, ball_center: np.ndarray, player_detections: sv.Detections) -> Tuple[Optional[Team], Optional[int]]:\n","        \"\"\"\n","        Find the closest player to the ball for pass tracking.\n","        :param ball_center: Center coordinates of the ball (x, y).\n","        :param player_detections: Detections of players.\n","        :return: Tuple of (team_id, player_idx).\n","        \"\"\"\n","        if len(player_detections.xyxy) == 0:\n","            return None, None\n","\n","        min_distance = float('inf')\n","        closest_player_idx = None\n","        closest_team = None\n","\n","        for idx, player_box in enumerate(player_detections.xyxy):\n","            player_center = self._get_bbox_center(player_box)\n","            distance = np.linalg.norm(player_center - ball_center)\n","\n","            if distance < min_distance:\n","                min_distance = distance\n","                closest_player_idx = idx\n","                closest_team = player_detections.class_id[idx]\n","\n","        return closest_team, closest_player_idx\n","\n","    def _smooth_possession(self, window_size: int) -> Optional[Team]:\n","        \"\"\"\n","        Smooth possession over a window of frames.\n","        :param window_size: Number of frames to consider for smoothing.\n","        :return: Smoothed possession (team_id).\n","        \"\"\"\n","        if len(self.possession_history) < window_size:\n","            return self.current_possession\n","\n","        recent_possession = [p for p in self.possession_history[-window_size:] if p is not None]\n","        if not recent_possession:\n","            return None\n","\n","        return max(set(recent_possession), key=recent_possession.count)\n","\n","    def _calculate_pass_distance(self, start_point: np.ndarray, end_point: np.ndarray) -> float:\n","        \"\"\"\n","        Calculate the distance between two points.\n","        :param start_point: Starting point (x, y).\n","        :param end_point: Ending point (x, y).\n","        :return: Euclidean distance.\n","        \"\"\"\n","        return np.linalg.norm(end_point - start_point)\n","\n","    def update(self, ball_detections: sv.Detections, player_detections: sv.Detections, goalkeepers_detections: sv.Detections = None) -> None:\n","        \"\"\"\n","        Update game statistics (possession, passes, speeds).\n","        :param ball_detections: Detections of the ball.\n","        :param player_detections: Detections of players.\n","        :param goalkeepers_detections: Detections of goalkeepers.\n","        \"\"\"\n","        if len(ball_detections.xyxy) == 0:\n","            self.possession_history.append(None)\n","            return\n","\n","        ball_center = self._get_bbox_center(ball_detections.xyxy[0])\n","\n","        # Combine player and goalkeeper detections if provided\n","        if goalkeepers_detections is not None and len(goalkeepers_detections) > 0:\n","            combined_detections = sv.Detections.merge([player_detections, goalkeepers_detections])\n","        else:\n","            combined_detections = player_detections\n","\n","        # Filter for valid team players and goalkeepers\n","        valid_entities = (combined_detections.class_id == Team.TEAM_A) | (combined_detections.class_id == Team.TEAM_B)\n","        if not np.any(valid_entities):\n","            self.possession_history.append(None)\n","            return\n","\n","        valid_detections = combined_detections[valid_entities]\n","\n","\n","        # Update possession tracking\n","        closest_team_possession, min_distance = self._get_closest_player_for_possession(ball_center, valid_detections)\n","\n","        if closest_team_possession is not None:\n","            self.possession_time[closest_team_possession] += 1\n","            self.total_frames += 1\n","\n","        self.possession_history.append(closest_team_possession)\n","        self.current_possession = self._smooth_possession(self.config.possession_smoothing_window)\n","\n","        # Update pass tracking (using separate logic from possession)\n","        current_ball_carrier, carrier_idx = self._get_closest_player_for_passing(ball_center, valid_detections)\n","\n","        if (self.last_ball_carrier is not None and\n","            current_ball_carrier is not None and\n","            self.last_ball_carrier == current_ball_carrier and  # Same team\n","            self.last_ball_carrier_player_idx != carrier_idx and  # Different player\n","            self.last_ball_position is not None):\n","\n","            # Calculate pass distance\n","            pass_distance = self._calculate_pass_distance(\n","                self.last_ball_position,\n","                ball_center\n","            )\n","\n","            # Only count passes with significant distance\n","            if pass_distance > self.config.significant_pass_distance:\n","                self.passes[current_ball_carrier]['total_passes'] += 1\n","\n","        # Update tracking variables for next frame\n","        self.last_ball_carrier = current_ball_carrier\n","        self.last_ball_carrier_player_idx = carrier_idx\n","        self.last_ball_position = ball_center\n","\n","    def get_stats(self) -> dict:\n","        \"\"\"\n","        Get the current game statistics.\n","        :return: Dictionary containing possession, passes, and player speeds.\n","        \"\"\"\n","        if self.total_frames == 0:\n","            return self._create_empty_stats()\n","\n","\n","        return {\n","            'possession_time': self.possession_time.copy(),\n","            'possession_percentage': {\n","                team_id: (time / self.total_frames * 100)\n","                for team_id, time in self.possession_time.items()\n","            },\n","            'current_possession': self.current_possession,\n","            'total_frames': self.total_frames,\n","            'history': self.possession_history.copy(),\n","            'passes': self.passes.copy(),\n","        }\n","\n","    def _create_empty_stats(self) -> dict:\n","        \"\"\"\n","        Create an empty stats dictionary.\n","        :return: Dictionary with default values.\n","        \"\"\"\n","        return {\n","            'possession_time': {Team.TEAM_A: 0, Team.TEAM_B: 0},\n","            'possession_percentage': {Team.TEAM_A: 0, Team.TEAM_B: 0},\n","            'current_possession': None,\n","            'total_frames': 0,\n","            'history': [],\n","            'passes': {Team.TEAM_A: {'total_passes': 0}, Team.TEAM_B: {'total_passes': 0}},\n","        }\n","\n","def draw_stats_overlay(\n","    frame: np.ndarray,\n","    stats: dict,\n","    config: GameStatsConfig\n",") -> np.ndarray:\n","    # Configuration\n","    team_a_name = config.display_config['team_names'][Team.TEAM_A]\n","    team_b_name = config.display_config['team_names'][Team.TEAM_B]\n","\n","    # Styling\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    title_scale = 0.65\n","    team_scale = 0.6\n","    stats_scale = 0.55\n","    thickness = 1\n","    padding = 10\n","    start_x = 15\n","    start_y = 30\n","\n","    # Colors\n","    team_a_color = (255, 191, 0)    # BGR for #00BFFF\n","    team_b_color = (147, 20, 255)    # BGR for #FF1493\n","    bg_color = (0, 0, 0)\n","    text_color = (255, 255, 255)\n","\n","    # Panel dimensions\n","    width = 260\n","    height = 120\n","\n","    # Create semi-transparent background\n","    overlay = frame.copy()\n","    cv2.rectangle(\n","        overlay,\n","        (start_x - padding, start_y - padding),\n","        (start_x + width, start_y + height),\n","        bg_color,\n","        -1\n","    )\n","    cv2.addWeighted(overlay, 0.85, frame, 0.15, 0, frame)\n","\n","    current_y = start_y\n","\n","    # Title\n","    cv2.putText(\n","        frame,\n","        \"MATCH STATS\",\n","        (start_x, current_y),\n","        font,\n","        title_scale,\n","        text_color,\n","        thickness,\n","        cv2.LINE_AA\n","    )\n","\n","    # Team headers\n","    current_y += 25\n","    # Team A left-aligned\n","    cv2.putText(\n","        frame,\n","        team_a_name,\n","        (start_x, current_y),\n","        font,\n","        team_scale,\n","        team_a_color,\n","        thickness,\n","        cv2.LINE_AA\n","    )\n","\n","    # Team B right-aligned\n","    team_b_size = cv2.getTextSize(team_b_name, font, team_scale, thickness)[0]\n","    cv2.putText(\n","        frame,\n","        team_b_name,\n","        (start_x + width - team_b_size[0], current_y),\n","        font,\n","        team_scale,\n","        team_b_color,\n","        thickness,\n","        cv2.LINE_AA\n","    )\n","\n","    # Possession bar\n","    current_y += 15\n","    bar_height = 18\n","    bar_width = width - 20\n","\n","    # Background bar\n","    cv2.rectangle(\n","        frame,\n","        (start_x + 10, current_y),\n","        (start_x + bar_width, current_y + bar_height),\n","        (40, 40, 40),\n","        -1\n","    )\n","\n","    # Team A possession portion\n","    team_a_perc = stats['possession_percentage'][Team.TEAM_A]\n","    team_a_width = int(bar_width * (team_a_perc/100))\n","    cv2.rectangle(\n","        frame,\n","        (start_x + 10, current_y),\n","        (start_x + 10 + team_a_width, current_y + bar_height),\n","        team_a_color,\n","        -1\n","    )\n","\n","    # Possession percentages\n","    percentage_y = current_y + 13\n","    cv2.putText(\n","        frame,\n","        f\"{team_a_perc:.1f}%\",\n","        (start_x + 15, percentage_y),\n","        font,\n","        stats_scale,\n","        text_color,\n","        thickness,\n","        cv2.LINE_AA\n","    )\n","\n","    team_b_perc = stats['possession_percentage'][Team.TEAM_B]\n","    perc_text = f\"{team_b_perc:.1f}%\"\n","    text_size = cv2.getTextSize(perc_text, font, stats_scale, thickness)[0]\n","    cv2.putText(\n","        frame,\n","        perc_text,\n","        (start_x + bar_width - text_size[0] - 5, percentage_y),\n","        font,\n","        stats_scale,\n","        text_color,\n","        thickness,\n","        cv2.LINE_AA\n","    )\n","\n","    # Passes - aligned under team headers\n","    current_y += bar_height + 20\n","    pass_y = current_y\n","\n","    # Team A passes (left side)\n","    team_a_passes = stats['passes'][Team.TEAM_A]['total_passes']\n","    cv2.rectangle(\n","        frame,\n","        (start_x, pass_y - 10),\n","        (start_x + 3, pass_y - 7),\n","        team_a_color,\n","        -1\n","    )\n","    cv2.putText(\n","        frame,\n","        f\"Passes: {team_a_passes}\",\n","        (start_x + 10, pass_y),\n","        font,\n","        stats_scale,\n","        text_color,\n","        thickness,\n","        cv2.LINE_AA\n","    )\n","\n","    # Team B passes (right side)\n","    team_b_passes = stats['passes'][Team.TEAM_B]['total_passes']\n","    pass_text = f\"Passes: {team_b_passes}\"\n","    pass_text_size = cv2.getTextSize(pass_text, font, stats_scale, thickness)[0]\n","\n","    # Calculate right-aligned position\n","    pass_text_x = start_x + width - pass_text_size[0] - 10\n","    cv2.rectangle(\n","        frame,\n","        (pass_text_x - 13, pass_y - 10),  # Indicator aligned with text\n","        (pass_text_x - 10, pass_y - 7),\n","        team_b_color,\n","        -1\n","    )\n","    cv2.putText(\n","        frame,\n","        pass_text,\n","        (pass_text_x, pass_y),\n","        font,\n","        stats_scale,\n","        text_color,\n","        thickness,\n","        cv2.LINE_AA\n","    )\n","\n","    return frame\n","\n","def initialize_annotators(config):\n","    color_palette = sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700'])\n","\n","    return {\n","        'box_annotator': sv.BoxAnnotator(\n","            color=color_palette,\n","            thickness=2,\n","            #corner_radius=4\n","        ),\n","        'label_annotator': sv.LabelAnnotator(\n","            color=color_palette,\n","            text_color=sv.Color.WHITE,\n","            text_position=sv.Position.TOP_CENTER,\n","            text_padding=2,\n","            text_scale=0.5\n","        ),\n","\n","        'ellipse_annotator': sv.EllipseAnnotator(\n","            color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n","            thickness=2\n","        ),\n","        'triangle_annotator': sv.TriangleAnnotator(\n","            color=sv.Color.from_hex('#FFD700'),\n","            base=25,\n","            height=21,\n","            outline_thickness=1\n","        ),\n","        'edge_annotator': sv.EdgeAnnotator(\n","            color=sv.Color.from_hex('#00BFFF'),\n","            thickness=2,\n","            edges=config.edges\n","        ),\n","        'vertex_annotator': sv.VertexAnnotator(\n","            color=sv.Color.from_hex('#FF1493'),\n","            radius=8\n","        ),\n","        'vertex_annotator_2': sv.VertexAnnotator(\n","            color=sv.Color.from_hex('#00BFFF'),\n","            radius=8\n","        )\n","    }\n","\n","    return annotators\n","\n","def add_ball_trail_overlay(frame, config, path, overlay_scale=0.45, alpha=0.6, x_offset=10, y_offset=None):\n","    \"\"\"\n","    Adds the ball trail overlay to the frame using draw_paths_on_pitch.\n","    \"\"\"\n","    # Step 1: Generate the base pitch\n","    annotated_pitch = draw_pitch(CONFIG)\n","    if annotated_pitch is None:\n","      print(\"Error: draw_pitch returned None.\")\n","      return frame\n","\n","    # Step 2: Draw the ball trail using draw_paths_on_pitch\n","    if len(path) > 0:\n","      annotated_pitch = draw_paths_on_pitch(\n","          config=CONFIG,\n","          paths=[path],  # Pass the ball trajectory as a list of paths\n","          color=sv.Color.WHITE,  # Color of the ball trail\n","          pitch=annotated_pitch\n","      )\n","\n","      if annotated_pitch is None:\n","            print(\"Error: draw_paths_on_pitch returned None.\")\n","            return frame\n","\n","    # Step 3: Resize the annotated pitch overlay\n","    overlay_height = int(annotated_pitch.shape[0] * overlay_scale)\n","    overlay_width = int(annotated_pitch.shape[1] * overlay_scale)\n","    resized_overlay = cv2.resize(annotated_pitch, (overlay_width, overlay_height))\n","\n","    # Step 4: Determine the position for the overlay\n","    frame_height, frame_width = frame.shape[:2]\n","    if y_offset is None:\n","        y_offset = frame_height - overlay_height - 10\n","\n","    # Step 5: Define the region of interest (ROI) in the frame\n","    roi = frame[y_offset:y_offset+overlay_height, x_offset:x_offset+overlay_width]\n","\n","    # Step 6: Blend the overlay with the ROI\n","    blended_overlay = cv2.addWeighted(roi, 1 - alpha, resized_overlay, alpha, 0)\n","\n","    # Step 7: Insert the blended overlay back into the frame\n","    frame[y_offset:y_offset+overlay_height, x_offset:x_offset+overlay_width] = blended_overlay\n","\n","    return frame\n","\n","def replace_outliers_based_on_distance(\n","    positions: List[np.ndarray],\n","    distance_threshold: float\n",") -> List[np.ndarray]:\n","    last_valid_position: Union[np.ndarray, None] = None\n","    cleaned_positions: List[np.ndarray] = []\n","\n","    for position in positions:\n","        if len(position) == 0:\n","            # If the current position is already empty, just add it to the cleaned positions\n","            cleaned_positions.append(position)\n","        else:\n","            if last_valid_position is None:\n","                # If there's no valid last position, accept the first valid one\n","                cleaned_positions.append(position)\n","                last_valid_position = position\n","            else:\n","                # Calculate the distance from the last valid position\n","                distance = np.linalg.norm(position - last_valid_position)\n","                if distance > distance_threshold:\n","                    # Replace with empty array if the distance exceeds the threshold\n","                    cleaned_positions.append(np.array([], dtype=np.float64))\n","                else:\n","                    cleaned_positions.append(position)\n","                    last_valid_position = position\n","\n","    return cleaned_positions\n","\n","######################################################################################################\n","def get_ball_possession(ball_detections, players_detections, goalkeepers_detections, max_distance=50):\n","    \"\"\"\n","    Determine which team has possession of the ball.\n","    \"\"\"\n","    if len(ball_detections.xyxy) == 0:\n","        return None  # No ball detected\n","\n","    ball_center = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)[0]\n","\n","    # Combine player and goalkeeper detections\n","    all_players = sv.Detections.merge([players_detections, goalkeepers_detections])\n","\n","    # Find the closest player to the ball\n","    min_distance = float('inf')\n","    possessing_team = None\n","\n","    for i, player_xy in enumerate(all_players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)):\n","        distance = np.linalg.norm(player_xy - ball_center)\n","        if distance < min_distance and distance < max_distance:  # Only consider players within max_distance\n","            min_distance = distance\n","            possessing_team = all_players.class_id[i]\n","\n","    # Debug prints\n","    print(f\"Ball Position: {ball_center}\")\n","    print(f\"Closest Player Distance: {min_distance}\")\n","    print(f\"Possessing Team: {possessing_team}\")\n","\n","    return possessing_team\n","\n","def calculate_team_centroids(team_1_xy, team_2_xy):\n","    \"\"\"\n","    Calculate the centroid of each team based on player positions.\n","    \"\"\"\n","    team_1_centroid = np.mean(team_1_xy, axis=0) if len(team_1_xy) > 0 else np.array([0, 0])\n","    team_2_centroid = np.mean(team_2_xy, axis=0) if len(team_2_xy) > 0 else np.array([0, 0])\n","    return team_1_centroid, team_2_centroid\n","\n","\n","def calculate_team_stretch_index(team_positions):\n","    \"\"\"\n","    Calculate the Team Stretch Index (TSI) based on player positions.\n","\n","    Args:\n","        team_positions (np.ndarray): Array of player positions (x, y) for a team.\n","\n","    Returns:\n","        float: The Team Stretch Index (TSI).\n","    \"\"\"\n","    if len(team_positions) == 0:\n","        return 0.0\n","\n","    # Calculate the spread in the x (horizontal) and y (vertical) directions\n","    x_positions = team_positions[:, 0]\n","    y_positions = team_positions[:, 1]\n","\n","    x_spread = np.max(x_positions) - np.min(x_positions)\n","    y_spread = np.max(y_positions) - np.min(y_positions)\n","\n","    # Combine horizontal and vertical spread to get the overall stretch index\n","    tsi = np.sqrt(x_spread**2 + y_spread**2)\n","\n","    return tsi\n","\n","\n","class Team(IntEnum):\n","    TEAM_A = 0\n","    TEAM_B = 1\n","\n","class PlayingStyleAnalyzer:\n","    def __init__(self, config, game_stats_tracker, fps=25, time_window=5):\n","        self.config = config\n","        self.game_stats_tracker = game_stats_tracker\n","        self.fps = fps\n","        self.time_window = time_window\n","        self.window_size = int(fps * time_window)  # Frames per window\n","        self.current_frame = 0\n","\n","        # Buffers for centroids, TSI, and positions\n","        self.team_a_centroids = []\n","        self.team_b_centroids = []\n","        self.team_a_tsi_values = []\n","        self.team_b_tsi_values = []\n","        self.team_a_positions = []\n","        self.team_b_positions = []\n","\n","        # Current playing styles (updated per window)\n","        self.current_styles = {\n","            Team.TEAM_A: \"Possessive\",\n","            Team.TEAM_B: \"Pressing\"\n","        }\n","\n","        # Attack direction configuration\n","        self.team_attack_direction = {\n","            Team.TEAM_A: 1,  # Positive X direction is attacking\n","            Team.TEAM_B: -1   # Negative X direction is attacking\n","        }\n","\n","        # History of styles for visualization\n","        self.style_history = []\n","\n","        # Thresholds for style determination\n","        self.high_tsi_threshold = self.config.length * 0.6  # 60% of pitch length\n","        self.low_tsi_threshold = self.config.length * 0.4  # 40% of pitch length\n","        self.midfield_threshold = 0.4  # 40% of players in midfield\n","        self.forward_movement_threshold = 0.3  # Movement vector threshold for forward movement\n","        self.backward_movement_threshold = -0.3  # Movement vector threshold for backward movement\n","        self.pressing_zone = self.config.length * 0.7  # Last 30% of pitch\n","\n","    def update_centroids(self, team_a_centroid, team_b_centroid, team_a_tsi, team_b_tsi):\n","        \"\"\"Update team centroids and TSI values.\"\"\"\n","        self.team_a_centroids.append(team_a_centroid)\n","        self.team_b_centroids.append(team_b_centroid)\n","        self.team_a_tsi_values.append(team_a_tsi)\n","        self.team_b_tsi_values.append(team_b_tsi)\n","        self.current_frame += 1\n","\n","        # Process the window when the current frame reaches the window size\n","        if self.current_frame % self.window_size == 0:\n","            self._process_window()\n","            # Reset buffers for the next window\n","            self.team_a_centroids = []\n","            self.team_b_centroids = []\n","            self.team_a_tsi_values = []\n","            self.team_b_tsi_values = []\n","\n","    def update_positions(self, team_a_xy, team_b_xy):\n","        \"\"\"Update player positions for both teams.\"\"\"\n","        self.team_a_positions.extend(team_a_xy)\n","        self.team_b_positions.extend(team_b_xy)\n","\n","    def _calculate_midfield_presence(self, positions):\n","        \"\"\"Calculate percentage of players in midfield region.\"\"\"\n","        if len(positions) == 0:\n","            return 0\n","\n","        midfield_start = self.config.length * 0.3\n","        midfield_end = self.config.length * 0.7\n","        in_midfield = sum(1 for x, y in positions if midfield_start < x < midfield_end)\n","        return in_midfield / len(positions)\n","\n","    def _is_in_opponent_half(self, centroid, attack_dir):\n","        \"\"\"Check if centroid is in opponent's half.\"\"\"\n","        return (centroid[0] * attack_dir) > (self.config.length / 2)\n","\n","    def _is_pressing(self, centroid, attack_dir):\n","        \"\"\"Check if team is in pressing zone.\"\"\"\n","        return (centroid[0] * attack_dir) > self.pressing_zone\n","\n","    def _process_window(self):\n","        \"\"\"Analyze data in the current time window to determine styles.\"\"\"\n","        start_frame = max(0, self.current_frame - self.window_size)\n","        end_frame = self.current_frame\n","\n","        # Extract possession data for this window\n","        possession_window = self.game_stats_tracker.possession_history[start_frame:end_frame]\n","        if len(possession_window) < self.window_size:\n","            return  # Not enough data\n","\n","        # Calculate possession percentages\n","        team_a_possession = sum(1 for p in possession_window if p == Team.TEAM_A)\n","        team_b_possession = sum(1 for p in possession_window if p == Team.TEAM_B)\n","        main_possession_team = (\n","            Team.TEAM_A if team_a_possession > team_b_possession\n","            else Team.TEAM_B if team_b_possession > team_a_possession\n","            else None\n","        )\n","\n","        # Calculate average movement vectors for the window\n","        team_a_movement = self._calculate_movement_vector(self.team_a_centroids)\n","        team_b_movement = self._calculate_movement_vector(self.team_b_centroids)\n","\n","        # Calculate average TSI for the window\n","        team_a_tsi = np.mean(self.team_a_tsi_values) if self.team_a_tsi_values else 0\n","        team_b_tsi = np.mean(self.team_b_tsi_values) if self.team_b_tsi_values else 0\n","\n","        # Determine styles based on movement, possession, TSI, and field presence\n","        team_a_style = self._determine_style(\n","            Team.TEAM_A, team_a_movement, main_possession_team == Team.TEAM_A, team_a_tsi, self.team_a_positions\n","        )\n","        team_b_style = self._determine_style(\n","            Team.TEAM_B, team_b_movement, main_possession_team == Team.TEAM_B, team_b_tsi, self.team_b_positions\n","        )\n","\n","        # Update current styles\n","        self.current_styles[Team.TEAM_A] = team_a_style\n","        self.current_styles[Team.TEAM_B] = team_b_style\n","\n","        # Record style history for visualization\n","        self.style_history.append({\n","            'start_frame': start_frame,\n","            'end_frame': end_frame - 1,\n","            Team.TEAM_A: team_a_style,\n","            Team.TEAM_B: team_b_style\n","        })\n","\n","    def _calculate_movement_vector(self, centroids):\n","        \"\"\"Calculate average displacement vector from centroid history.\"\"\"\n","        if len(centroids) < 2:\n","            return np.array([0, 0])\n","        displacements = [centroids[i] - centroids[i - 1] for i in range(1, len(centroids))]\n","        return np.mean(displacements, axis=0) if displacements else np.array([0, 0])\n","\n","    def _determine_style(self, team, movement_vector, has_possession, tsi, positions):\n","        \"\"\"\n","        Determine playing style based on movement, possession, TSI, and field presence.\n","        Styles are generalized to: Offensive, Defensive, Possessive, Pressing.\n","        \"\"\"\n","        attack_dir = self.team_attack_direction[team]\n","        centroid = np.mean(positions, axis=0) if len(positions) > 0 else (0, 0)\n","\n","        midfield_presence = self._calculate_midfield_presence(positions)\n","        in_opponent_half = self._is_in_opponent_half(centroid, attack_dir)\n","        is_pressing = self._is_pressing(centroid, attack_dir)\n","        movement_x = movement_vector[0] * attack_dir  # Adjusted for attack direction\n","\n","        if has_possession:\n","            if midfield_presence > self.midfield_threshold:\n","                if tsi > self.high_tsi_threshold and in_opponent_half:\n","                    return \"Offensive\"\n","                return \"Possessive\"\n","            elif movement_x > self.forward_movement_threshold:\n","                return \"Offensive\"\n","            else:\n","                return \"Possessive\"\n","        else:\n","            if is_pressing:\n","                return \"Pressing\"\n","            elif movement_x < self.backward_movement_threshold:\n","                return \"Defensive\"\n","            else:\n","                return \"Pressing\"\n","\n","    def get_current_styles(self):\n","        \"\"\"Return the current styles for both teams.\"\"\"\n","        return self.current_styles[Team.TEAM_A], self.current_styles[Team.TEAM_B]\n","\n","def update_main_loop(frame, team_1_xy, team_2_xy, team_1_tsi, team_2_tsi, game_stats_tracker, config):\n","    if not hasattr(update_main_loop, 'analyzer'):\n","        update_main_loop.analyzer = PlayingStyleAnalyzer(\n","            config=CONFIG,\n","            game_stats_tracker=game_stats_tracker,\n","            fps=25,\n","            time_window=5  # Set your desired time window here\n","        )\n","\n","    # Calculate centroids\n","    team_1_centroid, team_2_centroid = calculate_team_centroids(team_1_xy, team_2_xy)\n","\n","    # Update analyzer with new centroids\n","    update_main_loop.analyzer.update_centroids(team_1_centroid, team_2_centroid, team_1_tsi, team_2_tsi)\n","\n","    #Update Positions\n","    update_main_loop.analyzer.update_positions(team_1_xy, team_2_xy)\n","\n","    # Retrieve current styles\n","    team_1_style, team_2_style = update_main_loop.analyzer.get_current_styles()\n","\n","    # Visualization (optional)\n","    if frame is not None:\n","        cv2.putText(\n","            frame,\n","            f\"{team_1_style} | {team_2_style}\",\n","            (20, 135),\n","            cv2.FONT_HERSHEY_SIMPLEX,\n","            0.6,\n","            (255, 255, 255),\n","            1\n","        )\n","\n","    return team_1_style, team_2_style\n","\n","\n","class StyleVisualizer:\n","    def __init__(self, total_frames, config, fps):\n","        self.total_frames = total_frames\n","        self.config = config\n","        self.fps = fps\n","        self.style_history = {\n","            \"Team A\": [],\n","            \"Team B\": []\n","        }\n","        self.current_style = {\n","            \"Team A\": None,\n","            \"Team B\": None\n","        }\n","        # Professional color scheme (less saturated, more elegant)\n","        self.style_colors = {\n","            \"Possessive\": \"#3498db\",  # Soft blue\n","            \"Pressing\": \"#9b59b6\",    # Muted purple\n","            \"Defensive\": \"#e74c3c\",   # Softer red\n","            \"Offensive\": \"#2ecc71\",   # Softer green\n","        }\n","        # Add gradient capabilities\n","        self.use_gradients = True\n","        # Font configuration\n","        self.font_main = \"arial.ttf\"\n","        self.font_size_title = 100\n","        self.font_size_label = 14\n","        self.font_size_duration = 12\n","\n","    def update_style(self, team, style, frame_count):\n","        if self.current_style[team] != style:\n","            if self.current_style[team] is not None:\n","                self.style_history[team].append({\n","                    \"style\": self.current_style[team],\n","                    \"start_frame\": self.style_history[team][-1][\"end_frame\"] + 1 if self.style_history[team] else 0,\n","                    \"end_frame\": frame_count - 1\n","                })\n","            self.current_style[team] = style\n","\n","    def _create_gradient(self, start_color, end_color, width, height):\n","        \"\"\"Create a horizontal gradient image between two colors\"\"\"\n","        from PIL import Image, ImageDraw\n","        import numpy as np\n","\n","        # Convert hex to RGB\n","        def hex_to_rgb(hex_color):\n","            h = hex_color.lstrip('#')\n","            return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n","\n","        start_rgb = hex_to_rgb(start_color)\n","        end_rgb = hex_to_rgb(end_color)\n","\n","        # Create gradient array\n","        arr = np.zeros((height, width, 3), dtype=np.uint8)\n","        for x in range(width):\n","            r = start_rgb[0] + (end_rgb[0] - start_rgb[0]) * x // width\n","            g = start_rgb[1] + (end_rgb[1] - start_rgb[1]) * x // width\n","            b = start_rgb[2] + (end_rgb[2] - start_rgb[2]) * x // width\n","            arr[:, x] = [r, g, b]\n","\n","        return Image.fromarray(arr)\n","\n","    def _add_rounded_rectangle(self, draw, xy, radius, fill, outline=None, width=1):\n","        \"\"\"Draw a rounded rectangle\"\"\"\n","        x1, y1, x2, y2 = xy\n","        r = radius\n","\n","        # Draw four corners\n","        draw.pieslice([x1, y1, x1 + r*2, y1 + r*2], 180, 270, fill=fill, outline=outline, width=width)\n","        draw.pieslice([x2 - r*2, y1, x2, y1 + r*2], 270, 0, fill=fill, outline=outline, width=width)\n","        draw.pieslice([x1, y2 - r*2, x1 + r*2, y2], 90, 180, fill=fill, outline=outline, width=width)\n","        draw.pieslice([x2 - r*2, y2 - r*2, x2, y2], 0, 90, fill=fill, outline=outline, width=width)\n","\n","        # Draw four straight lines\n","        draw.rectangle([x1 + r, y1, x2 - r, y1 + r], fill=fill, outline=fill)\n","        draw.rectangle([x1 + r, y2 - r, x2 - r, y2], fill=fill, outline=fill)\n","        draw.rectangle([x1, y1 + r, x1 + r, y2 - r], fill=fill, outline=fill)\n","        draw.rectangle([x2 - r, y1 + r, x2, y2 - r], fill=fill, outline=fill)\n","\n","        # Draw central rectangle\n","        draw.rectangle([x1 + r, y1 + r, x2 - r, y2 - r], fill=fill, outline=fill)\n","\n","        # Add thin border if specified\n","        if outline:\n","            # Top line\n","            draw.line([x1 + r, y1, x2 - r, y1], fill=outline, width=width)\n","            # Bottom line\n","            draw.line([x1 + r, y2, x2 - r, y2], fill=outline, width=width)\n","            # Left line\n","            draw.line([x1, y1 + r, x1, y2 - r], fill=outline, width=width)\n","            # Right line\n","            draw.line([x2, y1 + r, x2, y2 - r], fill=outline, width=width)\n","\n","    def _add_drop_shadow(self, img, offset=(5, 5), radius=3, color=(0, 0, 0, 100)):\n","        \"\"\"Add a drop shadow effect to the image\"\"\"\n","        from PIL import Image, ImageFilter\n","\n","        # Create shadow mask with alpha channel\n","        shadow = Image.new('RGBA', img.size, (0, 0, 0, 0))\n","        shadow_draw = ImageDraw.Draw(shadow)\n","        shadow_draw.rectangle([0, 0, img.size[0], img.size[1]], fill=color)\n","        shadow = shadow.filter(ImageFilter.GaussianBlur(radius))\n","\n","        # Create result image with shadow\n","        result = Image.new('RGBA', img.size, (0, 0, 0, 0))\n","        result.paste(shadow, offset, shadow)\n","        result.paste(img, (0, 0), img)\n","\n","        return result\n","\n","    def finalize(self, output_path):\n","        from PIL import Image, ImageDraw, ImageFont, ImageColor, ImageEnhance, ImageFilter\n","\n","        # Add the final style segment\n","        for team in [\"Team A\", \"Team B\"]:\n","            if self.current_style[team] is not None:\n","                if self.style_history[team]:\n","                    last_segment = self.style_history[team][-1]\n","                    start_frame = last_segment[\"end_frame\"] + 1\n","                else:\n","                    start_frame = 0\n","                self.style_history[team].append({\n","                    \"style\": self.current_style[team],\n","                    \"start_frame\": start_frame,\n","                    \"end_frame\": self.total_frames - 1\n","                })\n","\n","        # Professional dimensions\n","        img_width = 1200\n","        img_height = 500\n","\n","        # Create a base image with anti-aliasing\n","        img = Image.new(\"RGBA\", (img_width, img_height), (255, 255, 255, 255))\n","        draw = ImageDraw.Draw(img)\n","\n","        # Add a subtle background pattern or gradient\n","        background = Image.new(\"RGBA\", (img_width, img_height), (248, 249, 250, 255))\n","        for i in range(0, img_width, 20):\n","            draw_bg = ImageDraw.Draw(background)\n","            draw_bg.line([(i, 0), (i, img_height)], fill=(240, 240, 240, 255), width=1)\n","        for i in range(0, img_height, 20):\n","            draw_bg = ImageDraw.Draw(background)\n","            draw_bg.line([(0, i), (img_width, i)], fill=(240, 240, 240, 255), width=1)\n","        img.paste(background, (0, 0), background)\n","\n","        # Load fonts\n","        try:\n","            font_title = ImageFont.truetype(self.font_main, self.font_size_title)\n","            font_label = ImageFont.truetype(self.font_main, self.font_size_label)\n","            font_duration = ImageFont.truetype(self.font_main, self.font_size_duration)\n","        except IOError:\n","            font_title = ImageFont.load_default()\n","            font_label = ImageFont.load_default()\n","            font_duration = ImageFont.load_default()\n","\n","        # Calculate dimensions\n","        team_height = 60  # Reduced from 80 to 60 to make narrower\n","        padding = 40\n","        timeline_padding = 20\n","        legend_height = 80\n","        corner_radius = 5\n","\n","        # Draw title with enhanced styling and better readability\n","        title = \"Team Playing Style Analysis\"\n","        title_bbox = draw.textbbox((0, 0), title, font=font_title)\n","        title_width = title_bbox[2] - title_bbox[0]\n","        title_height = title_bbox[3] - title_bbox[1]\n","\n","        # Create a wider, more prominent background for the title\n","        title_bg_x1 = (img_width - title_width) // 2 - 80  # Increased padding for larger title\n","        title_bg_x2 = (img_width + title_width) // 2 + 80  # Increased padding for larger title\n","        title_bg_y1 = padding // 2 - 20  # Increased padding\n","        title_bg_y2 = padding // 2 + title_height + 20  # Increased padding\n","\n","        # Add a gradient background for the title\n","        title_bg = self._create_gradient(\"#2980b9\", \"#8e44ad\", title_bg_x2 - title_bg_x1, title_bg_y2 - title_bg_y1)\n","        mask = Image.new(\"L\", (title_bg_x2 - title_bg_x1, title_bg_y2 - title_bg_y1), 0)\n","        mask_draw = ImageDraw.Draw(mask)\n","        mask_draw.rounded_rectangle([(0, 0), (title_bg_x2 - title_bg_x1, title_bg_y2 - title_bg_y1)],\n","                                  radius=corner_radius, fill=255)\n","        title_bg.putalpha(mask)\n","        img.paste(title_bg, (title_bg_x1, title_bg_y1), title_bg)\n","\n","        # Draw title text without shadow effect\n","        draw.text(((img_width - title_width) // 2, padding // 2),\n","                 title, fill=\"white\", font=font_title)\n","\n","        # Calculate timeline area\n","        timeline_width = img_width - (2 * padding) - 100  # Adjusted to allow space for team labels\n","        timeline_start_x = padding + 100  # Moved timeline right to make room for labels\n","\n","        # Position timeline right after the title\n","        timeline_start_y = title_bg_y2 + padding\n","\n","        # Draw team timelines\n","        for t, team in enumerate([\"Team A\", \"Team B\"]):\n","            y_start = timeline_start_y + t * (team_height + padding)  # Adjusted vertical position\n","\n","            # Draw team label with proper styling and enough space\n","            team_label = \"Team A\" if team == \"Team A\" else \"Team B\"\n","            text_bbox = draw.textbbox((0, 0), team_label, font=font_label)\n","            text_width = text_bbox[2] - text_bbox[0]\n","            text_height = text_bbox[3] - text_bbox[1]\n","\n","            # Draw a stylish label background - positioned to the left of the timeline\n","            label_bg_color = \"#3498db\" if team == \"Team A\" else \"#e74c3c\"  # Blue for A, Red for B\n","            label_x = timeline_start_x - 80  # Positioned well left of timeline\n","            label_y = y_start + (team_height - text_height) // 2\n","            label_padding = 8\n","\n","            # Draw the team label with a rounded rectangle\n","            self._add_rounded_rectangle(\n","                draw,\n","                (label_x - label_padding,\n","                 label_y - label_padding,\n","                 label_x + text_width + label_padding,\n","                 label_y + text_height + label_padding),\n","                radius=5,\n","                fill=label_bg_color,\n","                outline=None\n","            )\n","\n","            # Draw the team name text\n","            draw.text((label_x, label_y), team_label, fill=\"white\", font=font_label)\n","\n","            # Draw timeline background (rounded rectangle)\n","            self._add_rounded_rectangle(\n","                draw,\n","                (timeline_start_x, y_start, timeline_start_x + timeline_width, y_start + team_height),\n","                radius=corner_radius,\n","                fill=\"#f5f5f5\",\n","                outline=\"#dddddd\",\n","                width=1\n","            )\n","\n","            # Add time markers\n","            total_seconds = self.total_frames / self.fps\n","            marker_interval = 30  # seconds\n","            for second in range(0, int(total_seconds) + marker_interval, marker_interval):\n","                marker_x = timeline_start_x + (second / total_seconds) * timeline_width\n","                if marker_x <= timeline_start_x + timeline_width:\n","                    # Marker line\n","                    draw.line([(marker_x, y_start), (marker_x, y_start + team_height)],\n","                             fill=\"#dddddd\", width=1)\n","                    # Marker label\n","                    minutes = second // 60\n","                    seconds = second % 60\n","                    time_label = f\"{minutes}:{seconds:02d}\"\n","                    text_bbox = draw.textbbox((0, 0), time_label, font=font_duration)\n","                    text_width = text_bbox[2] - text_bbox[0]\n","                    draw.text((marker_x - text_width // 2, y_start + team_height + 5),\n","                             time_label, fill=\"#777777\", font=font_duration)\n","\n","            # Draw style segments with gradients\n","            x = timeline_start_x\n","            for segment in self.style_history[team]:\n","                style = segment[\"style\"]\n","                start_frame = segment[\"start_frame\"]\n","                end_frame = segment[\"end_frame\"]\n","                duration_frames = end_frame - start_frame + 1\n","                duration_seconds = duration_frames / self.fps\n","                duration_str = f\"{duration_seconds:.1f}s\"\n","\n","                segment_width = (duration_frames / self.total_frames) * timeline_width\n","                color = self.style_colors.get(style, \"#808080\")\n","\n","                # Draw segment with gradient effect if enabled\n","                if self.use_gradients and segment_width > 30:\n","                    # Slightly lighter version of the same color for gradient\n","                    end_color = color\n","                    start_r, start_g, start_b = ImageColor.getrgb(color)\n","                    # Lighten the start color\n","                    start_color = f\"#{min(start_r + 20, 255):02x}{min(start_g + 20, 255):02x}{min(start_b + 20, 255):02x}\"\n","\n","                    gradient_img = self._create_gradient(start_color, end_color, int(segment_width), team_height)\n","\n","                    # Draw rounded rectangle mask\n","                    mask = Image.new(\"L\", (int(segment_width), team_height), 0)\n","                    mask_draw = ImageDraw.Draw(mask)\n","                    mask_draw.rounded_rectangle([(0, 0), (int(segment_width), team_height)],\n","                                              radius=corner_radius, fill=255)\n","\n","                    # Apply mask to gradient and paste it\n","                    gradient_img.putalpha(mask)\n","                    img.paste(gradient_img, (int(x), int(y_start)), gradient_img)\n","\n","                    # Add subtle border\n","                    segment_rect = (int(x), int(y_start), int(x + segment_width), int(y_start + team_height))\n","                    draw.rounded_rectangle(segment_rect, radius=corner_radius,\n","                                         outline=\"#00000022\", width=1)\n","                else:\n","                    # Standard rectangle for smaller segments\n","                    segment_rect = (int(x), int(y_start), int(x + segment_width), int(y_start + team_height))\n","                    draw.rounded_rectangle(segment_rect, radius=corner_radius,\n","                                         fill=color, outline=\"#00000022\", width=1)\n","\n","                # Draw style label and duration if there's enough space\n","                if segment_width >= 60:\n","                    # Style text\n","                    style_text_bbox = draw.textbbox((0, 0), style, font=font_label)\n","                    style_text_width = style_text_bbox[2] - style_text_bbox[0]\n","                    style_text_x = x + (segment_width - style_text_width) / 2\n","                    style_text_y = y_start + 10  # Adjusted for narrower rectangles\n","                    draw.text((style_text_x, style_text_y), style, fill=\"white\", font=font_label)\n","\n","                    # Duration text\n","                    duration_text_bbox = draw.textbbox((0, 0), duration_str, font=font_duration)\n","                    duration_text_width = duration_text_bbox[2] - duration_text_bbox[0]\n","                    duration_text_x = x + (segment_width - duration_text_width) / 2\n","                    duration_text_y = y_start + team_height - 20  # Adjusted for narrower rectangles\n","                    draw.text((duration_text_x, duration_text_y), duration_str, fill=\"white\", font=font_duration)\n","\n","                x += segment_width\n","\n","        # Calculate the position after the team timelines\n","        timeline_end_y = timeline_start_y + (2 * (team_height + padding))\n","\n","        # Add total match time under the bars at the end\n","        total_seconds = self.total_frames / self.fps\n","        total_match_time = f\"Total Match Time: {total_seconds:.0f} seconds\"\n","        match_time_bbox = draw.textbbox((0, 0), total_match_time, font=font_label)\n","        match_time_width = match_time_bbox[2] - match_time_bbox[0]\n","\n","        # Position match time info at the end of the timeline\n","        match_time_x = timeline_start_x + timeline_width - match_time_width\n","        match_time_y = timeline_end_y - padding/2  # Position it below the last team's timeline\n","\n","        # Draw match time text directly under the end of the bars\n","        draw.text((match_time_x, match_time_y), total_match_time, fill=\"#555555\", font=font_label)\n","\n","        # Draw the legend after the match time info\n","        legend_y = timeline_end_y + padding  # Positioned after team analysis and match time\n","        legend_title = \"Playing Styles\"\n","\n","        tums = 120\n","\n","        # Draw a decorative legend box\n","        legend_box_x1 = tums\n","        legend_box_y1 = legend_y - 10\n","        legend_box_x2 = img_width - tums\n","        legend_box_y2 = legend_y + 55  # Made smaller for just one row\n","\n","        # Draw legend box with slight transparency\n","        self._add_rounded_rectangle(\n","            draw,\n","            (legend_box_x1, legend_box_y1, legend_box_x2, legend_box_y2),\n","            radius=corner_radius,\n","            fill=\"#f8f9fa\",\n","            outline=\"#dddddd\",\n","            width=1\n","        )\n","\n","        # Draw legend title\n","        text_bbox = draw.textbbox((0, 0), legend_title, font=font_label)\n","        text_width = text_bbox[2] - text_bbox[0]\n","        draw.text((tums + 15, legend_y), legend_title, fill=\"#333333\", font=font_label)\n","\n","        # Draw legend items in a grid layout\n","        legend_items_per_row = 4\n","        legend_item_width = (img_width - (2 * tums)) / legend_items_per_row\n","\n","        for i, (style, color) in enumerate(self.style_colors.items()):\n","            item_x = tums + 15 + (i % legend_items_per_row) * legend_item_width\n","            item_y = legend_y + 20\n","\n","            # Draw color box with rounded corners\n","            self._add_rounded_rectangle(\n","                draw,\n","                (item_x, item_y, item_x + 20, item_y + 20),\n","                radius=3,\n","                fill=color,\n","                outline=None\n","            )\n","\n","            # Draw style name\n","            draw.text((item_x + 30, item_y), style, fill=\"#333333\", font=font_duration)\n","\n","        # Save the final image\n","        img = img.convert(\"RGB\")\n","        img.save(output_path, quality=95)\n","\n","def generate_heatmap_for_team(positions, config, color, output_path):\n","    \"\"\"\n","    Generate a heatmap for a single team.\n","    \"\"\"\n","    # Create an empty pitch image\n","    pitch = draw_pitch(config)\n","    if pitch is None:\n","        raise ValueError(\"Failed to generate pitch image\")\n","    pitch_height, pitch_width = pitch.shape[:2]\n","\n","    # Create a grid for the heatmap\n","    x_scale = pitch_width / config.length\n","    y_scale = pitch_height / config.width\n","\n","    # Initialize heatmap\n","    heatmap = np.zeros((pitch_height, pitch_width), dtype=np.float32)\n","\n","    # Populate heatmap based on player positions\n","    for x, y in positions:\n","        x_pixel = int(x * x_scale)\n","        y_pixel = int(y * y_scale)\n","\n","        if 0 <= x_pixel < pitch_width and 0 <= y_pixel < pitch_height:\n","            heatmap[y_pixel, x_pixel] += 1\n","\n","    # Apply Gaussian filter to smooth the heatmap\n","    heatmap = gaussian_filter(heatmap, sigma=20)\n","\n","    # Normalize heatmap to the range [0, 255]\n","    heatmap = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX)\n","\n","    # Convert heatmap to 8-bit for color mapping\n","    heatmap = heatmap.astype(np.uint8)\n","\n","    # Create colored heatmap using a colormap\n","    heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","\n","    # Blend heatmap with the pitch\n","    overlay = cv2.addWeighted(pitch, 0.7, heatmap_color, 0.3, 0)\n","\n","    # Save the heatmap image\n","    cv2.imwrite(output_path, overlay)\n","    print(f\"Heatmap saved to {output_path}\")\n","\n","    return overlay\n","\n","\n","def combine_heatmaps(heatmap_team1, heatmap_team2):\n","    \"\"\"\n","    Combine two heatmaps into a single image.\n","    \"\"\"\n","    # Blend both heatmaps with transparency\n","    combined = cv2.addWeighted(heatmap_team1, 0.5, heatmap_team2, 0.5, 0)\n","    return combined\n","\n","\n","def main():\n","\n","    # Initialize possession tracker with custom config\n","    config = GameStatsConfig(\n","        possession_threshold=50.0,\n","        min_confidence=0.3,\n","        possession_smoothing_window=5,\n","        significant_pass_distance=30.0,\n","        display_config={\n","            'font': cv2.FONT_HERSHEY_SIMPLEX,\n","            'font_scale': 0.6,\n","            'text_color': (255, 255, 255),\n","            'box_color': (0, 0, 0),\n","            'thickness': 1,\n","            'padding': 5,\n","            'position': (10, 30),\n","            'team_names': {Team.TEAM_A: \"TEAM A\", Team.TEAM_B: \"TEAM B\"}\n","        }\n","    )\n","\n","    annotators = initialize_annotators(CONFIG)\n","\n","    game_stats_tracker = GameStatsTracker(config=config, fps=25.0, smoothing_window=10)\n","\n","    # Initialize SpeedEstimator\n","    speed_estimator = SpeedEstimator(\n","        config=CONFIG,\n","        fps=25.0,\n","        position_smoothing_window=10,\n","        speed_smoothing_window=20,\n","        max_acceleration=5.0\n","    )\n","\n","    #VIDEO PREPARATION\n","    video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH) #Extracts video properties from the source video\n","    video_sink = sv.VideoSink(TARGET_VIDEO_PATH, video_info=video_info) #Prepares to save the processed frames into a new video\n","\n","    # Get total frames first\n","    frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n","    total_frames = sum(1 for _ in frame_generator)\n","\n","    frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH) #reads frames from the video\n","    frames = list(frame_generator)\n","\n","    # Initialize visualizer\n","    style_visualizer = StyleVisualizer(total_frames, CONFIG, fps=video_info.fps)\n","\n","    # Initialize ByteTrack with increased memory (track_buffer)\n","    tracker = sv.ByteTrack() #Multi-object tracker initialized for tracking players\n","    tracker.reset()\n","\n","    # Initialize lists to accumulate player positions for each team\n","    team_1_positions = []\n","    team_2_positions = []\n","\n","    #RETRIEVING TRACKS FROM MODELS (OBJECT DETECTION)\n","    tracks = get_object_tracks(frames) # Get object tracks, either from stub or by running the detection\n","    keypoint_tracks = get_keypoint_tracks(frames) # Get keypoint tracks from stub or run detection\n","\n","    #COLLECTING PLAYER CROPS\n","    player_crops = collect_player_crops(frames, player_id=PLAYER_ID, stride=STRIDE)\n","\n","    path_raw = []\n","    M = deque(maxlen=MAXLEN)\n","\n","    #MAIN LOOP PROCESSING FRAME BY FRAME\n","    with video_sink:\n","        for frame_count, (frame, detections, key_points) in enumerate(zip(frames, tracks, keypoint_tracks)):\n","\n","            #PLAYER/REFEREE/BALL DETECTIONS\n","            ball_detections = detections[detections.class_id == BALL_ID] #Filters out the ball detections\n","            ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10) #Expands bounding box, capturing more detail\n","\n","            all_detections = detections[detections.class_id != BALL_ID] #Remove ball detections from the overall detections\n","            all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n","            all_detections = tracker.update_with_detections(detections=all_detections)\n","\n","            goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n","            players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n","            referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n","\n","\n","            #TEAM CLASSIFICATION\n","            players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n","            players_detections.class_id = team_classifier.predict(players_crops)\n","            goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)\n","            referees_detections.class_id -= 1\n","\n","            all_detections = sv.Detections.merge([\n","                players_detections, goalkeepers_detections, referees_detections])\n","\n","            all_detections.class_id = all_detections.class_id.astype(int)\n","\n","            #PERSPECTIVE TRANSFORMATION\n","            filter = key_points.confidence[0] > 0.5\n","            frame_reference_points = key_points.xy[0][filter]\n","            frame_reference_key_points = sv.KeyPoints(xy=frame_reference_points[np.newaxis, ...])\n","            pitch_reference_points = np.array(CONFIG.vertices)[filter]\n","\n","            transformer = ViewTransformer(\n","                source=frame_reference_points,\n","                target=pitch_reference_points\n","            )\n","\n","            M.append(transformer.m)\n","            transformer.m = np.mean(np.array(M), axis=0)\n","\n","            frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n","            pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n","            path_raw.append(pitch_ball_xy)\n","\n","            path = [\n","                np.empty((0, 2), dtype=np.float32) if coorinates.shape[0] >= 2 else coorinates\n","                for coorinates\n","                in path_raw\n","            ]\n","\n","            path = [coorinates.flatten() for coorinates in path]\n","\n","            #path = replace_outliers_based_on_distance(path, MAX_DISTANCE_THRESHOLD)\n","\n","            pitch_all_points = np.array(CONFIG.vertices)\n","            frame_all_points = transformer.transform_points(points=pitch_all_points)\n","            frame_all_key_points = sv.KeyPoints(xy=frame_all_points[np.newaxis, ...])\n","\n","            players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n","            pitch_players_xy = transformer.transform_points(points=players_xy)\n","            referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n","            pitch_referees_xy = transformer.transform_points(points=referees_xy)\n","\n","\n","            # Filter player coordinates by team\n","            team_1_xy = pitch_players_xy[players_detections.class_id == Team.TEAM_A]\n","            team_2_xy = pitch_players_xy[players_detections.class_id == Team.TEAM_B]\n","\n","            # Append positions to the respective team lists\n","            team_1_positions.extend(team_1_xy)\n","            team_2_positions.extend(team_2_xy)\n","\n","            # Calculate TSI for both teams\n","            team_1_tsi = calculate_team_stretch_index(team_1_xy)\n","            team_2_tsi = calculate_team_stretch_index(team_2_xy)\n","\n","             # Update player speeds using SpeedEstimator\n","            player_tracks = {\n","                'players': {\n","                    tracker_id: {'projection': pitch_players_xy[idx]}\n","                    for idx, tracker_id in enumerate(players_detections.tracker_id)\n","                }\n","            }\n","            player_tracks = speed_estimator.calculate_speed(player_tracks, frame_count)\n","\n","            # Create labels with player speeds\n","            labels = []\n","            speed_labels = []\n","            team_names = config.display_config['team_names']\n","\n","            for tracker_id, class_id in zip(all_detections.tracker_id, all_detections.class_id):\n","                if class_id in [Team.TEAM_A, Team.TEAM_B]:  # Only include players (exclude referees)\n","                    team_name = team_names[class_id]\n","                    labels.append(f\"{team_name}\") #{tracker_id}\")\n","                    # Get the speed from the SpeedEstimator\n","                    if tracker_id in player_tracks['players']:\n","                        speed = player_tracks['players'][tracker_id]['speed']\n","\n","                        if speed < 3.0:\n","                          speed = 0.0\n","\n","                    #labels.append(f\"#{tracker_id}\")  # Player ID inside the box\n","                    speed_labels.append(f\"{speed:.2f} km/h\")  # Speed under the box\n","                else:\n","                    labels.append(\"Ref\")  # Referees are annotated without speed\n","                    speed_labels.append(\"\")  # Empty string for referees\n","\n","            #ANNOTATION\n","            annotated_frame = frame.copy()\n","            #annotated_frame = annotators['box_annotator'].annotate(scene=annotated_frame,detections=all_detections)\n","            #annotated_frame = annotators['ellipse_annotator'].annotate(scene=annotated_frame,detections=all_detections)\n","            #annotated_frame = annotators['label_annotator'].annotate(scene=annotated_frame,detections=all_detections,labels=labels)\n","\n","            \"\"\"\n","            for detection, speed_label in zip(all_detections, speed_labels):\n","                if speed_label:  # Only annotate if there's a speed label\n","                    bbox = detection[0]  # Get the bounding box coordinates\n","                    x1, y1, x2, y2 = bbox\n","                    center_x = (x1 + x2) / 2\n","                    text_size, _ = cv2.getTextSize(speed_label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n","                    text_width, text_height = text_size\n","                    text_x = int(center_x - text_width / 2)  # Center the text horizontally (ensure it's an integer)\n","                    text_y = int(y2 + text_height + 25)  # Position the text just below the bounding box (ensure it's an integer)\n","\n","                    # Draw the speed label\n","                    cv2.putText(\n","                        annotated_frame,\n","                        speed_label,\n","                        (text_x, text_y),  # Ensure this is a tuple of integers\n","                        cv2.FONT_HERSHEY_SIMPLEX,\n","                        0.5,  # Smaller font size\n","                        (255, 255, 255),  # White color\n","                        1,  # Thickness\n","                        lineType=cv2.LINE_AA\n","                    )\n","\n","            \"\"\"\n","\n","            #annotated_frame = annotators['triangle_annotator'].annotate(scene=annotated_frame,detections=ball_detections)\n","\n","            #ANNOTATION FOR KEY-POINT VISUALIZATION\n","\n","            #annotated_frame = edge_annotator.annotate(scene=annotated_frame,key_points=frame_all_key_points)\n","            #annotated_frame = vertex_annotator_2.annotate(scene=annotated_frame,key_points=frame_all_key_points)\n","            #annotated_frame = annotators['vertex_annotator'].annotate(scene=annotated_frame,key_points=frame_reference_key_points)\n","\n","\n","            #ANNOTATION FOR PERSPECTIVE VISUALIZATION\n","\n","            annotated_frame = add_transparent_overlay(\n","              frame=annotated_frame,\n","              CONFIG=CONFIG,\n","              pitch_ball_xy=pitch_ball_xy,\n","              pitch_players_xy=pitch_players_xy,\n","              players_detections=players_detections,\n","              pitch_referees_xy=pitch_referees_xy\n","            )\n","\n","\n","            #ANNOTATION FOR VORONOI VISUALIZATION\n","            \"\"\"\n","            annotated_frame = add_voronoi_transparent_overlay(\n","              frame=annotated_frame,\n","              CONFIG=CONFIG,\n","              pitch_ball_xy=pitch_ball_xy,\n","              pitch_players_xy=pitch_players_xy,\n","              players_detections=players_detections\n","            )\n","            \"\"\"\n","            #BALL TRACKING\n","            \"\"\"\n","            annotated_frame = add_ball_trail_overlay(\n","                frame=annotated_frame,\n","                config=CONFIG,\n","                path=path\n","            )\n","            \"\"\"\n","\n","            # Updating\n","\n","            \"\"\"\n","            game_stats_tracker.update(\n","                ball_detections,\n","                players_detections,\n","                goalkeepers_detections\n","            )\n","\n","            # Get and display stats\n","            stats = game_stats_tracker.get_stats()\n","            annotated_frame = draw_stats_overlay(\n","                frame=annotated_frame,\n","                stats=stats,\n","                config=config\n","            )\n","\n","            team_1_style, team_2_style = update_main_loop(\n","                frame=annotated_frame,\n","                team_1_xy=team_1_xy,\n","                team_2_xy=team_2_xy,\n","                team_1_tsi=team_1_tsi,\n","                team_2_tsi=team_2_tsi,\n","                game_stats_tracker=game_stats_tracker,\n","                config=config\n","            )\n","\n","            # Update visualizer\n","            style_visualizer.update_style(\"Team A\", team_1_style, frame_count)\n","            style_visualizer.update_style(\"Team B\", team_2_style, frame_count)\n","\n","            \"\"\"\n","\n","            video_sink.write_frame(annotated_frame)\n","\n","\n","    # After processing all frames\n","\n","    #style_visualizer.finalize('/content/drive/MyDrive/Output_Image/style_timeline.jpg')\n","\n","    \"\"\"\n","    # After processing all frames, generate the heatmap\n","    team_colors = {\n","        0: (255, 191, 0),  # Team A color (BGR)\n","        1: (147, 20, 255)   # Team B color (BGR)\n","    }\n","\n","    # Generate heatmap for Team A\n","    heatmap_team1 = generate_heatmap_for_team(\n","        positions=team_1_positions,\n","        config=CONFIG,\n","        color=team_colors[0],\n","        output_path='/content/drive/MyDrive/Output_Image/heatmap_team1.png'\n","    )\n","\n","    # Generate heatmap for Team B\n","    heatmap_team2 = generate_heatmap_for_team(\n","        positions=team_2_positions,\n","        config=CONFIG,\n","        color=team_colors[1],\n","        output_path='/content/drive/MyDrive/Output_Image/heatmap_team2.png'\n","    )\n","\n","    # Combine both heatmaps\n","    combined_heatmap = combine_heatmaps(heatmap_team1, heatmap_team2)\n","    cv2.imwrite('/content/drive/MyDrive/Output_Image/combined_heatmap.png', combined_heatmap)\n","\n","    \"\"\"\n","\n","\n","    #PRINT POSSESSION STATS\n","    final_stats = game_stats_tracker.get_stats()\n","    print(\"\\nFinal Game Statistics:\")\n","    for team_id, percentage in final_stats['possession_percentage'].items():\n","        team_name = config.display_config['team_names'][team_id]\n","        print(f\"{team_name} Possession: {percentage:.1f}%\")\n","        print(f\"{team_name} Total Passes: {final_stats['passes'][team_id]['total_passes']}\")\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","source":[],"metadata":{"id":"zZghVNx6uSYt"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"06942d01e6b442c488deeca868e36516":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d9e03e8fd374da2b57a837607efa407","IPY_MODEL_4e7019bf8b7341c8b1752f68e4d7b05e","IPY_MODEL_ec03d7a0232e4d9b8f555bf8a75fae69"],"layout":"IPY_MODEL_437d5a85834a48d2b3a9eed6cfb09672"}},"6d9e03e8fd374da2b57a837607efa407":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc3c59ba17cd44b582e73b5fcadd57a0","placeholder":"â€‹","style":"IPY_MODEL_c329197ce17743f28355b5544de1e41c","value":"config.json:â€‡100%"}},"4e7019bf8b7341c8b1752f68e4d7b05e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a8bec973ebf4b84872ec4fd0ba057ab","max":69556,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6fba0f26ef54c2c8659d68637bad77b","value":69556}},"ec03d7a0232e4d9b8f555bf8a75fae69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_625f96cb7ae148f28c0f15bc81fd2971","placeholder":"â€‹","style":"IPY_MODEL_50f01f7f6893439891a8e020d8f655c2","value":"â€‡69.6k/69.6kâ€‡[00:00&lt;00:00,â€‡6.72MB/s]"}},"437d5a85834a48d2b3a9eed6cfb09672":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc3c59ba17cd44b582e73b5fcadd57a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c329197ce17743f28355b5544de1e41c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a8bec973ebf4b84872ec4fd0ba057ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6fba0f26ef54c2c8659d68637bad77b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"625f96cb7ae148f28c0f15bc81fd2971":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50f01f7f6893439891a8e020d8f655c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"979e92cb7703444fa6e35ff8b7975aca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_907c967e232f4560a1fa0fd4d36a973e","IPY_MODEL_fb0d698459974939914e0391abc87a50","IPY_MODEL_d5320351a0174162b8ffe9fec696164f"],"layout":"IPY_MODEL_f4205447f61146a698dc75844963b17a"}},"907c967e232f4560a1fa0fd4d36a973e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34a39dd49a5c446680d010b283fc2879","placeholder":"â€‹","style":"IPY_MODEL_d62940ab184c47d791d265240ac95ea4","value":"model.safetensors:â€‡100%"}},"fb0d698459974939914e0391abc87a50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28c6bc2ae8da4732947674e79f133863","max":64127208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9742b201b9ca40ac8d55b9326f7b8586","value":64127208}},"d5320351a0174162b8ffe9fec696164f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49d0a178eb1848b192f4a604712e3ff9","placeholder":"â€‹","style":"IPY_MODEL_85ea3182a168450c8dc66911f7a7dbcb","value":"â€‡64.1M/64.1Mâ€‡[00:00&lt;00:00,â€‡189MB/s]"}},"f4205447f61146a698dc75844963b17a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34a39dd49a5c446680d010b283fc2879":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d62940ab184c47d791d265240ac95ea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28c6bc2ae8da4732947674e79f133863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9742b201b9ca40ac8d55b9326f7b8586":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49d0a178eb1848b192f4a604712e3ff9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85ea3182a168450c8dc66911f7a7dbcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}